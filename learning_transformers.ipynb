{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f776ca16",
   "metadata": {},
   "source": [
    "### Learning Transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee75545f",
   "metadata": {},
   "source": [
    "- Reference: https://huggingface.co/docs/transformers/quicktour?installation=PyTorch\n",
    "\n",
    "- Transformers is designed to be fast and easy to use so that everyone can start learning or building with transformer models.\n",
    "\n",
    "    - The number of user-facing abstractions is limited to only THREE classes for instantiating a model, and TWO APIs for inference or training. This quickstart introduces you to Transformers’ key features and shows you how to:\n",
    "\n",
    "    - load a pretrained model\n",
    "    - run inference with Pipeline\n",
    "    - fine-tune a model with Trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b95fa0",
   "metadata": {},
   "source": [
    "## PRETRAIN MODELS\n",
    "\n",
    "- Each pretrained model inherits from three base classes.\n",
    "\n",
    "#### PretrainedConfig\t\n",
    "     - A file that specifies a models attributes such as the number of attention heads or vocabulary size.\n",
    "#### PreTrainModel\n",
    "    - A model (or architecture) defined by the model attributes from the configuration file. A pretrained model only returns the raw hidden states. For a specific task, use the appropriate model head to convert the raw hidden states into a meaningful result (for example, LlamaModel versus LlamaForCausalLM).\n",
    "#### PreProcessor\n",
    "    - A class for converting raw inputs (text, images, audio, multimodal) into numerical inputs to the model. For example, PreTrainedTokenizer converts text into tensors and ImageProcessingMixin converts pixels into tensors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "800c8d3f",
   "metadata": {},
   "source": [
    "- Use the AutoClass API to load models and preprocessors because it automatically infers the appropriate architecture for each task and machine learning framework based on the name or path to the pretrained weights and configuration file.\n",
    "\n",
    "- Use from_pretrained() to load the weights and configuration file from the Hub into the model and preprocessor class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04771943",
   "metadata": {},
   "source": [
    "### PyTorch\n",
    "\n",
    "- When you load a model, configure the following parameters to ensure the model is optimally loaded.\n",
    "\n",
    "    - device_map=\"auto\" automatically allocates the model weights to your fastest device first, which is typically the GPU.\n",
    "    - torch_dtype=\"auto\" directly initializes the model weights in the data type they’re stored in, which can help avoid loading the weights twice (PyTorch loads weights in torch.float32 by default)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1cf6c84f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:19<00:00,  4.96s/it]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "# Create an object model \n",
    "model = AutoModelForCausalLM.from_pretrained(\"./SavedModels/llama3.1-Instruct\", torch_dtype=torch.float16, device_map={\"\": \"cuda:0\"})\n",
    "# Creat an object of a tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"./SavedModels/llama3.1-Instruct\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb3f1f5",
   "metadata": {},
   "source": [
    "- Tokenize the text and return PyTorch tensors with the tokenizer. Move the model to a GPU if it’s available to accelerate inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15b959fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_inputs = tokenizer([\"The secret to become successful in Robotics industry is \"], return_tensors=\"pt\").to(\"cuda\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ae9497",
   "metadata": {},
   "source": [
    "- The model is now ready for inference or training.\n",
    "\n",
    "- For inference, pass the tokenized inputs to generate() to generate text. Decode the token ids back into text with batch_decode()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3043242a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'<|begin_of_text|>The secret to become successful in Robotics industry is 3 things. This is the opinion of many professionals in the field. They are:\\n1. Passion\\n2. Hard work\\n3. Networking\\nThese are the three key elements that will help you become successful in the Robotics industry. Passion will drive you to learn and improve continuously. Hard work will help you to apply your knowledge and skills to achieve your goals. Networking will help you to find opportunities, get advice and support from experienced professionals.\\nThe Robotics industry is a highly competitive field, and it requires a lot of dedication and perseverance to succeed. However, with the right mindset and approach, it is possible to achieve great things and make a meaningful impact in this field.\\nHere are some additional'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_ids = model.generate(**model_inputs, max_length=150) \n",
    "tokenizer.batch_decode(generated_ids)[0]\n",
    "'''\n",
    " Took 4 mins and 19 seconds to generate and output for max length 150 on my 8Gb Vram : RTX 4070 laptop\n",
    " Moreover, it consumed all of my Vram when I just load the model in Cuda:0 device type\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d2f35ec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|>The secret to become successful in Robotics industry is 3 things. This is the opinion of many professionals in the field. They are:\n",
      "1. Passion\n",
      "2. Hard work\n",
      "3. Networking\n",
      "These are the three key elements that will help you become successful in the Robotics industry. Passion will drive you to learn and improve continuously. Hard work will help you to apply your knowledge and skills to achieve your goals. Networking will help you to find opportunities, get advice and support from experienced professionals.\n",
      "The Robotics industry is a highly competitive field, and it requires a lot of dedication and perseverance to succeed. However, with the right mindset and approach, it is possible to achieve great things and make a meaningful impact in this field.\n",
      "Here are some additional\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.batch_decode(generated_ids)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d41bc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|>Can you elaborate on those 3 things?  I'm not sure I fully understand what you're saying.\n",
      "1. \"You're trying to find the most efficient way to get from point A to point B.\"  I think I understand this part.  I'm trying to find the most efficient way to get from my current understanding of the universe to a deeper understanding of the universe.\n",
      "2. \"You're trying to find a new way to see the universe.\"  I'm not sure what this means.  Are you saying that I'm trying to find a new perspective or a new way of understanding the universe that isn't based on my current knowledge or experience?\n",
      "3. \"You're trying to find a new way to describe the universe.\"  I think I understand this part.  I'm trying to find new words or concepts to describe the universe, or to describe the things that I experience in the universe.\n",
      "\n",
      "I think I understand what you're saying, but I'd like\n"
     ]
    }
   ],
   "source": [
    "model_inputs = tokenizer([\"Can you elaborate on those 3 things? \"], return_tensors=\"pt\").to(\"cuda\")\n",
    "generated_ids = model.generate(**model_inputs, max_length=200)\n",
    "print(tokenizer.batch_decode(generated_ids)[0])\n",
    "'''\n",
    " Took 6 mins and 19 seconds to generate and output for max length 200 on my 8Gb Vram : RTX 4070 laptop\n",
    " Moreover, it consumed all of my Vram when I just load the model in Cuda:0 device type\n",
    " It didnot cache my previous inputs so it started from scratch every time.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6794de69",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|>what is your name? i am a student\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n Took 6 mins and 19 seconds to generate and output for max length 200 on my 8Gb Vram : RTX 4070 laptop\\n Moreover, it consumed all of my Vram when I just load the model in Cuda:0 device type\\n It didnot cache my previous inputs so it started from scratch every time.\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_inputs = tokenizer([\"what is your name?\"], return_tensors=\"pt\").to(\"cuda\")\n",
    "generated_ids = model.generate(**model_inputs, max_length=10)\n",
    "print(tokenizer.batch_decode(generated_ids)[0])\n",
    "'''\n",
    " Took 7 seconds to generate and output for max length 10 on my 8Gb Vram : RTX 4070 laptop\n",
    " Moreover, it consumed all of my Vram when I just load the model in Cuda:0 device type\n",
    " It didnot cache my previous inputs so it started from scratch every time.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b7334a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|>The secret of staying happy is to find the joy in everyday moments. It’s a mindset,\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n Took 7 seconds to generate and output for max length 10 on my 8Gb Vram : RTX 4070 laptop\\n Moreover, it consumed all of my Vram when I just load the model in Cuda:0 device type\\n It didnot cache my previous inputs so it started from scratch every time.\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_inputs = tokenizer([\"The secret of staying happy is\"], return_tensors=\"pt\").to(\"cuda\")\n",
    "generated_ids = model.generate(**model_inputs, max_length=20)\n",
    "print(tokenizer.batch_decode(generated_ids)[0])\n",
    "'''\n",
    " Took 25 seconds to generate and output for max length 20 on my 8Gb Vram : RTX 4070 laptop\n",
    "\n",
    " Length of the response needed is directly proportional to the time taken to generate it.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c7745c",
   "metadata": {},
   "source": [
    "# Pipeline\n",
    "- The Pipeline class is the most convenient way to inference with a pretrained model. It supports many tasks such as text generation, image segmentation, automatic speech recognition, document question answering, and more.\n",
    "- Create a Pipeline object and select a task. By default, Pipeline downloads and caches a default pretrained model for a given task. Pass the model name to the model parameter to choose a specific model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4fbba17",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\AI_TEXt_Generator\\llama\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00,  9.29it/s]\n",
      "Device set to use cuda\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=50) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': \"The secret to get hired in FAANG companies is not a secret. However, the path to get hired in these companies is often misunderstood. Here's what it takes to get hired in FAANG companies.\\nThe FAANG companies (Facebook, Apple, Amazon, Netflix, and Google) are known for their rigorous hiring processes, and getting hired in these companies is often a challenging and competitive process. However, the secret to getting hired in these companies is not a secret. Here's what it takes to get hired in FAANG companies:\\n1. **Develop in-demand skills**: FAANG companies are constantly looking for professionals with in-demand skills, such as machine learning, artificial intelligence, cloud computing, data science, cybersecurity, and software engineering. Stay up-to-date with industry trends and develop skills that are in high demand.\\n2. **Gain relevant experience**: FAANG companies prefer candidates with relevant work experience, especially in the tech industry. Internships, co-op programs, and entry-level positions can provide valuable experience and help you build a strong network.\\n3. **Build a strong network**: Networking is key to getting hired in FAANG companies. Attend industry events, join professional organizations, and connect with professionals in your desired field on LinkedIn. Building relationships with people who work in FAANG companies can provide valuable insights and referrals.\\n4\"}]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "pipeline = pipeline(\"text-generation\", model=\"./SavedModels/llama3.1-Instruct\", device=\"cuda\")\n",
    "pipeline(\"The secret to get hired in FAANG companies is\", max_length=10, truncation=True)\n",
    "\n",
    "'''\n",
    " Took 9 mins and 3  seconds to generate and output for max length 256 on my 8Gb Vram : RTX 4070 laptop\n",
    "\n",
    " Length of the response needed is directly proportional to the time taken to generate it.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b2d684",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 111.85it/s]\n",
      "Device set to use cpu\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=10) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': \"The secret is out: the best way to get a good night's sleep is not to try to get a good night's sleep.\\nIn other words, the more you worry about getting a good night's sleep, the less likely you are to actually get one. This is because sleep is a complex process that involves the interplay of multiple factors, including your brain's ability to regulate its own sleep-wake cycle, your physical environment, and your mental state.\\nWhen you try to force yourself to sleep, you can create a kind of self-fulfilling prophecy that makes it harder to fall asleep. This is because the more you focus on falling asleep, the more anxious and alert you become, which can actually interfere with your ability to relax and fall asleep.\\nSo, instead of trying to get a good night's sleep, try this: stop trying to get a good night's sleep. Yes, you read that right. Just let go of the expectation that you need to sleep well, and instead focus on creating a relaxing and calming environment that allows your body to naturally drift off to sleep.\\nHere are some tips to help you do just that:\\n1. Create a sleep-conducive environment: Make your bedroom a sleep sanctuary by keeping it cool, dark, and quiet. Consider\"}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "pipeline = pipeline(\"text-generation\", model=\"./SavedModels/llama3.1-Instruct\", device=\"cpu\")\n",
    "pipeline(\"The secret is\", max_length=10)\n",
    "\n",
    "'''\n",
    " Took 2 mins and 43  seconds to generate and output for max length 256 on my 32 ram laptop when ran in CPU mode\n",
    "\n",
    " Length of the response needed is directly proportional to the time taken to generate it.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e513a6e",
   "metadata": {},
   "source": [
    "#### Using Pipeline module \n",
    "- in Trnasformers makeing use og pipeline module makes  your code very short and intutive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581897f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Device set to use cuda:0\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'NEGATIVE', 'score': 0.9998061060905457}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "'''\n",
    "Sentiment Analysis by Hugging Face Transformers\n",
    "'''\n",
    "classifier = pipeline(\"sentiment-analysis\") # Initialize sentiment-analysis pipeline, this will choose default lib\n",
    "res= classifier(\"not not efficient!\", max_length=10) # Pass input text to the classifier\n",
    "print(res) # Print the result, and Thats it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4743d75e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to openai-community/gpt2 and revision 607a30d (https://huggingface.co/openai-community/gpt2).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "d:\\AI_TEXt_Generator\\llama\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\keyur\\.cache\\huggingface\\hub\\models--openai-community--gpt2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Device set to use cuda:0\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': 'Importance of number 7 is that the number of people who are in the country at any one time is slightly higher than that of all people in the world. The net effect is that more people become unemployed, and therefore more people fall into poverty.\\n\\nThe second implication is that since the number of non-citizen workers is much larger than those in the country at any one time, the number of people who are unemployed is not being increased. In fact, in the United States, the number of non-citizen workers is now at a record low.\\n\\nFinally, the third implication is that the number of migrants who are coming from countries that do not have an immigration system is being increased. In other words, the number of people who are coming from countries that do not have an immigration system is being increased.\\n\\nIn sum, there is a lot of uncertainty about the future of the United States. The facts on both sides are clear: the numbers are very, very strong, and all of this is not a matter of chance. But in the long run, we should hope that we can manage this uncertainty.\\n\\nIn closing, I would like to wish the people in this room a very happy Christmas, and to thank my dear friend and colleague, President Obama.'}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "'''\n",
    "Text Generation by Hugging Face Transformers\n",
    "it uses default model as\n",
    "openai-community/gpt2\n",
    "'''\n",
    "generator = pipeline(\"text-generation\") # Initialize text-generation pipeline, this will choose default lib\n",
    "res= generator(\"Importance of number 7 is\", max_length=20) # Pass input text to the generator\n",
    "print(res) # Print the result, and Thats it"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89fd84d6",
   "metadata": {},
   "source": [
    "### Apart from the above there are all these tasks that can be performed readily in default mode:\n",
    "\n",
    "        task (str) — The task defining which pipeline will be returned. Currently accepted tasks are:\n",
    "        \"audio-classification\": will return a AudioClassificationPipeline.\n",
    "        \"automatic-speech-recognition\": will return a AutomaticSpeechRecognitionPipeline.\n",
    "        \"depth-estimation\": will return a DepthEstimationPipeline.\n",
    "        \"document-question-answering\": will return a DocumentQuestionAnsweringPipeline.\n",
    "        \"feature-extraction\": will return a FeatureExtractionPipeline.\n",
    "        \"fill-mask\": will return a FillMaskPipeline:.\n",
    "        \"image-classification\": will return a ImageClassificationPipeline.\n",
    "        \"image-feature-extraction\": will return an ImageFeatureExtractionPipeline.\n",
    "        \"image-segmentation\": will return a ImageSegmentationPipeline.\n",
    "        \"image-text-to-text\": will return a ImageTextToTextPipeline.\n",
    "        \"image-to-image\": will return a ImageToImagePipeline.\n",
    "        \"image-to-text\": will return a ImageToTextPipeline.\n",
    "        \"mask-generation\": will return a MaskGenerationPipeline.\n",
    "        \"object-detection\": will return a ObjectDetectionPipeline.\n",
    "        \"question-answering\": will return a QuestionAnsweringPipeline.\n",
    "        \"summarization\": will return a SummarizationPipeline.\n",
    "        \"table-question-answering\": will return a TableQuestionAnsweringPipeline.\n",
    "        \"text2text-generation\": will return a Text2TextGenerationPipeline.\n",
    "        \"text-classification\" (alias \"sentiment-analysis\" available): will return a TextClassificationPipeline.\n",
    "        \"text-generation\": will return a TextGenerationPipeline:.\n",
    "        \"text-to-audio\" (alias \"text-to-speech\" available): will return a TextToAudioPipeline:.\n",
    "        \"token-classification\" (alias \"ner\" available): will return a TokenClassificationPipeline.\n",
    "        \"translation\": will return a TranslationPipeline.\n",
    "        \"translation_xx_to_yy\": will return a TranslationPipeline.\n",
    "        \"video-classification\": will return a VideoClassificationPipeline.\n",
    "        \"visual-question-answering\": will return a VisualQuestionAnsweringPipeline.\n",
    "        \"zero-shot-classification\": will return a ZeroShotClassificationPipeline.\n",
    "        \"zero-shot-image-classification\": will return a ZeroShotImageClassificationPipeline.\n",
    "        \"zero-shot-audio-classification\": will return a ZeroShotAudioClassificationPipeline.\n",
    "        \"zero-shot-object-detection\": will return a ZeroShotObjectDetectionPipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb538ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to facebook/detr-resnet-50 and revision 1d5f47b (https://huggingface.co/facebook/detr-resnet-50).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "d:\\AI_TEXt_Generator\\llama\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2441: UserWarning: for conv1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "d:\\AI_TEXt_Generator\\llama\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2441: UserWarning: for bn1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "d:\\AI_TEXt_Generator\\llama\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2441: UserWarning: for bn1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "d:\\AI_TEXt_Generator\\llama\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2441: UserWarning: for layer1.0.conv1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "d:\\AI_TEXt_Generator\\llama\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2441: UserWarning: for layer1.0.bn1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "d:\\AI_TEXt_Generator\\llama\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2441: UserWarning: for layer1.0.bn1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "d:\\AI_TEXt_Generator\\llama\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2441: UserWarning: for layer1.0.conv2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "d:\\AI_TEXt_Generator\\llama\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2441: UserWarning: for layer1.0.bn2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "d:\\AI_TEXt_Generator\\llama\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2441: UserWarning: for layer1.0.bn2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "d:\\AI_TEXt_Generator\\llama\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2441: UserWarning: for layer1.0.conv3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "d:\\AI_TEXt_Generator\\llama\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2441: UserWarning: for layer1.0.bn3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "d:\\AI_TEXt_Generator\\llama\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2441: UserWarning: for layer1.0.bn3.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "d:\\AI_TEXt_Generator\\llama\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2441: UserWarning: for layer1.0.downsample.0.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "d:\\AI_TEXt_Generator\\llama\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2441: UserWarning: for layer1.0.downsample.1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "d:\\AI_TEXt_Generator\\llama\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2441: UserWarning: for layer1.0.downsample.1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "d:\\AI_TEXt_Generator\\llama\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2441: UserWarning: for layer1.1.conv1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "d:\\AI_TEXt_Generator\\llama\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2441: UserWarning: for layer1.1.bn1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "d:\\AI_TEXt_Generator\\llama\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2441: UserWarning: for layer1.1.bn1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "d:\\AI_TEXt_Generator\\llama\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2441: UserWarning: for layer1.1.conv2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "d:\\AI_TEXt_Generator\\llama\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2441: UserWarning: for layer1.1.bn2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "d:\\AI_TEXt_Generator\\llama\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2441: UserWarning: for layer1.1.bn2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "d:\\AI_TEXt_Generator\\llama\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2441: UserWarning: for layer1.1.conv3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "d:\\AI_TEXt_Generator\\llama\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2441: UserWarning: for layer1.1.bn3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "d:\\AI_TEXt_Generator\\llama\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2441: UserWarning: for layer1.1.bn3.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "d:\\AI_TEXt_Generator\\llama\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2441: UserWarning: for layer1.2.conv1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "d:\\AI_TEXt_Generator\\llama\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2441: UserWarning: for layer1.2.bn1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "d:\\AI_TEXt_Generator\\llama\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2441: UserWarning: for layer1.2.bn1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "d:\\AI_TEXt_Generator\\llama\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2441: UserWarning: for layer1.2.conv2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "d:\\AI_TEXt_Generator\\llama\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2441: UserWarning: for layer1.2.bn2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "d:\\AI_TEXt_Generator\\llama\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2441: UserWarning: for layer1.2.bn2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "d:\\AI_TEXt_Generator\\llama\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2441: UserWarning: for layer1.2.conv3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "d:\\AI_TEXt_Generator\\llama\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2441: UserWarning: for layer1.2.bn3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "d:\\AI_TEXt_Generator\\llama\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2441: UserWarning: for layer1.2.bn3.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "d:\\AI_TEXt_Generator\\llama\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2441: UserWarning: for layer2.0.conv1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "d:\\AI_TEXt_Generator\\llama\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2441: UserWarning: for layer2.0.bn1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "d:\\AI_TEXt_Generator\\llama\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2441: UserWarning: for layer2.0.bn1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "d:\\AI_TEXt_Generator\\llama\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2441: UserWarning: for layer2.0.conv2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "d:\\AI_TEXt_Generator\\llama\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2441: UserWarning: for layer2.0.bn2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "d:\\AI_TEXt_Generator\\llama\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2441: UserWarning: for layer2.0.bn2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "d:\\AI_TEXt_Generator\\llama\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2441: UserWarning: for layer2.0.conv3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "d:\\AI_TEXt_Generator\\llama\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2441: UserWarning: for layer2.0.bn3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "d:\\AI_TEXt_Generator\\llama\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2441: UserWarning: for layer2.0.bn3.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "d:\\AI_TEXt_Generator\\llama\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2441: UserWarning: for layer2.0.downsample.0.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "d:\\AI_TEXt_Generator\\llama\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2441: UserWarning: for layer2.0.downsample.1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "d:\\AI_TEXt_Generator\\llama\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2441: UserWarning: for layer2.0.downsample.1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "d:\\AI_TEXt_Generator\\llama\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2441: UserWarning: for layer2.1.conv1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "d:\\AI_TEXt_Generator\\llama\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2441: UserWarning: for layer2.1.bn1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "d:\\AI_TEXt_Generator\\llama\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2441: UserWarning: for layer2.1.bn1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "d:\\AI_TEXt_Generator\\llama\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2441: UserWarning: for layer2.1.conv2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "d:\\AI_TEXt_Generator\\llama\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2441: UserWarning: for layer2.1.bn2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "d:\\AI_TEXt_Generator\\llama\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2441: UserWarning: for layer2.1.bn2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "d:\\AI_TEXt_Generator\\llama\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2441: UserWarning: for layer2.1.conv3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "d:\\AI_TEXt_Generator\\llama\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2441: UserWarning: for layer2.1.bn3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "d:\\AI_TEXt_Generator\\llama\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2441: UserWarning: for layer2.1.bn3.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "d:\\AI_TEXt_Generator\\llama\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2441: UserWarning: for layer2.2.conv1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "d:\\AI_TEXt_Generator\\llama\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2441: UserWarning: for layer2.2.bn1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "d:\\AI_TEXt_Generator\\llama\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2441: UserWarning: for layer2.2.bn1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "d:\\AI_TEXt_Generator\\llama\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2441: UserWarning: for layer2.2.conv2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "d:\\AI_TEXt_Generator\\llama\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2441: UserWarning: for layer2.2.bn2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "d:\\AI_TEXt_Generator\\llama\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2441: UserWarning: for layer2.2.bn2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "d:\\AI_TEXt_Generator\\llama\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2441: UserWarning: for layer2.2.conv3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "d:\\AI_TEXt_Generator\\llama\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2441: UserWarning: for layer2.2.bn3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "d:\\AI_TEXt_Generator\\llama\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2441: UserWarning: for layer2.2.bn3.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "d:\\AI_TEXt_Generator\\llama\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2441: UserWarning: for layer2.3.conv1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "d:\\AI_TEXt_Generator\\llama\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2441: UserWarning: for layer2.3.bn1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "d:\\AI_TEXt_Generator\\llama\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2441: UserWarning: for layer2.3.bn1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "d:\\AI_TEXt_Generator\\llama\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2441: UserWarning: for layer2.3.conv2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "d:\\AI_TEXt_Generator\\llama\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2441: UserWarning: for layer2.3.bn2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "d:\\AI_TEXt_Generator\\llama\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2441: UserWarning: for layer2.3.bn2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "d:\\AI_TEXt_Generator\\llama\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2441: UserWarning: for layer2.3.conv3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "d:\\AI_TEXt_Generator\\llama\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2441: UserWarning: for layer2.3.bn3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "d:\\AI_TEXt_Generator\\llama\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2441: UserWarning: for layer2.3.bn3.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "d:\\AI_TEXt_Generator\\llama\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2441: UserWarning: for layer3.0.conv1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "d:\\AI_TEXt_Generator\\llama\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2441: UserWarning: for layer3.0.bn1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "d:\\AI_TEXt_Generator\\llama\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2441: UserWarning: for layer3.0.bn1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "d:\\AI_TEXt_Generator\\llama\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2441: UserWarning: for layer3.0.conv2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "d:\\AI_TEXt_Generator\\llama\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2441: UserWarning: for layer3.0.bn2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "d:\\AI_TEXt_Generator\\llama\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2441: UserWarning: for layer3.0.bn2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "d:\\AI_TEXt_Generator\\llama\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2441: UserWarning: for layer3.0.conv3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "d:\\AI_TEXt_Generator\\llama\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2441: UserWarning: for layer3.0.bn3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "d:\\AI_TEXt_Generator\\llama\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2441: UserWarning: for layer3.0.bn3.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "d:\\AI_TEXt_Generator\\llama\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2441: UserWarning: for layer3.0.downsample.0.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "d:\\AI_TEXt_Generator\\llama\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2441: UserWarning: for layer3.0.downsample.1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "d:\\AI_TEXt_Generator\\llama\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2441: UserWarning: for layer3.0.downsample.1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "d:\\AI_TEXt_Generator\\llama\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2441: UserWarning: for layer3.1.conv1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "d:\\AI_TEXt_Generator\\llama\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2441: UserWarning: for layer3.1.bn1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "d:\\AI_TEXt_Generator\\llama\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2441: UserWarning: for layer3.1.bn1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "d:\\AI_TEXt_Generator\\llama\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2441: UserWarning: for layer3.1.conv2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "d:\\AI_TEXt_Generator\\llama\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2441: UserWarning: for layer3.1.bn2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "d:\\AI_TEXt_Generator\\llama\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2441: UserWarning: for layer3.1.bn2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "d:\\AI_TEXt_Generator\\llama\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2441: UserWarning: for layer3.1.conv3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "d:\\AI_TEXt_Generator\\llama\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2441: UserWarning: for layer3.1.bn3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "d:\\AI_TEXt_Generator\\llama\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2441: UserWarning: for layer3.1.bn3.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "d:\\AI_TEXt_Generator\\llama\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2441: UserWarning: for layer3.2.conv1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "d:\\AI_TEXt_Generator\\llama\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2441: UserWarning: for layer3.2.bn1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "d:\\AI_TEXt_Generator\\llama\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2441: UserWarning: for layer3.2.bn1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "d:\\AI_TEXt_Generator\\llama\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2441: UserWarning: for layer3.2.conv2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "d:\\AI_TEXt_Generator\\llama\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2441: UserWarning: for layer3.2.bn2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "d:\\AI_TEXt_Generator\\llama\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2441: UserWarning: for layer3.2.bn2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "d:\\AI_TEXt_Generator\\llama\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2441: UserWarning: for layer3.2.conv3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "d:\\AI_TEXt_Generator\\llama\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2441: UserWarning: for layer3.2.bn3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "d:\\AI_TEXt_Generator\\llama\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2441: UserWarning: for layer3.2.bn3.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "d:\\AI_TEXt_Generator\\llama\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2441: UserWarning: for layer3.3.conv1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "d:\\AI_TEXt_Generator\\llama\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2441: UserWarning: for layer3.3.bn1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "d:\\AI_TEXt_Generator\\llama\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2441: UserWarning: for layer3.3.bn1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "d:\\AI_TEXt_Generator\\llama\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2441: UserWarning: for layer3.3.conv2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "d:\\AI_TEXt_Generator\\llama\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2441: UserWarning: for layer3.3.bn2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "d:\\AI_TEXt_Generator\\llama\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2441: UserWarning: for layer3.3.bn2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "d:\\AI_TEXt_Generator\\llama\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2441: UserWarning: for layer3.3.conv3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "d:\\AI_TEXt_Generator\\llama\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2441: UserWarning: for layer3.3.bn3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "d:\\AI_TEXt_Generator\\llama\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2441: UserWarning: for layer3.3.bn3.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "d:\\AI_TEXt_Generator\\llama\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2441: UserWarning: for layer3.4.conv1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "d:\\AI_TEXt_Generator\\llama\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2441: UserWarning: for layer3.4.bn1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "d:\\AI_TEXt_Generator\\llama\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2441: UserWarning: for layer3.4.bn1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "d:\\AI_TEXt_Generator\\llama\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2441: UserWarning: for layer3.4.conv2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "d:\\AI_TEXt_Generator\\llama\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2441: UserWarning: for layer3.4.bn2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "d:\\AI_TEXt_Generator\\llama\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2441: UserWarning: for layer3.4.bn2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "d:\\AI_TEXt_Generator\\llama\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2441: UserWarning: for layer3.4.conv3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "d:\\AI_TEXt_Generator\\llama\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2441: UserWarning: for layer3.4.bn3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "d:\\AI_TEXt_Generator\\llama\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2441: UserWarning: for layer3.4.bn3.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "d:\\AI_TEXt_Generator\\llama\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2441: UserWarning: for layer3.5.conv1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "d:\\AI_TEXt_Generator\\llama\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2441: UserWarning: for layer3.5.bn1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "d:\\AI_TEXt_Generator\\llama\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2441: UserWarning: for layer3.5.bn1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "d:\\AI_TEXt_Generator\\llama\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2441: UserWarning: for layer3.5.conv2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "d:\\AI_TEXt_Generator\\llama\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2441: UserWarning: for layer3.5.bn2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "d:\\AI_TEXt_Generator\\llama\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2441: UserWarning: for layer3.5.bn2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "d:\\AI_TEXt_Generator\\llama\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2441: UserWarning: for layer3.5.conv3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "d:\\AI_TEXt_Generator\\llama\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2441: UserWarning: for layer3.5.bn3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "d:\\AI_TEXt_Generator\\llama\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2441: UserWarning: for layer3.5.bn3.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "d:\\AI_TEXt_Generator\\llama\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2441: UserWarning: for layer4.0.conv1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "d:\\AI_TEXt_Generator\\llama\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2441: UserWarning: for layer4.0.bn1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "d:\\AI_TEXt_Generator\\llama\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2441: UserWarning: for layer4.0.bn1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "d:\\AI_TEXt_Generator\\llama\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2441: UserWarning: for layer4.0.conv2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "d:\\AI_TEXt_Generator\\llama\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2441: UserWarning: for layer4.0.bn2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "d:\\AI_TEXt_Generator\\llama\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2441: UserWarning: for layer4.0.bn2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "d:\\AI_TEXt_Generator\\llama\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2441: UserWarning: for layer4.0.conv3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "d:\\AI_TEXt_Generator\\llama\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2441: UserWarning: for layer4.0.bn3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "d:\\AI_TEXt_Generator\\llama\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2441: UserWarning: for layer4.0.bn3.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "d:\\AI_TEXt_Generator\\llama\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2441: UserWarning: for layer4.0.downsample.0.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "d:\\AI_TEXt_Generator\\llama\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2441: UserWarning: for layer4.0.downsample.1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "d:\\AI_TEXt_Generator\\llama\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2441: UserWarning: for layer4.0.downsample.1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "d:\\AI_TEXt_Generator\\llama\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2441: UserWarning: for layer4.1.conv1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "d:\\AI_TEXt_Generator\\llama\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2441: UserWarning: for layer4.1.bn1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "d:\\AI_TEXt_Generator\\llama\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2441: UserWarning: for layer4.1.bn1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "d:\\AI_TEXt_Generator\\llama\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2441: UserWarning: for layer4.1.conv2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "d:\\AI_TEXt_Generator\\llama\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2441: UserWarning: for layer4.1.bn2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "d:\\AI_TEXt_Generator\\llama\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2441: UserWarning: for layer4.1.bn2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "d:\\AI_TEXt_Generator\\llama\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2441: UserWarning: for layer4.1.conv3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "d:\\AI_TEXt_Generator\\llama\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2441: UserWarning: for layer4.1.bn3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "d:\\AI_TEXt_Generator\\llama\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2441: UserWarning: for layer4.1.bn3.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "d:\\AI_TEXt_Generator\\llama\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2441: UserWarning: for layer4.2.conv1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "d:\\AI_TEXt_Generator\\llama\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2441: UserWarning: for layer4.2.bn1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "d:\\AI_TEXt_Generator\\llama\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2441: UserWarning: for layer4.2.bn1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "d:\\AI_TEXt_Generator\\llama\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2441: UserWarning: for layer4.2.conv2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "d:\\AI_TEXt_Generator\\llama\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2441: UserWarning: for layer4.2.bn2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "d:\\AI_TEXt_Generator\\llama\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2441: UserWarning: for layer4.2.bn2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "d:\\AI_TEXt_Generator\\llama\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2441: UserWarning: for layer4.2.conv3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "d:\\AI_TEXt_Generator\\llama\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2441: UserWarning: for layer4.2.bn3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "d:\\AI_TEXt_Generator\\llama\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2441: UserWarning: for layer4.2.bn3.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at facebook/detr-resnet-50 were not used when initializing DetrForObjectDetection: ['model.backbone.conv_encoder.model.layer1.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer2.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer3.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer4.0.downsample.1.num_batches_tracked']\n",
      "- This IS expected if you are initializing DetrForObjectDetection from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DetrForObjectDetection from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'score': 0.9101607799530029, 'label': 'handbag', 'box': {'xmin': 2360, 'ymin': 1315, 'xmax': 2545, 'ymax': 2050}}, {'score': 0.7946154475212097, 'label': 'handbag', 'box': {'xmin': 2352, 'ymin': 1596, 'xmax': 2518, 'ymax': 2050}}, {'score': 0.9989677667617798, 'label': 'person', 'box': {'xmin': 1589, 'ymin': 885, 'xmax': 2129, 'ymax': 2847}}, {'score': 0.8264105916023254, 'label': 'handbag', 'box': {'xmin': 2219, 'ymin': 1433, 'xmax': 2518, 'ymax': 2048}}, {'score': 0.9995189905166626, 'label': 'person', 'box': {'xmin': 1121, 'ymin': 954, 'xmax': 1714, 'ymax': 3045}}, {'score': 0.9984346032142639, 'label': 'person', 'box': {'xmin': 2053, 'ymin': 1057, 'xmax': 2487, 'ymax': 2814}}, {'score': 0.9997161030769348, 'label': 'person', 'box': {'xmin': 2475, 'ymin': 985, 'xmax': 3029, 'ymax': 3010}}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "'''\n",
    "Object Detection by Hugging Face Transformers\n",
    "it uses default model as\n",
    "defaulted to facebook/detr-resnet-50\n",
    "'''\n",
    "generator = pipeline(\"object-detection\") # Initialize object-detection pipeline, this will choose default lib\n",
    "detector= generator(\"./Images/friends.jpg\") # Pass input text to the generator\n",
    "print(detector) # Print the result, and Thats it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e19ed0ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "score: 0.9101607799530029\n",
      "label: handbag\n",
      "score: 0.7946154475212097\n",
      "label: handbag\n",
      "score: 0.9989677667617798\n",
      "label: person\n",
      "score: 0.8264105916023254\n",
      "label: handbag\n",
      "score: 0.9995189905166626\n",
      "label: person\n",
      "score: 0.9984346032142639\n",
      "label: person\n",
      "score: 0.9997161030769348\n",
      "label: person\n"
     ]
    }
   ],
   "source": [
    "print(len(detector))\n",
    "for obj in detector:\n",
    "    for key, value in obj.items():\n",
    "        if key == \"label\":\n",
    "            i = 0\n",
    "            print(f\"{key}: {value}\")\n",
    "        if key == \"score\":\n",
    "            print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd6aa12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
