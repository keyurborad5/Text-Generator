{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20e9988f",
   "metadata": {},
   "source": [
    "# LLama 3\n",
    "- Text to Text generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dabc0ca2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpy\n",
      "  Using cached numpy-2.3.2-cp311-cp311-win_amd64.whl.metadata (60 kB)\n",
      "Using cached numpy-2.3.2-cp311-cp311-win_amd64.whl (13.1 MB)\n",
      "Installing collected packages: numpy\n",
      "Successfully installed numpy-2.3.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15a1be7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.55.3-py3-none-any.whl.metadata (41 kB)\n",
      "Collecting filelock (from transformers)\n",
      "  Using cached filelock-3.19.1-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting huggingface-hub<1.0,>=0.34.0 (from transformers)\n",
      "  Using cached huggingface_hub-0.34.4-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in d:\\ai_text_generator\\llama\\lib\\site-packages (from transformers) (2.3.2)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\ai_text_generator\\llama\\lib\\site-packages (from transformers) (25.0)\n",
      "Collecting pyyaml>=5.1 (from transformers)\n",
      "  Using cached PyYAML-6.0.2-cp311-cp311-win_amd64.whl.metadata (2.1 kB)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Using cached regex-2025.7.34-cp311-cp311-win_amd64.whl.metadata (41 kB)\n",
      "Collecting requests (from transformers)\n",
      "  Using cached requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers)\n",
      "  Using cached tokenizers-0.21.4-cp39-abi3-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers)\n",
      "  Using cached safetensors-0.6.2-cp38-abi3-win_amd64.whl.metadata (4.1 kB)\n",
      "Collecting tqdm>=4.27 (from transformers)\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub<1.0,>=0.34.0->transformers)\n",
      "  Using cached fsspec-2025.7.0-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in d:\\ai_text_generator\\llama\\lib\\site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.14.1)\n",
      "Requirement already satisfied: colorama in d:\\ai_text_generator\\llama\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Collecting charset_normalizer<4,>=2 (from requests->transformers)\n",
      "  Using cached charset_normalizer-3.4.3-cp311-cp311-win_amd64.whl.metadata (37 kB)\n",
      "Collecting idna<4,>=2.5 (from requests->transformers)\n",
      "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests->transformers)\n",
      "  Using cached urllib3-2.5.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests->transformers)\n",
      "  Using cached certifi-2025.8.3-py3-none-any.whl.metadata (2.4 kB)\n",
      "Downloading transformers-4.55.3-py3-none-any.whl (11.3 MB)\n",
      "   ---------------------------------------- 0.0/11.3 MB ? eta -:--:--\n",
      "   ---------------- ----------------------- 4.7/11.3 MB 47.4 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 9.4/11.3 MB 25.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.3/11.3 MB 24.3 MB/s  0:00:00\n",
      "Using cached huggingface_hub-0.34.4-py3-none-any.whl (561 kB)\n",
      "Using cached tokenizers-0.21.4-cp39-abi3-win_amd64.whl (2.5 MB)\n",
      "Using cached fsspec-2025.7.0-py3-none-any.whl (199 kB)\n",
      "Using cached PyYAML-6.0.2-cp311-cp311-win_amd64.whl (161 kB)\n",
      "Using cached regex-2025.7.34-cp311-cp311-win_amd64.whl (276 kB)\n",
      "Using cached safetensors-0.6.2-cp38-abi3-win_amd64.whl (320 kB)\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Using cached filelock-3.19.1-py3-none-any.whl (15 kB)\n",
      "Using cached requests-2.32.5-py3-none-any.whl (64 kB)\n",
      "Using cached charset_normalizer-3.4.3-cp311-cp311-win_amd64.whl (107 kB)\n",
      "Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
      "Using cached urllib3-2.5.0-py3-none-any.whl (129 kB)\n",
      "Using cached certifi-2025.8.3-py3-none-any.whl (161 kB)\n",
      "Installing collected packages: urllib3, tqdm, safetensors, regex, pyyaml, idna, fsspec, filelock, charset_normalizer, certifi, requests, huggingface-hub, tokenizers, transformers\n",
      "\n",
      "   ----------------------------------------  0/14 [urllib3]\n",
      "   ----------------------------------------  0/14 [urllib3]\n",
      "   ----------------------------------------  0/14 [urllib3]\n",
      "   ----------------------------------------  0/14 [urllib3]\n",
      "   ----------------------------------------  0/14 [urllib3]\n",
      "   -- -------------------------------------  1/14 [tqdm]\n",
      "   -- -------------------------------------  1/14 [tqdm]\n",
      "   -- -------------------------------------  1/14 [tqdm]\n",
      "   -- -------------------------------------  1/14 [tqdm]\n",
      "   -- -------------------------------------  1/14 [tqdm]\n",
      "   -------- -------------------------------  3/14 [regex]\n",
      "   -------- -------------------------------  3/14 [regex]\n",
      "   ----------- ----------------------------  4/14 [pyyaml]\n",
      "   ----------- ----------------------------  4/14 [pyyaml]\n",
      "   ----------------- ----------------------  6/14 [fsspec]\n",
      "   ----------------- ----------------------  6/14 [fsspec]\n",
      "   ----------------- ----------------------  6/14 [fsspec]\n",
      "   ----------------- ----------------------  6/14 [fsspec]\n",
      "   ----------------- ----------------------  6/14 [fsspec]\n",
      "   ----------------- ----------------------  6/14 [fsspec]\n",
      "   ----------------- ----------------------  6/14 [fsspec]\n",
      "   ----------------- ----------------------  6/14 [fsspec]\n",
      "   -------------------- -------------------  7/14 [filelock]\n",
      "   ---------------------- -----------------  8/14 [charset_normalizer]\n",
      "   ---------------------- -----------------  8/14 [charset_normalizer]\n",
      "   ---------------------------- ----------- 10/14 [requests]\n",
      "   ---------------------------- ----------- 10/14 [requests]\n",
      "   ------------------------------- -------- 11/14 [huggingface-hub]\n",
      "   ------------------------------- -------- 11/14 [huggingface-hub]\n",
      "   ------------------------------- -------- 11/14 [huggingface-hub]\n",
      "   ------------------------------- -------- 11/14 [huggingface-hub]\n",
      "   ------------------------------- -------- 11/14 [huggingface-hub]\n",
      "   ------------------------------- -------- 11/14 [huggingface-hub]\n",
      "   ------------------------------- -------- 11/14 [huggingface-hub]\n",
      "   ------------------------------- -------- 11/14 [huggingface-hub]\n",
      "   ------------------------------- -------- 11/14 [huggingface-hub]\n",
      "   ------------------------------- -------- 11/14 [huggingface-hub]\n",
      "   ------------------------------- -------- 11/14 [huggingface-hub]\n",
      "   ------------------------------- -------- 11/14 [huggingface-hub]\n",
      "   ------------------------------- -------- 11/14 [huggingface-hub]\n",
      "   ------------------------------- -------- 11/14 [huggingface-hub]\n",
      "   ------------------------------- -------- 11/14 [huggingface-hub]\n",
      "   ------------------------------- -------- 11/14 [huggingface-hub]\n",
      "   ------------------------------- -------- 11/14 [huggingface-hub]\n",
      "   ------------------------------- -------- 11/14 [huggingface-hub]\n",
      "   ------------------------------- -------- 11/14 [huggingface-hub]\n",
      "   ------------------------------- -------- 11/14 [huggingface-hub]\n",
      "   ------------------------------- -------- 11/14 [huggingface-hub]\n",
      "   ------------------------------- -------- 11/14 [huggingface-hub]\n",
      "   ------------------------------- -------- 11/14 [huggingface-hub]\n",
      "   ---------------------------------- ----- 12/14 [tokenizers]\n",
      "   ---------------------------------- ----- 12/14 [tokenizers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ---------------------------------------- 14/14 [transformers]\n",
      "\n",
      "Successfully installed certifi-2025.8.3 charset_normalizer-3.4.3 filelock-3.19.1 fsspec-2025.7.0 huggingface-hub-0.34.4 idna-3.10 pyyaml-6.0.2 regex-2025.7.34 requests-2.32.5 safetensors-0.6.2 tokenizers-0.21.4 tqdm-4.67.1 transformers-4.55.3 urllib3-2.5.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8ef6033",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\AI_TEXt_Generator\\llama\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Fetching 4 files:   0%|          | 0/4 [00:00<?, ?it/s]d:\\AI_TEXt_Generator\\llama\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\keyur\\.cache\\huggingface\\hub\\models--meta-llama--Meta-Llama-3.1-8B-Instruct. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Fetching 4 files: 100%|██████████| 4/4 [03:01<00:00, 45.35s/it] \n",
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:04<00:00,  1.16s/it]\n",
      "Some parameters are on the meta device because they were offloaded to the disk and cpu.\n",
      "Device set to use cuda:0\n",
      "d:\\AI_TEXt_Generator\\llama\\Lib\\site-packages\\transformers\\modeling_utils.py:3974: UserWarning: Attempting to save a model with offloaded modules. Ensure that unallocated cpu memory exceeds the `shard_size` (5GB default)\n",
      "  warnings.warn(\n",
      "Saving checkpoint shards: 100%|██████████| 4/4 [00:29<00:00,  7.32s/it]\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "import torch\n",
    "\n",
    "model_id = \"meta-llama/Meta-Llama-3.1-8B-Instruct\"\n",
    "\n",
    "pipeline = transformers.pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model_id,\n",
    "    model_kwargs={\"torch_dtype\": torch.bfloat16},\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "\n",
    "pipeline.save_pretrained(\"./SavedModels/llama3.1-Instruct\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a89282",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting hf_xet\n",
      "  Downloading hf_xet-1.1.8-cp37-abi3-win_amd64.whl.metadata (703 bytes)\n",
      "Downloading hf_xet-1.1.8-cp37-abi3-win_amd64.whl (2.8 MB)\n",
      "   ---------------------------------------- 0.0/2.8 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.8/2.8 MB 54.0 MB/s  0:00:00\n",
      "Installing collected packages: hf_xet\n",
      "Successfully installed hf_xet-1.1.8\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install hf_xet\n",
    "pip install acclelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9981ff17",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\AI_TEXt_Generator\\llama\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:07<00:00,  1.90s/it]\n",
      "Some parameters are on the meta device because they were offloaded to the cpu.\n",
      "Device set to use cuda:0\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'role': 'assistant', 'content': \"I'm a mechanical engineer with a strong background in designing and developing mechanical systems, products, and processes. My areas of expertise include mechanical design, thermal systems, fluid mechanics, and manufacturing. \\n\\nI hold a degree in Mechanical Engineering and have years of experience working on various projects, from concept design to prototype testing and production implementation. My work involves applying principles of mechanics, thermodynamics, and materials science to create innovative solutions for real-world problems.\\n\\nI'm also passionate about staying up-to-date with the latest technologies and advancements in the field, including the use of computer-aided design (CAD) software, finite element analysis (FEA), and computational fluid dynamics (CFD).\"}\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "import torch\n",
    "\n",
    "model_id = \"./SavedModels/llama3.1-Instruct\"\n",
    "\n",
    "pipeline = transformers.pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model_id,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "\n",
    "# pipeline.save_pretrained(\"./SavedModels/llama3.1-Instruct\")\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a mechanical engineer\"},\n",
    "    {\"role\": \"user\", \"content\": \"Who are you?\"},\n",
    "]\n",
    "outputs = pipeline(\n",
    "    messages,\n",
    "    max_new_tokens=256,\n",
    ")\n",
    "print(outputs[0][\"generated_text\"][-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48f5bd5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'role': 'assistant', 'content': \"When selecting a drive motor for an Electric Vehicle (EV), several key factors need to be considered. Here are some of the most important ones:\\n\\n1. **Power Output**: The motor should be able to produce the required torque and power to propel the vehicle at various speeds and loads. The power output is typically measured in kilowatts (kW) or horsepower (hp).\\n\\n2. **Torque Characteristics**: The motor should be able to produce sufficient torque at low speeds to accelerate the vehicle from a standstill and to provide good low-speed maneuverability.\\n\\n3. **Efficiency**: The motor should be highly efficient to minimize energy losses and maximize the vehicle's range. Efficiency is typically measured as a percentage.\\n\\n4. **Speed Range**: The motor should be able to operate over a wide speed range, from low speeds (e.g., 0-10 km/h) to high speeds (e.g., 150-200 km/h).\\n\\n5. **Weight and Packaging**: The motor should be lightweight and compact to minimize the vehicle's overall weight and to optimize packaging.\\n\\n6. **Cooling System**: The motor should have an efficient cooling system to prevent overheating and to ensure reliable operation.\\n\\n7. **Reliability and Durability**: The motor should be designed to\"}\n"
     ]
    }
   ],
   "source": [
    "# pipeline.save_pretrained(\"./SavedModels/llama3.1-Instruct\")\n",
    "messages = [\n",
    "    \n",
    "    {\"role\": \"user\", \"content\": \"Great now tell me what factors to be considered while selecting a drive motor for EV?\"},\n",
    "]\n",
    "outputs = pipeline(\n",
    "    messages,\n",
    "    max_new_tokens=256,\n",
    ")\n",
    "print(outputs[0][\"generated_text\"][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25d52c67",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\AI_TEXt_Generator\\llama\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ASTConfig', 'ASTFeatureExtractor', 'ASTForAudioClassification', 'ASTModel', 'ASTPreTrainedModel', 'Adafactor', 'AdamWeightDecay', 'AdaptiveEmbedding', 'AddedToken', 'Aimv2Config', 'Aimv2Model', 'Aimv2PreTrainedModel', 'Aimv2TextConfig', 'Aimv2TextModel', 'Aimv2VisionConfig', 'Aimv2VisionModel', 'AlbertConfig', 'AlbertForMaskedLM', 'AlbertForMultipleChoice', 'AlbertForPreTraining', 'AlbertForQuestionAnswering', 'AlbertForSequenceClassification', 'AlbertForTokenClassification', 'AlbertModel', 'AlbertOnnxConfig', 'AlbertPreTrainedModel', 'AlbertTokenizer', 'AlbertTokenizerFast', 'AlignConfig', 'AlignModel', 'AlignPreTrainedModel', 'AlignProcessor', 'AlignTextConfig', 'AlignTextModel', 'AlignVisionConfig', 'AlignVisionModel', 'AltCLIPConfig', 'AltCLIPModel', 'AltCLIPPreTrainedModel', 'AltCLIPProcessor', 'AltCLIPTextConfig', 'AltCLIPTextModel', 'AltCLIPVisionConfig', 'AltCLIPVisionModel', 'AlternatingCodebooksLogitsProcessor', 'AqlmConfig', 'ArceeConfig', 'ArceeForCausalLM', 'ArceeForQuestionAnswering', 'ArceeForSequenceClassification', 'ArceeForTokenClassification', 'ArceeModel', 'ArceePreTrainedModel', 'AriaConfig', 'AriaForConditionalGeneration', 'AriaImageProcessor', 'AriaModel', 'AriaPreTrainedModel', 'AriaProcessor', 'AriaTextConfig', 'AriaTextForCausalLM', 'AriaTextModel', 'AriaTextPreTrainedModel', 'AsyncTextIteratorStreamer', 'AttentionInterface', 'AttentionMaskInterface', 'AudioClassificationPipeline', 'AutoBackbone', 'AutoConfig', 'AutoFeatureExtractor', 'AutoImageProcessor', 'AutoModel', 'AutoModelForAudioClassification', 'AutoModelForAudioFrameClassification', 'AutoModelForAudioTokenization', 'AutoModelForAudioXVector', 'AutoModelForCTC', 'AutoModelForCausalLM', 'AutoModelForDepthEstimation', 'AutoModelForDocumentQuestionAnswering', 'AutoModelForImageClassification', 'AutoModelForImageSegmentation', 'AutoModelForImageTextToText', 'AutoModelForImageToImage', 'AutoModelForInstanceSegmentation', 'AutoModelForKeypointDetection', 'AutoModelForKeypointMatching', 'AutoModelForMaskGeneration', 'AutoModelForMaskedImageModeling', 'AutoModelForMaskedLM', 'AutoModelForMultipleChoice', 'AutoModelForNextSentencePrediction', 'AutoModelForObjectDetection', 'AutoModelForPreTraining', 'AutoModelForQuestionAnswering', 'AutoModelForSemanticSegmentation', 'AutoModelForSeq2SeqLM', 'AutoModelForSequenceClassification', 'AutoModelForSpeechSeq2Seq', 'AutoModelForTableQuestionAnswering', 'AutoModelForTextEncoding', 'AutoModelForTextToSpectrogram', 'AutoModelForTextToWaveform', 'AutoModelForTimeSeriesPrediction', 'AutoModelForTokenClassification', 'AutoModelForUniversalSegmentation', 'AutoModelForVideoClassification', 'AutoModelForVision2Seq', 'AutoModelForVisualQuestionAnswering', 'AutoModelForZeroShotImageClassification', 'AutoModelForZeroShotObjectDetection', 'AutoModelWithLMHead', 'AutoProcessor', 'AutoRoundConfig', 'AutoTokenizer', 'AutoVideoProcessor', 'AutoformerConfig', 'AutoformerForPrediction', 'AutoformerModel', 'AutoformerPreTrainedModel', 'AutomaticSpeechRecognitionPipeline', 'AwqConfig', 'AyaVisionConfig', 'AyaVisionForConditionalGeneration', 'AyaVisionModel', 'AyaVisionPreTrainedModel', 'AyaVisionProcessor', 'BambaConfig', 'BambaForCausalLM', 'BambaModel', 'BambaPreTrainedModel', 'BarkCausalModel', 'BarkCoarseConfig', 'BarkCoarseModel', 'BarkConfig', 'BarkFineConfig', 'BarkFineModel', 'BarkModel', 'BarkPreTrainedModel', 'BarkProcessor', 'BarkSemanticConfig', 'BarkSemanticModel', 'BartConfig', 'BartForCausalLM', 'BartForConditionalGeneration', 'BartForQuestionAnswering', 'BartForSequenceClassification', 'BartModel', 'BartOnnxConfig', 'BartPreTrainedModel', 'BartPretrainedModel', 'BartTokenizer', 'BartTokenizerFast', 'BarthezTokenizer', 'BarthezTokenizerFast', 'BartphoTokenizer', 'BaseImageProcessor', 'BaseImageProcessorFast', 'BaseVideoProcessor', 'BasicTokenizer', 'BatchEncoding', 'BatchFeature', 'BayesianDetectorConfig', 'BayesianDetectorModel', 'BeamScorer', 'BeamSearchScorer', 'BeitBackbone', 'BeitConfig', 'BeitFeatureExtractor', 'BeitForImageClassification', 'BeitForMaskedImageModeling', 'BeitForSemanticSegmentation', 'BeitImageProcessor', 'BeitImageProcessorFast', 'BeitModel', 'BeitOnnxConfig', 'BeitPreTrainedModel', 'BertConfig', 'BertForMaskedLM', 'BertForMultipleChoice', 'BertForNextSentencePrediction', 'BertForPreTraining', 'BertForQuestionAnswering', 'BertForSequenceClassification', 'BertForTokenClassification', 'BertGenerationConfig', 'BertGenerationDecoder', 'BertGenerationEncoder', 'BertGenerationPreTrainedModel', 'BertGenerationTokenizer', 'BertJapaneseTokenizer', 'BertLMHeadModel', 'BertLayer', 'BertModel', 'BertOnnxConfig', 'BertPreTrainedModel', 'BertTokenizer', 'BertTokenizerFast', 'BertweetTokenizer', 'BigBirdConfig', 'BigBirdForCausalLM', 'BigBirdForMaskedLM', 'BigBirdForMultipleChoice', 'BigBirdForPreTraining', 'BigBirdForQuestionAnswering', 'BigBirdForSequenceClassification', 'BigBirdForTokenClassification', 'BigBirdLayer', 'BigBirdModel', 'BigBirdOnnxConfig', 'BigBirdPegasusConfig', 'BigBirdPegasusForCausalLM', 'BigBirdPegasusForConditionalGeneration', 'BigBirdPegasusForQuestionAnswering', 'BigBirdPegasusForSequenceClassification', 'BigBirdPegasusModel', 'BigBirdPegasusOnnxConfig', 'BigBirdPegasusPreTrainedModel', 'BigBirdPreTrainedModel', 'BigBirdTokenizer', 'BigBirdTokenizerFast', 'BioGptConfig', 'BioGptForCausalLM', 'BioGptForSequenceClassification', 'BioGptForTokenClassification', 'BioGptModel', 'BioGptPreTrainedModel', 'BioGptTokenizer', 'BitBackbone', 'BitConfig', 'BitForImageClassification', 'BitImageProcessor', 'BitImageProcessorFast', 'BitModel', 'BitNetConfig', 'BitNetForCausalLM', 'BitNetModel', 'BitNetPreTrainedModel', 'BitNetQuantConfig', 'BitPreTrainedModel', 'BitsAndBytesConfig', 'BlenderbotConfig', 'BlenderbotForCausalLM', 'BlenderbotForConditionalGeneration', 'BlenderbotModel', 'BlenderbotOnnxConfig', 'BlenderbotPreTrainedModel', 'BlenderbotSmallConfig', 'BlenderbotSmallForCausalLM', 'BlenderbotSmallForConditionalGeneration', 'BlenderbotSmallModel', 'BlenderbotSmallOnnxConfig', 'BlenderbotSmallPreTrainedModel', 'BlenderbotSmallTokenizer', 'BlenderbotSmallTokenizerFast', 'BlenderbotTokenizer', 'BlenderbotTokenizerFast', 'Blip2Config', 'Blip2ForConditionalGeneration', 'Blip2ForImageTextRetrieval', 'Blip2Model', 'Blip2PreTrainedModel', 'Blip2Processor', 'Blip2QFormerConfig', 'Blip2QFormerModel', 'Blip2TextModelWithProjection', 'Blip2VisionConfig', 'Blip2VisionModel', 'Blip2VisionModelWithProjection', 'BlipConfig', 'BlipForConditionalGeneration', 'BlipForImageTextRetrieval', 'BlipForQuestionAnswering', 'BlipImageProcessor', 'BlipImageProcessorFast', 'BlipModel', 'BlipPreTrainedModel', 'BlipProcessor', 'BlipTextConfig', 'BlipTextLMHeadModel', 'BlipTextModel', 'BlipTextPreTrainedModel', 'BlipVisionConfig', 'BlipVisionModel', 'BloomConfig', 'BloomForCausalLM', 'BloomForQuestionAnswering', 'BloomForSequenceClassification', 'BloomForTokenClassification', 'BloomModel', 'BloomOnnxConfig', 'BloomPreTrainedModel', 'BloomTokenizerFast', 'BridgeTowerConfig', 'BridgeTowerForContrastiveLearning', 'BridgeTowerForImageAndTextRetrieval', 'BridgeTowerForMaskedLM', 'BridgeTowerImageProcessor', 'BridgeTowerImageProcessorFast', 'BridgeTowerModel', 'BridgeTowerPreTrainedModel', 'BridgeTowerProcessor', 'BridgeTowerTextConfig', 'BridgeTowerVisionConfig', 'BrosConfig', 'BrosForTokenClassification', 'BrosModel', 'BrosPreTrainedModel', 'BrosProcessor', 'BrosSpadeEEForTokenClassification', 'BrosSpadeELForTokenClassification', 'ByT5Tokenizer', 'CLIPConfig', 'CLIPFeatureExtractor', 'CLIPForImageClassification', 'CLIPImageProcessor', 'CLIPImageProcessorFast', 'CLIPModel', 'CLIPOnnxConfig', 'CLIPPreTrainedModel', 'CLIPProcessor', 'CLIPSegConfig', 'CLIPSegForImageSegmentation', 'CLIPSegModel', 'CLIPSegPreTrainedModel', 'CLIPSegProcessor', 'CLIPSegTextConfig', 'CLIPSegTextModel', 'CLIPSegVisionConfig', 'CLIPSegVisionModel', 'CLIPTextConfig', 'CLIPTextModel', 'CLIPTextModelWithProjection', 'CLIPTokenizer', 'CLIPTokenizerFast', 'CLIPVisionConfig', 'CLIPVisionModel', 'CLIPVisionModelWithProjection', 'CONFIG_MAPPING', 'CONFIG_NAME', 'CTRLConfig', 'CTRLForSequenceClassification', 'CTRLLMHeadModel', 'CTRLModel', 'CTRLPreTrainedModel', 'CTRLTokenizer', 'Cache', 'CacheConfig', 'CacheLayerMixin', 'CacheProcessor', 'CamembertConfig', 'CamembertForCausalLM', 'CamembertForMaskedLM', 'CamembertForMultipleChoice', 'CamembertForQuestionAnswering', 'CamembertForSequenceClassification', 'CamembertForTokenClassification', 'CamembertModel', 'CamembertOnnxConfig', 'CamembertPreTrainedModel', 'CamembertTokenizer', 'CamembertTokenizerFast', 'CanineConfig', 'CanineForMultipleChoice', 'CanineForQuestionAnswering', 'CanineForSequenceClassification', 'CanineForTokenClassification', 'CanineLayer', 'CanineModel', 'CaninePreTrainedModel', 'CanineTokenizer', 'ChameleonConfig', 'ChameleonForConditionalGeneration', 'ChameleonImageProcessor', 'ChameleonImageProcessorFast', 'ChameleonModel', 'ChameleonPreTrainedModel', 'ChameleonProcessor', 'ChameleonVQVAE', 'ChameleonVQVAEConfig', 'CharSpan', 'CharacterTokenizer', 'ChineseCLIPConfig', 'ChineseCLIPFeatureExtractor', 'ChineseCLIPImageProcessor', 'ChineseCLIPImageProcessorFast', 'ChineseCLIPModel', 'ChineseCLIPOnnxConfig', 'ChineseCLIPPreTrainedModel', 'ChineseCLIPProcessor', 'ChineseCLIPTextConfig', 'ChineseCLIPTextModel', 'ChineseCLIPVisionConfig', 'ChineseCLIPVisionModel', 'ChunkedSlidingLayer', 'ClapAudioConfig', 'ClapAudioModel', 'ClapAudioModelWithProjection', 'ClapConfig', 'ClapFeatureExtractor', 'ClapModel', 'ClapPreTrainedModel', 'ClapProcessor', 'ClapTextConfig', 'ClapTextModel', 'ClapTextModelWithProjection', 'ClassifierFreeGuidanceLogitsProcessor', 'ClvpConfig', 'ClvpDecoder', 'ClvpDecoderConfig', 'ClvpEncoder', 'ClvpEncoderConfig', 'ClvpFeatureExtractor', 'ClvpForCausalLM', 'ClvpModel', 'ClvpModelForConditionalGeneration', 'ClvpPreTrainedModel', 'ClvpProcessor', 'ClvpTokenizer', 'CodeGenConfig', 'CodeGenForCausalLM', 'CodeGenModel', 'CodeGenOnnxConfig', 'CodeGenPreTrainedModel', 'CodeGenTokenizer', 'CodeGenTokenizerFast', 'CodeLlamaTokenizer', 'CodeLlamaTokenizerFast', 'Cohere2Config', 'Cohere2ForCausalLM', 'Cohere2Model', 'Cohere2PreTrainedModel', 'Cohere2VisionConfig', 'Cohere2VisionForConditionalGeneration', 'Cohere2VisionImageProcessorFast', 'Cohere2VisionModel', 'Cohere2VisionPreTrainedModel', 'Cohere2VisionProcessor', 'CohereConfig', 'CohereForCausalLM', 'CohereModel', 'CoherePreTrainedModel', 'CohereTokenizerFast', 'ColPaliConfig', 'ColPaliForRetrieval', 'ColPaliPreTrainedModel', 'ColPaliProcessor', 'ColQwen2Config', 'ColQwen2ForRetrieval', 'ColQwen2PreTrainedModel', 'ColQwen2Processor', 'CompileConfig', 'CompressedTensorsConfig', 'ConditionalDetrConfig', 'ConditionalDetrFeatureExtractor', 'ConditionalDetrForObjectDetection', 'ConditionalDetrForSegmentation', 'ConditionalDetrImageProcessor', 'ConditionalDetrImageProcessorFast', 'ConditionalDetrModel', 'ConditionalDetrOnnxConfig', 'ConditionalDetrPreTrainedModel', 'ConstrainedBeamSearchScorer', 'Constraint', 'ConstraintListState', 'Conv1D', 'ConvBertConfig', 'ConvBertForMaskedLM', 'ConvBertForMultipleChoice', 'ConvBertForQuestionAnswering', 'ConvBertForSequenceClassification', 'ConvBertForTokenClassification', 'ConvBertLayer', 'ConvBertModel', 'ConvBertOnnxConfig', 'ConvBertPreTrainedModel', 'ConvBertTokenizer', 'ConvBertTokenizerFast', 'ConvNextBackbone', 'ConvNextConfig', 'ConvNextFeatureExtractor', 'ConvNextForImageClassification', 'ConvNextImageProcessor', 'ConvNextImageProcessorFast', 'ConvNextModel', 'ConvNextOnnxConfig', 'ConvNextPreTrainedModel', 'ConvNextV2Backbone', 'ConvNextV2Config', 'ConvNextV2ForImageClassification', 'ConvNextV2Model', 'ConvNextV2PreTrainedModel', 'CpmAntConfig', 'CpmAntForCausalLM', 'CpmAntModel', 'CpmAntPreTrainedModel', 'CpmAntTokenizer', 'CpmTokenizer', 'CpmTokenizerFast', 'CsmBackboneModel', 'CsmConfig', 'CsmDepthDecoderConfig', 'CsmDepthDecoderForCausalLM', 'CsmDepthDecoderModel', 'CsmForConditionalGeneration', 'CsmPreTrainedModel', 'CsmProcessor', 'CsvPipelineDataFormat', 'CvtConfig', 'CvtForImageClassification', 'CvtModel', 'CvtPreTrainedModel', 'DFineConfig', 'DFineForObjectDetection', 'DFineModel', 'DFinePreTrainedModel', 'DPRConfig', 'DPRContextEncoder', 'DPRContextEncoderTokenizer', 'DPRContextEncoderTokenizerFast', 'DPRPreTrainedModel', 'DPRPretrainedContextEncoder', 'DPRPretrainedQuestionEncoder', 'DPRPretrainedReader', 'DPRQuestionEncoder', 'DPRQuestionEncoderTokenizer', 'DPRQuestionEncoderTokenizerFast', 'DPRReader', 'DPRReaderOutput', 'DPRReaderTokenizer', 'DPRReaderTokenizerFast', 'DPTConfig', 'DPTFeatureExtractor', 'DPTForDepthEstimation', 'DPTForSemanticSegmentation', 'DPTImageProcessor', 'DPTImageProcessorFast', 'DPTModel', 'DPTPreTrainedModel', 'DabDetrConfig', 'DabDetrForObjectDetection', 'DabDetrModel', 'DabDetrPreTrainedModel', 'DacConfig', 'DacFeatureExtractor', 'DacModel', 'DacPreTrainedModel', 'Data2VecAudioConfig', 'Data2VecAudioForAudioFrameClassification', 'Data2VecAudioForCTC', 'Data2VecAudioForSequenceClassification', 'Data2VecAudioForXVector', 'Data2VecAudioModel', 'Data2VecAudioPreTrainedModel', 'Data2VecTextConfig', 'Data2VecTextForCausalLM', 'Data2VecTextForMaskedLM', 'Data2VecTextForMultipleChoice', 'Data2VecTextForQuestionAnswering', 'Data2VecTextForSequenceClassification', 'Data2VecTextForTokenClassification', 'Data2VecTextModel', 'Data2VecTextOnnxConfig', 'Data2VecTextPreTrainedModel', 'Data2VecVisionConfig', 'Data2VecVisionForImageClassification', 'Data2VecVisionForSemanticSegmentation', 'Data2VecVisionModel', 'Data2VecVisionOnnxConfig', 'Data2VecVisionPreTrainedModel', 'DataCollator', 'DataCollatorForLanguageModeling', 'DataCollatorForMultipleChoice', 'DataCollatorForPermutationLanguageModeling', 'DataCollatorForSOP', 'DataCollatorForSeq2Seq', 'DataCollatorForTokenClassification', 'DataCollatorForWholeWordMask', 'DataCollatorWithFlattening', 'DataCollatorWithPadding', 'DataProcessor', 'DbrxConfig', 'DbrxForCausalLM', 'DbrxModel', 'DbrxPreTrainedModel', 'DebertaConfig', 'DebertaForMaskedLM', 'DebertaForQuestionAnswering', 'DebertaForSequenceClassification', 'DebertaForTokenClassification', 'DebertaModel', 'DebertaOnnxConfig', 'DebertaPreTrainedModel', 'DebertaTokenizer', 'DebertaTokenizerFast', 'DebertaV2Config', 'DebertaV2ForMaskedLM', 'DebertaV2ForMultipleChoice', 'DebertaV2ForQuestionAnswering', 'DebertaV2ForSequenceClassification', 'DebertaV2ForTokenClassification', 'DebertaV2Model', 'DebertaV2OnnxConfig', 'DebertaV2PreTrainedModel', 'DebertaV2Tokenizer', 'DebertaV2TokenizerFast', 'DecisionTransformerConfig', 'DecisionTransformerGPT2Model', 'DecisionTransformerGPT2PreTrainedModel', 'DecisionTransformerModel', 'DecisionTransformerPreTrainedModel', 'DeepseekV2Config', 'DeepseekV2ForCausalLM', 'DeepseekV2ForSequenceClassification', 'DeepseekV2Model', 'DeepseekV2PreTrainedModel', 'DeepseekV3Config', 'DeepseekV3ForCausalLM', 'DeepseekV3Model', 'DeepseekV3PreTrainedModel', 'DeepseekVLConfig', 'DeepseekVLForConditionalGeneration', 'DeepseekVLHybridConfig', 'DeepseekVLHybridForConditionalGeneration', 'DeepseekVLHybridImageProcessor', 'DeepseekVLHybridImageProcessorFast', 'DeepseekVLHybridModel', 'DeepseekVLHybridPreTrainedModel', 'DeepseekVLHybridProcessor', 'DeepseekVLImageProcessor', 'DeepseekVLImageProcessorFast', 'DeepseekVLModel', 'DeepseekVLPreTrainedModel', 'DeepseekVLProcessor', 'DefaultDataCollator', 'DefaultFlowCallback', 'DeformableDetrConfig', 'DeformableDetrFeatureExtractor', 'DeformableDetrForObjectDetection', 'DeformableDetrImageProcessor', 'DeformableDetrImageProcessorFast', 'DeformableDetrModel', 'DeformableDetrPreTrainedModel', 'DeiTConfig', 'DeiTFeatureExtractor', 'DeiTForImageClassification', 'DeiTForImageClassificationWithTeacher', 'DeiTForMaskedImageModeling', 'DeiTImageProcessor', 'DeiTImageProcessorFast', 'DeiTModel', 'DeiTOnnxConfig', 'DeiTPreTrainedModel', 'DepthAnythingConfig', 'DepthAnythingForDepthEstimation', 'DepthAnythingPreTrainedModel', 'DepthEstimationPipeline', 'DepthProConfig', 'DepthProForDepthEstimation', 'DepthProImageProcessor', 'DepthProImageProcessorFast', 'DepthProModel', 'DepthProPreTrainedModel', 'DetaConfig', 'DetaForObjectDetection', 'DetaImageProcessor', 'DetaModel', 'DetaPreTrainedModel', 'DetrConfig', 'DetrFeatureExtractor', 'DetrForObjectDetection', 'DetrForSegmentation', 'DetrImageProcessor', 'DetrImageProcessorFast', 'DetrModel', 'DetrOnnxConfig', 'DetrPreTrainedModel', 'DiaConfig', 'DiaDecoderConfig', 'DiaEncoderConfig', 'DiaFeatureExtractor', 'DiaForConditionalGeneration', 'DiaModel', 'DiaPreTrainedModel', 'DiaProcessor', 'DiaTokenizer', 'DiffLlamaConfig', 'DiffLlamaForCausalLM', 'DiffLlamaForQuestionAnswering', 'DiffLlamaForSequenceClassification', 'DiffLlamaForTokenClassification', 'DiffLlamaModel', 'DiffLlamaPreTrainedModel', 'DinatBackbone', 'DinatConfig', 'DinatForImageClassification', 'DinatModel', 'DinatPreTrainedModel', 'Dinov2Backbone', 'Dinov2Config', 'Dinov2ForImageClassification', 'Dinov2Model', 'Dinov2OnnxConfig', 'Dinov2PreTrainedModel', 'Dinov2WithRegistersBackbone', 'Dinov2WithRegistersConfig', 'Dinov2WithRegistersForImageClassification', 'Dinov2WithRegistersModel', 'Dinov2WithRegistersPreTrainedModel', 'DisjunctiveConstraint', 'DistilBertConfig', 'DistilBertForMaskedLM', 'DistilBertForMultipleChoice', 'DistilBertForQuestionAnswering', 'DistilBertForSequenceClassification', 'DistilBertForTokenClassification', 'DistilBertModel', 'DistilBertOnnxConfig', 'DistilBertPreTrainedModel', 'DistilBertTokenizer', 'DistilBertTokenizerFast', 'DocumentQuestionAnsweringPipeline', 'DogeConfig', 'DogeForCausalLM', 'DogeForSequenceClassification', 'DogeModel', 'DogePreTrainedModel', 'DonutFeatureExtractor', 'DonutImageProcessor', 'DonutImageProcessorFast', 'DonutProcessor', 'DonutSwinConfig', 'DonutSwinForImageClassification', 'DonutSwinModel', 'DonutSwinPreTrainedModel', 'Dots1Config', 'Dots1ForCausalLM', 'Dots1Model', 'Dots1PreTrainedModel', 'DummyObject', 'DynamicCache', 'DynamicLayer', 'EarlyStoppingCallback', 'EetqConfig', 'EfficientFormerConfig', 'EfficientFormerForImageClassification', 'EfficientFormerForImageClassificationWithTeacher', 'EfficientFormerImageProcessor', 'EfficientFormerModel', 'EfficientFormerPreTrainedModel', 'EfficientLoFTRConfig', 'EfficientLoFTRForKeypointMatching', 'EfficientLoFTRImageProcessor', 'EfficientLoFTRModel', 'EfficientLoFTRPreTrainedModel', 'EfficientNetConfig', 'EfficientNetForImageClassification', 'EfficientNetImageProcessor', 'EfficientNetImageProcessorFast', 'EfficientNetModel', 'EfficientNetOnnxConfig', 'EfficientNetPreTrainedModel', 'ElectraConfig', 'ElectraForCausalLM', 'ElectraForMaskedLM', 'ElectraForMultipleChoice', 'ElectraForPreTraining', 'ElectraForQuestionAnswering', 'ElectraForSequenceClassification', 'ElectraForTokenClassification', 'ElectraModel', 'ElectraOnnxConfig', 'ElectraPreTrainedModel', 'ElectraTokenizer', 'ElectraTokenizerFast', 'Emu3Config', 'Emu3ForCausalLM', 'Emu3ForConditionalGeneration', 'Emu3ImageProcessor', 'Emu3Model', 'Emu3PreTrainedModel', 'Emu3Processor', 'Emu3TextConfig', 'Emu3TextModel', 'Emu3VQVAE', 'Emu3VQVAEConfig', 'EncodecConfig', 'EncodecFeatureExtractor', 'EncodecModel', 'EncodecPreTrainedModel', 'EncoderDecoderCache', 'EncoderDecoderConfig', 'EncoderDecoderModel', 'EncoderNoRepeatNGramLogitsProcessor', 'EncoderRepetitionPenaltyLogitsProcessor', 'EomtConfig', 'EomtForUniversalSegmentation', 'EomtImageProcessor', 'EomtImageProcessorFast', 'EomtPreTrainedModel', 'EosTokenCriteria', 'EpsilonLogitsWarper', 'Ernie4_5Config', 'Ernie4_5ForCausalLM', 'Ernie4_5Model', 'Ernie4_5PreTrainedModel', 'Ernie4_5_MoeConfig', 'Ernie4_5_MoeForCausalLM', 'Ernie4_5_MoeModel', 'Ernie4_5_MoePreTrainedModel', 'ErnieConfig', 'ErnieForCausalLM', 'ErnieForMaskedLM', 'ErnieForMultipleChoice', 'ErnieForNextSentencePrediction', 'ErnieForPreTraining', 'ErnieForQuestionAnswering', 'ErnieForSequenceClassification', 'ErnieForTokenClassification', 'ErnieMConfig', 'ErnieMForInformationExtraction', 'ErnieMForMultipleChoice', 'ErnieMForQuestionAnswering', 'ErnieMForSequenceClassification', 'ErnieMForTokenClassification', 'ErnieMModel', 'ErnieMPreTrainedModel', 'ErnieMTokenizer', 'ErnieModel', 'ErnieOnnxConfig', 'ErniePreTrainedModel', 'EsmConfig', 'EsmFoldPreTrainedModel', 'EsmForMaskedLM', 'EsmForProteinFolding', 'EsmForSequenceClassification', 'EsmForTokenClassification', 'EsmModel', 'EsmPreTrainedModel', 'EsmTokenizer', 'EtaLogitsWarper', 'EvalPrediction', 'EvollaConfig', 'EvollaForProteinText2Text', 'EvollaModel', 'EvollaPreTrainedModel', 'EvollaProcessor', 'Exaone4Config', 'Exaone4ForCausalLM', 'Exaone4ForQuestionAnswering', 'Exaone4ForSequenceClassification', 'Exaone4ForTokenClassification', 'Exaone4Model', 'Exaone4PreTrainedModel', 'ExponentialDecayLengthPenalty', 'FEATURE_EXTRACTOR_MAPPING', 'FLAX_MODEL_FOR_AUDIO_CLASSIFICATION_MAPPING', 'FLAX_MODEL_FOR_CAUSAL_LM_MAPPING', 'FLAX_MODEL_FOR_IMAGE_CLASSIFICATION_MAPPING', 'FLAX_MODEL_FOR_MASKED_LM_MAPPING', 'FLAX_MODEL_FOR_MULTIPLE_CHOICE_MAPPING', 'FLAX_MODEL_FOR_NEXT_SENTENCE_PREDICTION_MAPPING', 'FLAX_MODEL_FOR_PRETRAINING_MAPPING', 'FLAX_MODEL_FOR_QUESTION_ANSWERING_MAPPING', 'FLAX_MODEL_FOR_SEQUENCE_CLASSIFICATION_MAPPING', 'FLAX_MODEL_FOR_SEQ_TO_SEQ_CAUSAL_LM_MAPPING', 'FLAX_MODEL_FOR_SPEECH_SEQ_2_SEQ_MAPPING', 'FLAX_MODEL_FOR_TOKEN_CLASSIFICATION_MAPPING', 'FLAX_MODEL_FOR_VISION_2_SEQ_MAPPING', 'FLAX_MODEL_MAPPING', 'FNetConfig', 'FNetForMaskedLM', 'FNetForMultipleChoice', 'FNetForNextSentencePrediction', 'FNetForPreTraining', 'FNetForQuestionAnswering', 'FNetForSequenceClassification', 'FNetForTokenClassification', 'FNetLayer', 'FNetModel', 'FNetPreTrainedModel', 'FNetTokenizer', 'FNetTokenizerFast', 'FPQuantConfig', 'FSMTConfig', 'FSMTForConditionalGeneration', 'FSMTModel', 'FSMTTokenizer', 'FalconConfig', 'FalconForCausalLM', 'FalconForQuestionAnswering', 'FalconForSequenceClassification', 'FalconForTokenClassification', 'FalconH1Config', 'FalconH1ForCausalLM', 'FalconH1Model', 'FalconH1PreTrainedModel', 'FalconMambaCache', 'FalconMambaConfig', 'FalconMambaForCausalLM', 'FalconMambaModel', 'FalconMambaPreTrainedModel', 'FalconModel', 'FalconPreTrainedModel', 'FastSpeech2ConformerConfig', 'FastSpeech2ConformerHifiGan', 'FastSpeech2ConformerHifiGanConfig', 'FastSpeech2ConformerModel', 'FastSpeech2ConformerPreTrainedModel', 'FastSpeech2ConformerTokenizer', 'FastSpeech2ConformerWithHifiGan', 'FastSpeech2ConformerWithHifiGanConfig', 'FbgemmFp8Config', 'FeatureExtractionMixin', 'FeatureExtractionPipeline', 'FillMaskPipeline', 'FineGrainedFP8Config', 'FlaubertConfig', 'FlaubertForMultipleChoice', 'FlaubertForQuestionAnswering', 'FlaubertForQuestionAnsweringSimple', 'FlaubertForSequenceClassification', 'FlaubertForTokenClassification', 'FlaubertModel', 'FlaubertOnnxConfig', 'FlaubertPreTrainedModel', 'FlaubertTokenizer', 'FlaubertWithLMHeadModel', 'FlavaConfig', 'FlavaFeatureExtractor', 'FlavaForPreTraining', 'FlavaImageCodebook', 'FlavaImageCodebookConfig', 'FlavaImageConfig', 'FlavaImageModel', 'FlavaImageProcessor', 'FlavaImageProcessorFast', 'FlavaModel', 'FlavaMultimodalConfig', 'FlavaMultimodalModel', 'FlavaPreTrainedModel', 'FlavaProcessor', 'FlavaTextConfig', 'FlavaTextModel', 'FlaxAlbertForMaskedLM', 'FlaxAlbertForMultipleChoice', 'FlaxAlbertForPreTraining', 'FlaxAlbertForQuestionAnswering', 'FlaxAlbertForSequenceClassification', 'FlaxAlbertForTokenClassification', 'FlaxAlbertModel', 'FlaxAlbertPreTrainedModel', 'FlaxAutoModel', 'FlaxAutoModelForCausalLM', 'FlaxAutoModelForImageClassification', 'FlaxAutoModelForMaskedLM', 'FlaxAutoModelForMultipleChoice', 'FlaxAutoModelForNextSentencePrediction', 'FlaxAutoModelForPreTraining', 'FlaxAutoModelForQuestionAnswering', 'FlaxAutoModelForSeq2SeqLM', 'FlaxAutoModelForSequenceClassification', 'FlaxAutoModelForSpeechSeq2Seq', 'FlaxAutoModelForTokenClassification', 'FlaxAutoModelForVision2Seq', 'FlaxBartDecoderPreTrainedModel', 'FlaxBartForCausalLM', 'FlaxBartForConditionalGeneration', 'FlaxBartForQuestionAnswering', 'FlaxBartForSequenceClassification', 'FlaxBartModel', 'FlaxBartPreTrainedModel', 'FlaxBeitForImageClassification', 'FlaxBeitForMaskedImageModeling', 'FlaxBeitModel', 'FlaxBeitPreTrainedModel', 'FlaxBertForCausalLM', 'FlaxBertForMaskedLM', 'FlaxBertForMultipleChoice', 'FlaxBertForNextSentencePrediction', 'FlaxBertForPreTraining', 'FlaxBertForQuestionAnswering', 'FlaxBertForSequenceClassification', 'FlaxBertForTokenClassification', 'FlaxBertModel', 'FlaxBertPreTrainedModel', 'FlaxBigBirdForCausalLM', 'FlaxBigBirdForMaskedLM', 'FlaxBigBirdForMultipleChoice', 'FlaxBigBirdForPreTraining', 'FlaxBigBirdForQuestionAnswering', 'FlaxBigBirdForSequenceClassification', 'FlaxBigBirdForTokenClassification', 'FlaxBigBirdModel', 'FlaxBigBirdPreTrainedModel', 'FlaxBlenderbotForConditionalGeneration', 'FlaxBlenderbotModel', 'FlaxBlenderbotPreTrainedModel', 'FlaxBlenderbotSmallForConditionalGeneration', 'FlaxBlenderbotSmallModel', 'FlaxBlenderbotSmallPreTrainedModel', 'FlaxBloomForCausalLM', 'FlaxBloomModel', 'FlaxBloomPreTrainedModel', 'FlaxCLIPModel', 'FlaxCLIPPreTrainedModel', 'FlaxCLIPTextModel', 'FlaxCLIPTextModelWithProjection', 'FlaxCLIPTextPreTrainedModel', 'FlaxCLIPVisionModel', 'FlaxCLIPVisionPreTrainedModel', 'FlaxDinov2ForImageClassification', 'FlaxDinov2Model', 'FlaxDinov2PreTrainedModel', 'FlaxDistilBertForMaskedLM', 'FlaxDistilBertForMultipleChoice', 'FlaxDistilBertForQuestionAnswering', 'FlaxDistilBertForSequenceClassification', 'FlaxDistilBertForTokenClassification', 'FlaxDistilBertModel', 'FlaxDistilBertPreTrainedModel', 'FlaxElectraForCausalLM', 'FlaxElectraForMaskedLM', 'FlaxElectraForMultipleChoice', 'FlaxElectraForPreTraining', 'FlaxElectraForQuestionAnswering', 'FlaxElectraForSequenceClassification', 'FlaxElectraForTokenClassification', 'FlaxElectraModel', 'FlaxElectraPreTrainedModel', 'FlaxEncoderDecoderModel', 'FlaxForceTokensLogitsProcessor', 'FlaxForcedBOSTokenLogitsProcessor', 'FlaxForcedEOSTokenLogitsProcessor', 'FlaxGPT2LMHeadModel', 'FlaxGPT2Model', 'FlaxGPT2PreTrainedModel', 'FlaxGPTJForCausalLM', 'FlaxGPTJModel', 'FlaxGPTJPreTrainedModel', 'FlaxGPTNeoForCausalLM', 'FlaxGPTNeoModel', 'FlaxGPTNeoPreTrainedModel', 'FlaxGemmaForCausalLM', 'FlaxGemmaModel', 'FlaxGemmaPreTrainedModel', 'FlaxGenerationMixin', 'FlaxLlamaForCausalLM', 'FlaxLlamaModel', 'FlaxLlamaPreTrainedModel', 'FlaxLogitsProcessor', 'FlaxLogitsProcessorList', 'FlaxLogitsWarper', 'FlaxLongT5ForConditionalGeneration', 'FlaxLongT5Model', 'FlaxLongT5PreTrainedModel', 'FlaxMBartForConditionalGeneration', 'FlaxMBartForQuestionAnswering', 'FlaxMBartForSequenceClassification', 'FlaxMBartModel', 'FlaxMBartPreTrainedModel', 'FlaxMT5EncoderModel', 'FlaxMT5ForConditionalGeneration', 'FlaxMT5Model', 'FlaxMarianMTModel', 'FlaxMarianModel', 'FlaxMarianPreTrainedModel', 'FlaxMinLengthLogitsProcessor', 'FlaxMistralForCausalLM', 'FlaxMistralModel', 'FlaxMistralPreTrainedModel', 'FlaxOPTForCausalLM', 'FlaxOPTModel', 'FlaxOPTPreTrainedModel', 'FlaxPegasusForConditionalGeneration', 'FlaxPegasusModel', 'FlaxPegasusPreTrainedModel', 'FlaxPreTrainedModel', 'FlaxRegNetForImageClassification', 'FlaxRegNetModel', 'FlaxRegNetPreTrainedModel', 'FlaxResNetForImageClassification', 'FlaxResNetModel', 'FlaxResNetPreTrainedModel', 'FlaxRoFormerForMaskedLM', 'FlaxRoFormerForMultipleChoice', 'FlaxRoFormerForQuestionAnswering', 'FlaxRoFormerForSequenceClassification', 'FlaxRoFormerForTokenClassification', 'FlaxRoFormerModel', 'FlaxRoFormerPreTrainedModel', 'FlaxRobertaForCausalLM', 'FlaxRobertaForMaskedLM', 'FlaxRobertaForMultipleChoice', 'FlaxRobertaForQuestionAnswering', 'FlaxRobertaForSequenceClassification', 'FlaxRobertaForTokenClassification', 'FlaxRobertaModel', 'FlaxRobertaPreLayerNormForCausalLM', 'FlaxRobertaPreLayerNormForMaskedLM', 'FlaxRobertaPreLayerNormForMultipleChoice', 'FlaxRobertaPreLayerNormForQuestionAnswering', 'FlaxRobertaPreLayerNormForSequenceClassification', 'FlaxRobertaPreLayerNormForTokenClassification', 'FlaxRobertaPreLayerNormModel', 'FlaxRobertaPreLayerNormPreTrainedModel', 'FlaxRobertaPreTrainedModel', 'FlaxSpeechEncoderDecoderModel', 'FlaxSuppressTokensAtBeginLogitsProcessor', 'FlaxSuppressTokensLogitsProcessor', 'FlaxT5EncoderModel', 'FlaxT5ForConditionalGeneration', 'FlaxT5Model', 'FlaxT5PreTrainedModel', 'FlaxTemperatureLogitsWarper', 'FlaxTopKLogitsWarper', 'FlaxTopPLogitsWarper', 'FlaxViTForImageClassification', 'FlaxViTModel', 'FlaxViTPreTrainedModel', 'FlaxVisionEncoderDecoderModel', 'FlaxVisionTextDualEncoderModel', 'FlaxWav2Vec2ForCTC', 'FlaxWav2Vec2ForPreTraining', 'FlaxWav2Vec2Model', 'FlaxWav2Vec2PreTrainedModel', 'FlaxWhisperForAudioClassification', 'FlaxWhisperForConditionalGeneration', 'FlaxWhisperModel', 'FlaxWhisperPreTrainedModel', 'FlaxWhisperTimeStampLogitsProcessor', 'FlaxXGLMForCausalLM', 'FlaxXGLMModel', 'FlaxXGLMPreTrainedModel', 'FlaxXLMRobertaForCausalLM', 'FlaxXLMRobertaForMaskedLM', 'FlaxXLMRobertaForMultipleChoice', 'FlaxXLMRobertaForQuestionAnswering', 'FlaxXLMRobertaForSequenceClassification', 'FlaxXLMRobertaForTokenClassification', 'FlaxXLMRobertaModel', 'FlaxXLMRobertaPreTrainedModel', 'FocalNetBackbone', 'FocalNetConfig', 'FocalNetForImageClassification', 'FocalNetForMaskedImageModeling', 'FocalNetModel', 'FocalNetPreTrainedModel', 'ForcedBOSTokenLogitsProcessor', 'ForcedEOSTokenLogitsProcessor', 'FunnelBaseModel', 'FunnelConfig', 'FunnelForMaskedLM', 'FunnelForMultipleChoice', 'FunnelForPreTraining', 'FunnelForQuestionAnswering', 'FunnelForSequenceClassification', 'FunnelForTokenClassification', 'FunnelModel', 'FunnelPreTrainedModel', 'FunnelTokenizer', 'FunnelTokenizerFast', 'FuyuConfig', 'FuyuForCausalLM', 'FuyuImageProcessor', 'FuyuModel', 'FuyuPreTrainedModel', 'FuyuProcessor', 'GLPNConfig', 'GLPNFeatureExtractor', 'GLPNForDepthEstimation', 'GLPNImageProcessor', 'GLPNLayer', 'GLPNModel', 'GLPNPreTrainedModel', 'GPT2Config', 'GPT2DoubleHeadsModel', 'GPT2ForQuestionAnswering', 'GPT2ForSequenceClassification', 'GPT2ForTokenClassification', 'GPT2LMHeadModel', 'GPT2Model', 'GPT2OnnxConfig', 'GPT2PreTrainedModel', 'GPT2Tokenizer', 'GPT2TokenizerFast', 'GPTBigCodeConfig', 'GPTBigCodeForCausalLM', 'GPTBigCodeForSequenceClassification', 'GPTBigCodeForTokenClassification', 'GPTBigCodeModel', 'GPTBigCodePreTrainedModel', 'GPTJConfig', 'GPTJForCausalLM', 'GPTJForQuestionAnswering', 'GPTJForSequenceClassification', 'GPTJModel', 'GPTJOnnxConfig', 'GPTJPreTrainedModel', 'GPTNeoConfig', 'GPTNeoForCausalLM', 'GPTNeoForQuestionAnswering', 'GPTNeoForSequenceClassification', 'GPTNeoForTokenClassification', 'GPTNeoModel', 'GPTNeoOnnxConfig', 'GPTNeoPreTrainedModel', 'GPTNeoXConfig', 'GPTNeoXForCausalLM', 'GPTNeoXForQuestionAnswering', 'GPTNeoXForSequenceClassification', 'GPTNeoXForTokenClassification', 'GPTNeoXJapaneseConfig', 'GPTNeoXJapaneseForCausalLM', 'GPTNeoXJapaneseLayer', 'GPTNeoXJapaneseModel', 'GPTNeoXJapanesePreTrainedModel', 'GPTNeoXJapaneseTokenizer', 'GPTNeoXLayer', 'GPTNeoXModel', 'GPTNeoXPreTrainedModel', 'GPTNeoXTokenizerFast', 'GPTQConfig', 'GPTSanJapaneseConfig', 'GPTSanJapaneseForConditionalGeneration', 'GPTSanJapaneseModel', 'GPTSanJapanesePreTrainedModel', 'GPTSanJapaneseTokenizer', 'GPTSw3Tokenizer', 'Gemma2Config', 'Gemma2ForCausalLM', 'Gemma2ForSequenceClassification', 'Gemma2ForTokenClassification', 'Gemma2Model', 'Gemma2PreTrainedModel', 'Gemma3Config', 'Gemma3ForCausalLM', 'Gemma3ForConditionalGeneration', 'Gemma3ForSequenceClassification', 'Gemma3ImageProcessor', 'Gemma3ImageProcessorFast', 'Gemma3Model', 'Gemma3PreTrainedModel', 'Gemma3Processor', 'Gemma3TextConfig', 'Gemma3TextModel', 'Gemma3nAudioConfig', 'Gemma3nAudioEncoder', 'Gemma3nAudioFeatureExtractor', 'Gemma3nConfig', 'Gemma3nForCausalLM', 'Gemma3nForConditionalGeneration', 'Gemma3nModel', 'Gemma3nPreTrainedModel', 'Gemma3nProcessor', 'Gemma3nTextConfig', 'Gemma3nTextModel', 'Gemma3nVisionConfig', 'GemmaConfig', 'GemmaForCausalLM', 'GemmaForSequenceClassification', 'GemmaForTokenClassification', 'GemmaModel', 'GemmaPreTrainedModel', 'GemmaTokenizer', 'GemmaTokenizerFast', 'GenerationConfig', 'GenerationMixin', 'GitConfig', 'GitForCausalLM', 'GitModel', 'GitPreTrainedModel', 'GitProcessor', 'GitVisionConfig', 'GitVisionModel', 'Glm4Config', 'Glm4ForCausalLM', 'Glm4ForSequenceClassification', 'Glm4ForTokenClassification', 'Glm4Model', 'Glm4MoeConfig', 'Glm4MoeForCausalLM', 'Glm4MoeModel', 'Glm4MoePreTrainedModel', 'Glm4PreTrainedModel', 'Glm4vConfig', 'Glm4vForConditionalGeneration', 'Glm4vImageProcessor', 'Glm4vImageProcessorFast', 'Glm4vModel', 'Glm4vPreTrainedModel', 'Glm4vProcessor', 'Glm4vTextConfig', 'Glm4vTextModel', 'Glm4vVideoProcessor', 'GlmConfig', 'GlmForCausalLM', 'GlmForSequenceClassification', 'GlmForTokenClassification', 'GlmModel', 'GlmPreTrainedModel', 'GlueDataTrainingArguments', 'GlueDataset', 'GotOcr2Config', 'GotOcr2ForConditionalGeneration', 'GotOcr2ImageProcessor', 'GotOcr2ImageProcessorFast', 'GotOcr2Model', 'GotOcr2PreTrainedModel', 'GotOcr2Processor', 'GotOcr2VisionConfig', 'GptOssConfig', 'GptOssForCausalLM', 'GptOssModel', 'GptOssPreTrainedModel', 'GradientAccumulator', 'GradientCheckpointingLayer', 'GraniteConfig', 'GraniteForCausalLM', 'GraniteModel', 'GraniteMoeConfig', 'GraniteMoeForCausalLM', 'GraniteMoeHybridConfig', 'GraniteMoeHybridForCausalLM', 'GraniteMoeHybridModel', 'GraniteMoeHybridPreTrainedModel', 'GraniteMoeModel', 'GraniteMoePreTrainedModel', 'GraniteMoeSharedConfig', 'GraniteMoeSharedForCausalLM', 'GraniteMoeSharedModel', 'GraniteMoeSharedPreTrainedModel', 'GranitePreTrainedModel', 'GraniteSpeechCTCEncoder', 'GraniteSpeechConfig', 'GraniteSpeechEncoderConfig', 'GraniteSpeechFeatureExtractor', 'GraniteSpeechForConditionalGeneration', 'GraniteSpeechPreTrainedModel', 'GraniteSpeechProcessor', 'GraphormerConfig', 'GraphormerForGraphClassification', 'GraphormerModel', 'GraphormerPreTrainedModel', 'GroundingDinoConfig', 'GroundingDinoForObjectDetection', 'GroundingDinoImageProcessor', 'GroundingDinoImageProcessorFast', 'GroundingDinoModel', 'GroundingDinoPreTrainedModel', 'GroundingDinoProcessor', 'GroupViTConfig', 'GroupViTModel', 'GroupViTOnnxConfig', 'GroupViTPreTrainedModel', 'GroupViTTextConfig', 'GroupViTTextModel', 'GroupViTVisionConfig', 'GroupViTVisionModel', 'HGNetV2Backbone', 'HGNetV2Config', 'HGNetV2ForImageClassification', 'HGNetV2PreTrainedModel', 'HQQQuantizedCache', 'HQQQuantizedCacheProcessor', 'HammingDiversityLogitsProcessor', 'HeliumConfig', 'HeliumForCausalLM', 'HeliumForSequenceClassification', 'HeliumForTokenClassification', 'HeliumModel', 'HeliumPreTrainedModel', 'HerbertTokenizer', 'HerbertTokenizerFast', 'HfArgumentParser', 'HieraBackbone', 'HieraConfig', 'HieraForImageClassification', 'HieraForPreTraining', 'HieraModel', 'HieraPreTrainedModel', 'HiggsConfig', 'HqqConfig', 'HubertConfig', 'HubertForCTC', 'HubertForSequenceClassification', 'HubertModel', 'HubertPreTrainedModel', 'HybridCache', 'HybridChunkedCache', 'IBertConfig', 'IBertForMaskedLM', 'IBertForMultipleChoice', 'IBertForQuestionAnswering', 'IBertForSequenceClassification', 'IBertForTokenClassification', 'IBertModel', 'IBertOnnxConfig', 'IBertPreTrainedModel', 'IJepaConfig', 'IJepaForImageClassification', 'IJepaModel', 'IJepaPreTrainedModel', 'IMAGE_PROCESSOR_MAPPING', 'Idefics2Config', 'Idefics2ForConditionalGeneration', 'Idefics2ImageProcessor', 'Idefics2ImageProcessorFast', 'Idefics2Model', 'Idefics2PreTrainedModel', 'Idefics2Processor', 'Idefics3Config', 'Idefics3ForConditionalGeneration', 'Idefics3ImageProcessor', 'Idefics3ImageProcessorFast', 'Idefics3Model', 'Idefics3PreTrainedModel', 'Idefics3Processor', 'Idefics3VisionConfig', 'Idefics3VisionTransformer', 'IdeficsConfig', 'IdeficsForVisionText2Text', 'IdeficsImageProcessor', 'IdeficsModel', 'IdeficsPreTrainedModel', 'IdeficsProcessor', 'ImageClassificationPipeline', 'ImageFeatureExtractionMixin', 'ImageFeatureExtractionPipeline', 'ImageGPTConfig', 'ImageGPTFeatureExtractor', 'ImageGPTForCausalImageModeling', 'ImageGPTForImageClassification', 'ImageGPTImageProcessor', 'ImageGPTModel', 'ImageGPTOnnxConfig', 'ImageGPTPreTrainedModel', 'ImageProcessingMixin', 'ImageSegmentationPipeline', 'ImageTextToTextPipeline', 'ImageToImagePipeline', 'ImageToTextPipeline', 'InfNanRemoveLogitsProcessor', 'InformerConfig', 'InformerForPrediction', 'InformerModel', 'InformerPreTrainedModel', 'InputExample', 'InputFeatures', 'InstructBlipConfig', 'InstructBlipForConditionalGeneration', 'InstructBlipModel', 'InstructBlipPreTrainedModel', 'InstructBlipProcessor', 'InstructBlipQFormerConfig', 'InstructBlipQFormerModel', 'InstructBlipVideoConfig', 'InstructBlipVideoForConditionalGeneration', 'InstructBlipVideoImageProcessor', 'InstructBlipVideoModel', 'InstructBlipVideoPreTrainedModel', 'InstructBlipVideoProcessor', 'InstructBlipVideoQFormerConfig', 'InstructBlipVideoQFormerModel', 'InstructBlipVideoVideoProcessor', 'InstructBlipVideoVisionConfig', 'InstructBlipVideoVisionModel', 'InstructBlipVisionConfig', 'InstructBlipVisionModel', 'InternVLConfig', 'InternVLForConditionalGeneration', 'InternVLModel', 'InternVLPreTrainedModel', 'InternVLProcessor', 'InternVLVideoProcessor', 'InternVLVisionConfig', 'InternVLVisionModel', 'InternVLVisionPreTrainedModel', 'IntervalStrategy', 'JambaConfig', 'JambaForCausalLM', 'JambaForSequenceClassification', 'JambaModel', 'JambaPreTrainedModel', 'JanusConfig', 'JanusForConditionalGeneration', 'JanusImageProcessor', 'JanusImageProcessorFast', 'JanusModel', 'JanusPreTrainedModel', 'JanusProcessor', 'JanusVQVAE', 'JanusVQVAEConfig', 'JanusVisionConfig', 'JanusVisionModel', 'JetMoeConfig', 'JetMoeForCausalLM', 'JetMoeForSequenceClassification', 'JetMoeModel', 'JetMoePreTrainedModel', 'JsonPipelineDataFormat', 'JukeboxConfig', 'JukeboxModel', 'JukeboxPreTrainedModel', 'JukeboxPrior', 'JukeboxPriorConfig', 'JukeboxTokenizer', 'JukeboxVQVAE', 'JukeboxVQVAEConfig', 'KerasMetricCallback', 'Kosmos2Config', 'Kosmos2ForConditionalGeneration', 'Kosmos2Model', 'Kosmos2PreTrainedModel', 'Kosmos2Processor', 'KyutaiSpeechToTextConfig', 'KyutaiSpeechToTextFeatureExtractor', 'KyutaiSpeechToTextForConditionalGeneration', 'KyutaiSpeechToTextModel', 'KyutaiSpeechToTextPreTrainedModel', 'KyutaiSpeechToTextProcessor', 'LEDConfig', 'LEDForConditionalGeneration', 'LEDForQuestionAnswering', 'LEDForSequenceClassification', 'LEDModel', 'LEDPreTrainedModel', 'LEDTokenizer', 'LEDTokenizerFast', 'LayoutLMConfig', 'LayoutLMForMaskedLM', 'LayoutLMForQuestionAnswering', 'LayoutLMForSequenceClassification', 'LayoutLMForTokenClassification', 'LayoutLMModel', 'LayoutLMOnnxConfig', 'LayoutLMPreTrainedModel', 'LayoutLMTokenizer', 'LayoutLMTokenizerFast', 'LayoutLMv2Config', 'LayoutLMv2FeatureExtractor', 'LayoutLMv2ForQuestionAnswering', 'LayoutLMv2ForSequenceClassification', 'LayoutLMv2ForTokenClassification', 'LayoutLMv2ImageProcessor', 'LayoutLMv2ImageProcessorFast', 'LayoutLMv2Layer', 'LayoutLMv2Model', 'LayoutLMv2PreTrainedModel', 'LayoutLMv2Processor', 'LayoutLMv2Tokenizer', 'LayoutLMv2TokenizerFast', 'LayoutLMv3Config', 'LayoutLMv3FeatureExtractor', 'LayoutLMv3ForQuestionAnswering', 'LayoutLMv3ForSequenceClassification', 'LayoutLMv3ForTokenClassification', 'LayoutLMv3ImageProcessor', 'LayoutLMv3ImageProcessorFast', 'LayoutLMv3Model', 'LayoutLMv3OnnxConfig', 'LayoutLMv3PreTrainedModel', 'LayoutLMv3Processor', 'LayoutLMv3Tokenizer', 'LayoutLMv3TokenizerFast', 'LayoutXLMProcessor', 'LayoutXLMTokenizer', 'LayoutXLMTokenizerFast', 'LevitConfig', 'LevitFeatureExtractor', 'LevitForImageClassification', 'LevitForImageClassificationWithTeacher', 'LevitImageProcessor', 'LevitImageProcessorFast', 'LevitModel', 'LevitOnnxConfig', 'LevitPreTrainedModel', 'Lfm2Config', 'Lfm2ForCausalLM', 'Lfm2Model', 'Lfm2PreTrainedModel', 'LightGlueConfig', 'LightGlueForKeypointMatching', 'LightGlueImageProcessor', 'LightGluePreTrainedModel', 'LiltConfig', 'LiltForQuestionAnswering', 'LiltForSequenceClassification', 'LiltForTokenClassification', 'LiltModel', 'LiltPreTrainedModel', 'LineByLineTextDataset', 'LineByLineWithRefDataset', 'LineByLineWithSOPTextDataset', 'Llama4Config', 'Llama4ForCausalLM', 'Llama4ForConditionalGeneration', 'Llama4ImageProcessorFast', 'Llama4PreTrainedModel', 'Llama4Processor', 'Llama4TextConfig', 'Llama4TextModel', 'Llama4VisionConfig', 'Llama4VisionModel', 'LlamaConfig', 'LlamaForCausalLM', 'LlamaForQuestionAnswering', 'LlamaForSequenceClassification', 'LlamaForTokenClassification', 'LlamaModel', 'LlamaPreTrainedModel', 'LlamaTokenizer', 'LlamaTokenizerFast', 'LlavaConfig', 'LlavaForConditionalGeneration', 'LlavaImageProcessor', 'LlavaImageProcessorFast', 'LlavaModel', 'LlavaNextConfig', 'LlavaNextForConditionalGeneration', 'LlavaNextImageProcessor', 'LlavaNextImageProcessorFast', 'LlavaNextModel', 'LlavaNextPreTrainedModel', 'LlavaNextProcessor', 'LlavaNextVideoConfig', 'LlavaNextVideoForConditionalGeneration', 'LlavaNextVideoImageProcessor', 'LlavaNextVideoModel', 'LlavaNextVideoPreTrainedModel', 'LlavaNextVideoProcessor', 'LlavaNextVideoVideoProcessor', 'LlavaOnevisionConfig', 'LlavaOnevisionForConditionalGeneration', 'LlavaOnevisionImageProcessor', 'LlavaOnevisionImageProcessorFast', 'LlavaOnevisionModel', 'LlavaOnevisionPreTrainedModel', 'LlavaOnevisionProcessor', 'LlavaOnevisionVideoProcessor', 'LlavaPreTrainedModel', 'LlavaProcessor', 'LogitNormalization', 'LogitsProcessor', 'LogitsProcessorList', 'LongT5Config', 'LongT5EncoderModel', 'LongT5ForConditionalGeneration', 'LongT5Model', 'LongT5OnnxConfig', 'LongT5PreTrainedModel', 'LongformerConfig', 'LongformerForMaskedLM', 'LongformerForMultipleChoice', 'LongformerForQuestionAnswering', 'LongformerForSequenceClassification', 'LongformerForTokenClassification', 'LongformerModel', 'LongformerOnnxConfig', 'LongformerPreTrainedModel', 'LongformerSelfAttention', 'LongformerTokenizer', 'LongformerTokenizerFast', 'LukeConfig', 'LukeForEntityClassification', 'LukeForEntityPairClassification', 'LukeForEntitySpanClassification', 'LukeForMaskedLM', 'LukeForMultipleChoice', 'LukeForQuestionAnswering', 'LukeForSequenceClassification', 'LukeForTokenClassification', 'LukeModel', 'LukePreTrainedModel', 'LukeTokenizer', 'LxmertConfig', 'LxmertEncoder', 'LxmertForPreTraining', 'LxmertForQuestionAnswering', 'LxmertModel', 'LxmertPreTrainedModel', 'LxmertTokenizer', 'LxmertTokenizerFast', 'LxmertVisualFeatureEncoder', 'LxmertXLayer', 'M2M100Config', 'M2M100ForConditionalGeneration', 'M2M100Model', 'M2M100OnnxConfig', 'M2M100PreTrainedModel', 'M2M100Tokenizer', 'MBart50Tokenizer', 'MBart50TokenizerFast', 'MBartConfig', 'MBartForCausalLM', 'MBartForConditionalGeneration', 'MBartForQuestionAnswering', 'MBartForSequenceClassification', 'MBartModel', 'MBartOnnxConfig', 'MBartPreTrainedModel', 'MBartTokenizer', 'MBartTokenizerFast', 'MCTCTConfig', 'MCTCTFeatureExtractor', 'MCTCTForCTC', 'MCTCTModel', 'MCTCTPreTrainedModel', 'MCTCTProcessor', 'MLCDPreTrainedModel', 'MLCDVisionConfig', 'MLCDVisionModel', 'MLukeTokenizer', 'MMBTConfig', 'MMBTForClassification', 'MMBTModel', 'MMGroundingDinoConfig', 'MMGroundingDinoForObjectDetection', 'MMGroundingDinoModel', 'MMGroundingDinoPreTrainedModel', 'MODEL_CARD_NAME', 'MODEL_FOR_AUDIO_CLASSIFICATION_MAPPING', 'MODEL_FOR_AUDIO_FRAME_CLASSIFICATION_MAPPING', 'MODEL_FOR_AUDIO_TOKENIZATION_MAPPING', 'MODEL_FOR_AUDIO_XVECTOR_MAPPING', 'MODEL_FOR_BACKBONE_MAPPING', 'MODEL_FOR_CAUSAL_IMAGE_MODELING_MAPPING', 'MODEL_FOR_CAUSAL_LM_MAPPING', 'MODEL_FOR_CTC_MAPPING', 'MODEL_FOR_DEPTH_ESTIMATION_MAPPING', 'MODEL_FOR_DOCUMENT_QUESTION_ANSWERING_MAPPING', 'MODEL_FOR_IMAGE_CLASSIFICATION_MAPPING', 'MODEL_FOR_IMAGE_MAPPING', 'MODEL_FOR_IMAGE_SEGMENTATION_MAPPING', 'MODEL_FOR_IMAGE_TEXT_TO_TEXT_MAPPING', 'MODEL_FOR_IMAGE_TO_IMAGE_MAPPING', 'MODEL_FOR_INSTANCE_SEGMENTATION_MAPPING', 'MODEL_FOR_KEYPOINT_DETECTION_MAPPING', 'MODEL_FOR_KEYPOINT_MATCHING_MAPPING', 'MODEL_FOR_MASKED_IMAGE_MODELING_MAPPING', 'MODEL_FOR_MASKED_LM_MAPPING', 'MODEL_FOR_MASK_GENERATION_MAPPING', 'MODEL_FOR_MULTIPLE_CHOICE_MAPPING', 'MODEL_FOR_NEXT_SENTENCE_PREDICTION_MAPPING', 'MODEL_FOR_OBJECT_DETECTION_MAPPING', 'MODEL_FOR_PRETRAINING_MAPPING', 'MODEL_FOR_QUESTION_ANSWERING_MAPPING', 'MODEL_FOR_RETRIEVAL_MAPPING', 'MODEL_FOR_SEMANTIC_SEGMENTATION_MAPPING', 'MODEL_FOR_SEQUENCE_CLASSIFICATION_MAPPING', 'MODEL_FOR_SEQ_TO_SEQ_CAUSAL_LM_MAPPING', 'MODEL_FOR_SPEECH_SEQ_2_SEQ_MAPPING', 'MODEL_FOR_TABLE_QUESTION_ANSWERING_MAPPING', 'MODEL_FOR_TEXT_ENCODING_MAPPING', 'MODEL_FOR_TEXT_TO_SPECTROGRAM_MAPPING', 'MODEL_FOR_TEXT_TO_WAVEFORM_MAPPING', 'MODEL_FOR_TIME_SERIES_CLASSIFICATION_MAPPING', 'MODEL_FOR_TIME_SERIES_PREDICTION_MAPPING', 'MODEL_FOR_TIME_SERIES_REGRESSION_MAPPING', 'MODEL_FOR_TOKEN_CLASSIFICATION_MAPPING', 'MODEL_FOR_UNIVERSAL_SEGMENTATION_MAPPING', 'MODEL_FOR_VIDEO_CLASSIFICATION_MAPPING', 'MODEL_FOR_VISION_2_SEQ_MAPPING', 'MODEL_FOR_VISUAL_QUESTION_ANSWERING_MAPPING', 'MODEL_FOR_ZERO_SHOT_IMAGE_CLASSIFICATION_MAPPING', 'MODEL_FOR_ZERO_SHOT_OBJECT_DETECTION_MAPPING', 'MODEL_MAPPING', 'MODEL_NAMES_MAPPING', 'MODEL_WITH_LM_HEAD_MAPPING', 'MPNetConfig', 'MPNetForMaskedLM', 'MPNetForMultipleChoice', 'MPNetForQuestionAnswering', 'MPNetForSequenceClassification', 'MPNetForTokenClassification', 'MPNetLayer', 'MPNetModel', 'MPNetPreTrainedModel', 'MPNetTokenizer', 'MPNetTokenizerFast', 'MT5Config', 'MT5EncoderModel', 'MT5ForConditionalGeneration', 'MT5ForQuestionAnswering', 'MT5ForSequenceClassification', 'MT5ForTokenClassification', 'MT5Model', 'MT5OnnxConfig', 'MT5PreTrainedModel', 'MT5Tokenizer', 'MT5TokenizerFast', 'Mamba2Config', 'Mamba2ForCausalLM', 'Mamba2Model', 'Mamba2PreTrainedModel', 'MambaCache', 'MambaConfig', 'MambaForCausalLM', 'MambaModel', 'MambaPreTrainedModel', 'MarianConfig', 'MarianForCausalLM', 'MarianMTModel', 'MarianModel', 'MarianOnnxConfig', 'MarianPreTrainedModel', 'MarianTokenizer', 'MarkupLMConfig', 'MarkupLMFeatureExtractor', 'MarkupLMForQuestionAnswering', 'MarkupLMForSequenceClassification', 'MarkupLMForTokenClassification', 'MarkupLMModel', 'MarkupLMPreTrainedModel', 'MarkupLMProcessor', 'MarkupLMTokenizer', 'MarkupLMTokenizerFast', 'Mask2FormerConfig', 'Mask2FormerForUniversalSegmentation', 'Mask2FormerImageProcessor', 'Mask2FormerImageProcessorFast', 'Mask2FormerModel', 'Mask2FormerPreTrainedModel', 'MaskFormerConfig', 'MaskFormerFeatureExtractor', 'MaskFormerForInstanceSegmentation', 'MaskFormerImageProcessor', 'MaskFormerImageProcessorFast', 'MaskFormerModel', 'MaskFormerPreTrainedModel', 'MaskFormerSwinBackbone', 'MaskFormerSwinConfig', 'MaskFormerSwinModel', 'MaskFormerSwinPreTrainedModel', 'MaskGenerationPipeline', 'MaxLengthCriteria', 'MaxTimeCriteria', 'MecabTokenizer', 'MegaConfig', 'MegaForCausalLM', 'MegaForMaskedLM', 'MegaForMultipleChoice', 'MegaForQuestionAnswering', 'MegaForSequenceClassification', 'MegaForTokenClassification', 'MegaModel', 'MegaOnnxConfig', 'MegaPreTrainedModel', 'MegatronBertConfig', 'MegatronBertForCausalLM', 'MegatronBertForMaskedLM', 'MegatronBertForMultipleChoice', 'MegatronBertForNextSentencePrediction', 'MegatronBertForPreTraining', 'MegatronBertForQuestionAnswering', 'MegatronBertForSequenceClassification', 'MegatronBertForTokenClassification', 'MegatronBertModel', 'MegatronBertPreTrainedModel', 'MgpstrConfig', 'MgpstrForSceneTextRecognition', 'MgpstrModel', 'MgpstrPreTrainedModel', 'MgpstrProcessor', 'MgpstrTokenizer', 'MimiConfig', 'MimiModel', 'MimiPreTrainedModel', 'MinLengthLogitsProcessor', 'MinNewTokensLengthLogitsProcessor', 'MinPLogitsWarper', 'MiniMaxConfig', 'MiniMaxForCausalLM', 'MiniMaxForQuestionAnswering', 'MiniMaxForSequenceClassification', 'MiniMaxForTokenClassification', 'MiniMaxModel', 'MiniMaxPreTrainedModel', 'Mistral3Config', 'Mistral3ForConditionalGeneration', 'Mistral3Model', 'Mistral3PreTrainedModel', 'MistralCommonTokenizer', 'MistralConfig', 'MistralForCausalLM', 'MistralForQuestionAnswering', 'MistralForSequenceClassification', 'MistralForTokenClassification', 'MistralModel', 'MistralPreTrainedModel', 'MixtralConfig', 'MixtralForCausalLM', 'MixtralForQuestionAnswering', 'MixtralForSequenceClassification', 'MixtralForTokenClassification', 'MixtralModel', 'MixtralPreTrainedModel', 'MllamaConfig', 'MllamaForCausalLM', 'MllamaForConditionalGeneration', 'MllamaImageProcessor', 'MllamaModel', 'MllamaPreTrainedModel', 'MllamaProcessor', 'MllamaTextModel', 'MllamaVisionModel', 'MobileBertConfig', 'MobileBertForMaskedLM', 'MobileBertForMultipleChoice', 'MobileBertForNextSentencePrediction', 'MobileBertForPreTraining', 'MobileBertForQuestionAnswering', 'MobileBertForSequenceClassification', 'MobileBertForTokenClassification', 'MobileBertLayer', 'MobileBertModel', 'MobileBertOnnxConfig', 'MobileBertPreTrainedModel', 'MobileBertTokenizer', 'MobileBertTokenizerFast', 'MobileNetV1Config', 'MobileNetV1FeatureExtractor', 'MobileNetV1ForImageClassification', 'MobileNetV1ImageProcessor', 'MobileNetV1ImageProcessorFast', 'MobileNetV1Model', 'MobileNetV1OnnxConfig', 'MobileNetV1PreTrainedModel', 'MobileNetV2Config', 'MobileNetV2FeatureExtractor', 'MobileNetV2ForImageClassification', 'MobileNetV2ForSemanticSegmentation', 'MobileNetV2ImageProcessor', 'MobileNetV2ImageProcessorFast', 'MobileNetV2Model', 'MobileNetV2OnnxConfig', 'MobileNetV2PreTrainedModel', 'MobileViTConfig', 'MobileViTFeatureExtractor', 'MobileViTForImageClassification', 'MobileViTForSemanticSegmentation', 'MobileViTImageProcessor', 'MobileViTImageProcessorFast', 'MobileViTModel', 'MobileViTOnnxConfig', 'MobileViTPreTrainedModel', 'MobileViTV2Config', 'MobileViTV2ForImageClassification', 'MobileViTV2ForSemanticSegmentation', 'MobileViTV2Model', 'MobileViTV2OnnxConfig', 'MobileViTV2PreTrainedModel', 'ModalEmbeddings', 'ModelCard', 'ModernBertConfig', 'ModernBertDecoderConfig', 'ModernBertDecoderForCausalLM', 'ModernBertDecoderForSequenceClassification', 'ModernBertDecoderModel', 'ModernBertDecoderPreTrainedModel', 'ModernBertForMaskedLM', 'ModernBertForMultipleChoice', 'ModernBertForQuestionAnswering', 'ModernBertForSequenceClassification', 'ModernBertForTokenClassification', 'ModernBertModel', 'ModernBertPreTrainedModel', 'MoonshineConfig', 'MoonshineForConditionalGeneration', 'MoonshineModel', 'MoonshinePreTrainedModel', 'MoshiConfig', 'MoshiDepthConfig', 'MoshiForCausalLM', 'MoshiForConditionalGeneration', 'MoshiModel', 'MoshiPreTrainedModel', 'MptConfig', 'MptForCausalLM', 'MptForQuestionAnswering', 'MptForSequenceClassification', 'MptForTokenClassification', 'MptModel', 'MptPreTrainedModel', 'MraConfig', 'MraForMaskedLM', 'MraForMultipleChoice', 'MraForQuestionAnswering', 'MraForSequenceClassification', 'MraForTokenClassification', 'MraLayer', 'MraModel', 'MraPreTrainedModel', 'MusicgenConfig', 'MusicgenDecoderConfig', 'MusicgenForCausalLM', 'MusicgenForConditionalGeneration', 'MusicgenMelodyConfig', 'MusicgenMelodyDecoderConfig', 'MusicgenMelodyFeatureExtractor', 'MusicgenMelodyForCausalLM', 'MusicgenMelodyForConditionalGeneration', 'MusicgenMelodyModel', 'MusicgenMelodyPreTrainedModel', 'MusicgenMelodyProcessor', 'MusicgenModel', 'MusicgenPreTrainedModel', 'MusicgenProcessor', 'MvpConfig', 'MvpForCausalLM', 'MvpForConditionalGeneration', 'MvpForQuestionAnswering', 'MvpForSequenceClassification', 'MvpModel', 'MvpPreTrainedModel', 'MvpTokenizer', 'MvpTokenizerFast', 'Mxfp4Config', 'MyT5Tokenizer', 'NatBackbone', 'NatConfig', 'NatForImageClassification', 'NatModel', 'NatPreTrainedModel', 'NemotronConfig', 'NemotronForCausalLM', 'NemotronForQuestionAnswering', 'NemotronForSequenceClassification', 'NemotronForTokenClassification', 'NemotronModel', 'NemotronPreTrainedModel', 'NerPipeline', 'NezhaConfig', 'NezhaForMaskedLM', 'NezhaForMultipleChoice', 'NezhaForNextSentencePrediction', 'NezhaForPreTraining', 'NezhaForQuestionAnswering', 'NezhaForSequenceClassification', 'NezhaForTokenClassification', 'NezhaModel', 'NezhaPreTrainedModel', 'NllbMoeConfig', 'NllbMoeForConditionalGeneration', 'NllbMoeModel', 'NllbMoePreTrainedModel', 'NllbMoeSparseMLP', 'NllbMoeTop2Router', 'NllbTokenizer', 'NllbTokenizerFast', 'NoBadWordsLogitsProcessor', 'NoRepeatNGramLogitsProcessor', 'NougatImageProcessor', 'NougatImageProcessorFast', 'NougatProcessor', 'NougatTokenizerFast', 'NystromformerConfig', 'NystromformerForMaskedLM', 'NystromformerForMultipleChoice', 'NystromformerForQuestionAnswering', 'NystromformerForSequenceClassification', 'NystromformerForTokenClassification', 'NystromformerLayer', 'NystromformerModel', 'NystromformerPreTrainedModel', 'OPTConfig', 'OPTForCausalLM', 'OPTForQuestionAnswering', 'OPTForSequenceClassification', 'OPTModel', 'OPTPreTrainedModel', 'ObjectDetectionPipeline', 'OffloadedCache', 'OffloadedCacheProcessor', 'OffloadedStaticCache', 'Olmo2Config', 'Olmo2ForCausalLM', 'Olmo2Model', 'Olmo2PreTrainedModel', 'OlmoConfig', 'OlmoForCausalLM', 'OlmoModel', 'OlmoPreTrainedModel', 'OlmoeConfig', 'OlmoeForCausalLM', 'OlmoeModel', 'OlmoePreTrainedModel', 'OmDetTurboConfig', 'OmDetTurboForObjectDetection', 'OmDetTurboPreTrainedModel', 'OmDetTurboProcessor', 'OneFormerConfig', 'OneFormerForUniversalSegmentation', 'OneFormerImageProcessor', 'OneFormerImageProcessorFast', 'OneFormerModel', 'OneFormerPreTrainedModel', 'OneFormerProcessor', 'OpenAIGPTConfig', 'OpenAIGPTDoubleHeadsModel', 'OpenAIGPTForSequenceClassification', 'OpenAIGPTLMHeadModel', 'OpenAIGPTModel', 'OpenAIGPTPreTrainedModel', 'OpenAIGPTTokenizer', 'OpenAIGPTTokenizerFast', 'OpenLlamaConfig', 'OpenLlamaForCausalLM', 'OpenLlamaForSequenceClassification', 'OpenLlamaModel', 'OpenLlamaPreTrainedModel', 'OwlViTConfig', 'OwlViTFeatureExtractor', 'OwlViTForObjectDetection', 'OwlViTImageProcessor', 'OwlViTImageProcessorFast', 'OwlViTModel', 'OwlViTOnnxConfig', 'OwlViTPreTrainedModel', 'OwlViTProcessor', 'OwlViTTextConfig', 'OwlViTTextModel', 'OwlViTVisionConfig', 'OwlViTVisionModel', 'Owlv2Config', 'Owlv2ForObjectDetection', 'Owlv2ImageProcessor', 'Owlv2ImageProcessorFast', 'Owlv2Model', 'Owlv2PreTrainedModel', 'Owlv2Processor', 'Owlv2TextConfig', 'Owlv2TextModel', 'Owlv2VisionConfig', 'Owlv2VisionModel', 'PLBartConfig', 'PLBartForCausalLM', 'PLBartForConditionalGeneration', 'PLBartForSequenceClassification', 'PLBartModel', 'PLBartPreTrainedModel', 'PLBartTokenizer', 'PROCESSOR_MAPPING', 'PYTORCH_PRETRAINED_BERT_CACHE', 'PYTORCH_TRANSFORMERS_CACHE', 'PaliGemmaConfig', 'PaliGemmaForConditionalGeneration', 'PaliGemmaModel', 'PaliGemmaPreTrainedModel', 'PaliGemmaProcessor', 'PatchTSMixerConfig', 'PatchTSMixerForPrediction', 'PatchTSMixerForPretraining', 'PatchTSMixerForRegression', 'PatchTSMixerForTimeSeriesClassification', 'PatchTSMixerModel', 'PatchTSMixerPreTrainedModel', 'PatchTSTConfig', 'PatchTSTForClassification', 'PatchTSTForPrediction', 'PatchTSTForPretraining', 'PatchTSTForRegression', 'PatchTSTModel', 'PatchTSTPreTrainedModel', 'PegasusConfig', 'PegasusForCausalLM', 'PegasusForConditionalGeneration', 'PegasusModel', 'PegasusPreTrainedModel', 'PegasusTokenizer', 'PegasusTokenizerFast', 'PegasusXConfig', 'PegasusXForConditionalGeneration', 'PegasusXModel', 'PegasusXPreTrainedModel', 'PerceiverConfig', 'PerceiverFeatureExtractor', 'PerceiverForImageClassificationConvProcessing', 'PerceiverForImageClassificationFourier', 'PerceiverForImageClassificationLearned', 'PerceiverForMaskedLM', 'PerceiverForMultimodalAutoencoding', 'PerceiverForOpticalFlow', 'PerceiverForSequenceClassification', 'PerceiverImageProcessor', 'PerceiverImageProcessorFast', 'PerceiverLayer', 'PerceiverModel', 'PerceiverOnnxConfig', 'PerceiverPreTrainedModel', 'PerceiverTokenizer', 'PerceptionLMConfig', 'PerceptionLMForConditionalGeneration', 'PerceptionLMImageProcessorFast', 'PerceptionLMModel', 'PerceptionLMPreTrainedModel', 'PerceptionLMProcessor', 'PerceptionLMVideoProcessor', 'PersimmonConfig', 'PersimmonForCausalLM', 'PersimmonForSequenceClassification', 'PersimmonForTokenClassification', 'PersimmonModel', 'PersimmonPreTrainedModel', 'Phi3Config', 'Phi3ForCausalLM', 'Phi3ForSequenceClassification', 'Phi3ForTokenClassification', 'Phi3Model', 'Phi3PreTrainedModel', 'Phi4MultimodalAudioConfig', 'Phi4MultimodalAudioModel', 'Phi4MultimodalAudioPreTrainedModel', 'Phi4MultimodalConfig', 'Phi4MultimodalFeatureExtractor', 'Phi4MultimodalForCausalLM', 'Phi4MultimodalImageProcessorFast', 'Phi4MultimodalModel', 'Phi4MultimodalPreTrainedModel', 'Phi4MultimodalProcessor', 'Phi4MultimodalVisionConfig', 'Phi4MultimodalVisionModel', 'Phi4MultimodalVisionPreTrainedModel', 'PhiConfig', 'PhiForCausalLM', 'PhiForSequenceClassification', 'PhiForTokenClassification', 'PhiModel', 'PhiPreTrainedModel', 'PhimoeConfig', 'PhimoeForCausalLM', 'PhimoeForSequenceClassification', 'PhimoeModel', 'PhimoePreTrainedModel', 'PhobertTokenizer', 'PhrasalConstraint', 'PipedPipelineDataFormat', 'Pipeline', 'PipelineDataFormat', 'Pix2StructConfig', 'Pix2StructForConditionalGeneration', 'Pix2StructImageProcessor', 'Pix2StructPreTrainedModel', 'Pix2StructProcessor', 'Pix2StructTextConfig', 'Pix2StructTextModel', 'Pix2StructVisionConfig', 'Pix2StructVisionModel', 'PixtralImageProcessor', 'PixtralImageProcessorFast', 'PixtralPreTrainedModel', 'PixtralProcessor', 'PixtralVisionConfig', 'PixtralVisionModel', 'PoolFormerConfig', 'PoolFormerFeatureExtractor', 'PoolFormerForImageClassification', 'PoolFormerImageProcessor', 'PoolFormerImageProcessorFast', 'PoolFormerModel', 'PoolFormerOnnxConfig', 'PoolFormerPreTrainedModel', 'Pop2PianoConfig', 'Pop2PianoFeatureExtractor', 'Pop2PianoForConditionalGeneration', 'Pop2PianoPreTrainedModel', 'Pop2PianoProcessor', 'Pop2PianoTokenizer', 'PreTrainedModel', 'PreTrainedTokenizer', 'PreTrainedTokenizerBase', 'PreTrainedTokenizerFast', 'PrefixConstrainedLogitsProcessor', 'PretrainedBartModel', 'PretrainedConfig', 'PretrainedFSMTModel', 'PrinterCallback', 'ProcessorMixin', 'ProgressCallback', 'PromptDepthAnythingConfig', 'PromptDepthAnythingForDepthEstimation', 'PromptDepthAnythingImageProcessor', 'PromptDepthAnythingPreTrainedModel', 'ProphetNetConfig', 'ProphetNetDecoder', 'ProphetNetEncoder', 'ProphetNetForCausalLM', 'ProphetNetForConditionalGeneration', 'ProphetNetModel', 'ProphetNetPreTrainedModel', 'ProphetNetTokenizer', 'PushToHubCallback', 'PvtConfig', 'PvtForImageClassification', 'PvtImageProcessor', 'PvtImageProcessorFast', 'PvtModel', 'PvtOnnxConfig', 'PvtPreTrainedModel', 'PvtV2Backbone', 'PvtV2Config', 'PvtV2ForImageClassification', 'PvtV2Model', 'PvtV2PreTrainedModel', 'QDQBertConfig', 'QDQBertForMaskedLM', 'QDQBertForMultipleChoice', 'QDQBertForNextSentencePrediction', 'QDQBertForQuestionAnswering', 'QDQBertForSequenceClassification', 'QDQBertForTokenClassification', 'QDQBertLMHeadModel', 'QDQBertLayer', 'QDQBertModel', 'QDQBertPreTrainedModel', 'QuantizedCache', 'QuantizedCacheConfig', 'QuantizedCacheProcessor', 'QuantoConfig', 'QuantoQuantizedCache', 'QuantoQuantizedCacheProcessor', 'QuarkConfig', 'QuestionAnsweringPipeline', 'Qwen2AudioConfig', 'Qwen2AudioEncoder', 'Qwen2AudioEncoderConfig', 'Qwen2AudioForConditionalGeneration', 'Qwen2AudioPreTrainedModel', 'Qwen2AudioProcessor', 'Qwen2Config', 'Qwen2ForCausalLM', 'Qwen2ForQuestionAnswering', 'Qwen2ForSequenceClassification', 'Qwen2ForTokenClassification', 'Qwen2Model', 'Qwen2MoeConfig', 'Qwen2MoeForCausalLM', 'Qwen2MoeForQuestionAnswering', 'Qwen2MoeForSequenceClassification', 'Qwen2MoeForTokenClassification', 'Qwen2MoeModel', 'Qwen2MoePreTrainedModel', 'Qwen2PreTrainedModel', 'Qwen2Tokenizer', 'Qwen2TokenizerFast', 'Qwen2VLConfig', 'Qwen2VLForConditionalGeneration', 'Qwen2VLImageProcessor', 'Qwen2VLImageProcessorFast', 'Qwen2VLModel', 'Qwen2VLPreTrainedModel', 'Qwen2VLProcessor', 'Qwen2VLTextConfig', 'Qwen2VLTextModel', 'Qwen2VLVideoProcessor', 'Qwen2_5OmniConfig', 'Qwen2_5OmniForConditionalGeneration', 'Qwen2_5OmniPreTrainedModel', 'Qwen2_5OmniPreTrainedModelForConditionalGeneration', 'Qwen2_5OmniProcessor', 'Qwen2_5OmniTalkerConfig', 'Qwen2_5OmniTalkerForConditionalGeneration', 'Qwen2_5OmniTalkerModel', 'Qwen2_5OmniThinkerConfig', 'Qwen2_5OmniThinkerForConditionalGeneration', 'Qwen2_5OmniThinkerTextModel', 'Qwen2_5OmniToken2WavBigVGANModel', 'Qwen2_5OmniToken2WavConfig', 'Qwen2_5OmniToken2WavDiTModel', 'Qwen2_5OmniToken2WavModel', 'Qwen2_5_VLConfig', 'Qwen2_5_VLForConditionalGeneration', 'Qwen2_5_VLModel', 'Qwen2_5_VLPreTrainedModel', 'Qwen2_5_VLProcessor', 'Qwen2_5_VLTextConfig', 'Qwen2_5_VLTextModel', 'Qwen3Config', 'Qwen3ForCausalLM', 'Qwen3ForQuestionAnswering', 'Qwen3ForSequenceClassification', 'Qwen3ForTokenClassification', 'Qwen3Model', 'Qwen3MoeConfig', 'Qwen3MoeForCausalLM', 'Qwen3MoeForQuestionAnswering', 'Qwen3MoeForSequenceClassification', 'Qwen3MoeForTokenClassification', 'Qwen3MoeModel', 'Qwen3MoePreTrainedModel', 'Qwen3PreTrainedModel', 'ROPE_INIT_FUNCTIONS', 'RTDetrConfig', 'RTDetrForObjectDetection', 'RTDetrImageProcessor', 'RTDetrImageProcessorFast', 'RTDetrModel', 'RTDetrPreTrainedModel', 'RTDetrResNetBackbone', 'RTDetrResNetConfig', 'RTDetrResNetPreTrainedModel', 'RTDetrV2Config', 'RTDetrV2ForObjectDetection', 'RTDetrV2Model', 'RTDetrV2PreTrainedModel', 'RagConfig', 'RagModel', 'RagPreTrainedModel', 'RagRetriever', 'RagSequenceForGeneration', 'RagTokenForGeneration', 'RagTokenizer', 'RealmConfig', 'RealmEmbedder', 'RealmForOpenQA', 'RealmKnowledgeAugEncoder', 'RealmPreTrainedModel', 'RealmReader', 'RealmRetriever', 'RealmScorer', 'RealmTokenizer', 'RealmTokenizerFast', 'RecurrentGemmaConfig', 'RecurrentGemmaForCausalLM', 'RecurrentGemmaModel', 'RecurrentGemmaPreTrainedModel', 'ReformerAttention', 'ReformerConfig', 'ReformerForMaskedLM', 'ReformerForQuestionAnswering', 'ReformerForSequenceClassification', 'ReformerLayer', 'ReformerModel', 'ReformerModelWithLMHead', 'ReformerPreTrainedModel', 'ReformerTokenizer', 'ReformerTokenizerFast', 'RegNetConfig', 'RegNetForImageClassification', 'RegNetModel', 'RegNetPreTrainedModel', 'RemBertConfig', 'RemBertForCausalLM', 'RemBertForMaskedLM', 'RemBertForMultipleChoice', 'RemBertForQuestionAnswering', 'RemBertForSequenceClassification', 'RemBertForTokenClassification', 'RemBertLayer', 'RemBertModel', 'RemBertOnnxConfig', 'RemBertPreTrainedModel', 'RemBertTokenizer', 'RemBertTokenizerFast', 'RepetitionPenaltyLogitsProcessor', 'ResNetBackbone', 'ResNetConfig', 'ResNetForImageClassification', 'ResNetModel', 'ResNetOnnxConfig', 'ResNetPreTrainedModel', 'RetriBertConfig', 'RetriBertModel', 'RetriBertPreTrainedModel', 'RetriBertTokenizer', 'RetriBertTokenizerFast', 'RoCBertConfig', 'RoCBertForCausalLM', 'RoCBertForMaskedLM', 'RoCBertForMultipleChoice', 'RoCBertForPreTraining', 'RoCBertForQuestionAnswering', 'RoCBertForSequenceClassification', 'RoCBertForTokenClassification', 'RoCBertLayer', 'RoCBertModel', 'RoCBertPreTrainedModel', 'RoCBertTokenizer', 'RoFormerConfig', 'RoFormerForCausalLM', 'RoFormerForMaskedLM', 'RoFormerForMultipleChoice', 'RoFormerForQuestionAnswering', 'RoFormerForSequenceClassification', 'RoFormerForTokenClassification', 'RoFormerLayer', 'RoFormerModel', 'RoFormerOnnxConfig', 'RoFormerPreTrainedModel', 'RoFormerTokenizer', 'RoFormerTokenizerFast', 'RobertaConfig', 'RobertaForCausalLM', 'RobertaForMaskedLM', 'RobertaForMultipleChoice', 'RobertaForQuestionAnswering', 'RobertaForSequenceClassification', 'RobertaForTokenClassification', 'RobertaModel', 'RobertaOnnxConfig', 'RobertaPreLayerNormConfig', 'RobertaPreLayerNormForCausalLM', 'RobertaPreLayerNormForMaskedLM', 'RobertaPreLayerNormForMultipleChoice', 'RobertaPreLayerNormForQuestionAnswering', 'RobertaPreLayerNormForSequenceClassification', 'RobertaPreLayerNormForTokenClassification', 'RobertaPreLayerNormModel', 'RobertaPreLayerNormOnnxConfig', 'RobertaPreLayerNormPreTrainedModel', 'RobertaPreTrainedModel', 'RobertaTokenizer', 'RobertaTokenizerFast', 'RwkvConfig', 'RwkvForCausalLM', 'RwkvModel', 'RwkvPreTrainedModel', 'SEWConfig', 'SEWDConfig', 'SEWDForCTC', 'SEWDForSequenceClassification', 'SEWDModel', 'SEWDPreTrainedModel', 'SEWForCTC', 'SEWForSequenceClassification', 'SEWModel', 'SEWPreTrainedModel', 'SLOW_TO_FAST_CONVERTERS', 'SPIECE_UNDERLINE', 'SamConfig', 'SamHQConfig', 'SamHQMaskDecoderConfig', 'SamHQModel', 'SamHQPreTrainedModel', 'SamHQProcessor', 'SamHQPromptEncoderConfig', 'SamHQVisionConfig', 'SamHQVisionModel', 'SamImageProcessor', 'SamImageProcessorFast', 'SamMaskDecoderConfig', 'SamModel', 'SamPreTrainedModel', 'SamProcessor', 'SamPromptEncoderConfig', 'SamVisionConfig', 'SamVisionModel', 'SchedulerType', 'SeamlessM4TCodeHifiGan', 'SeamlessM4TConfig', 'SeamlessM4TFeatureExtractor', 'SeamlessM4TForSpeechToSpeech', 'SeamlessM4TForSpeechToText', 'SeamlessM4TForTextToSpeech', 'SeamlessM4TForTextToText', 'SeamlessM4THifiGan', 'SeamlessM4TModel', 'SeamlessM4TPreTrainedModel', 'SeamlessM4TProcessor', 'SeamlessM4TTextToUnitForConditionalGeneration', 'SeamlessM4TTextToUnitModel', 'SeamlessM4TTokenizer', 'SeamlessM4TTokenizerFast', 'SeamlessM4Tv2Config', 'SeamlessM4Tv2ForSpeechToSpeech', 'SeamlessM4Tv2ForSpeechToText', 'SeamlessM4Tv2ForTextToSpeech', 'SeamlessM4Tv2ForTextToText', 'SeamlessM4Tv2Model', 'SeamlessM4Tv2PreTrainedModel', 'SegGptConfig', 'SegGptForImageSegmentation', 'SegGptImageProcessor', 'SegGptModel', 'SegGptPreTrainedModel', 'SegformerConfig', 'SegformerDecodeHead', 'SegformerFeatureExtractor', 'SegformerForImageClassification', 'SegformerForSemanticSegmentation', 'SegformerImageProcessor', 'SegformerImageProcessorFast', 'SegformerLayer', 'SegformerModel', 'SegformerOnnxConfig', 'SegformerPreTrainedModel', 'Seq2SeqTrainer', 'Seq2SeqTrainingArguments', 'SequenceBiasLogitsProcessor', 'SequenceFeatureExtractor', 'ShieldGemma2Config', 'ShieldGemma2ForImageClassification', 'ShieldGemma2Processor', 'Siglip2Config', 'Siglip2ForImageClassification', 'Siglip2ImageProcessor', 'Siglip2ImageProcessorFast', 'Siglip2Model', 'Siglip2PreTrainedModel', 'Siglip2Processor', 'Siglip2TextConfig', 'Siglip2TextModel', 'Siglip2VisionConfig', 'Siglip2VisionModel', 'SiglipConfig', 'SiglipForImageClassification', 'SiglipImageProcessor', 'SiglipImageProcessorFast', 'SiglipModel', 'SiglipPreTrainedModel', 'SiglipProcessor', 'SiglipTextConfig', 'SiglipTextModel', 'SiglipTokenizer', 'SiglipVisionConfig', 'SiglipVisionModel', 'SingleSentenceClassificationProcessor', 'SinkCache', 'SlidingWindowCache', 'SlidingWindowLayer', 'SmolLM3Config', 'SmolLM3ForCausalLM', 'SmolLM3ForQuestionAnswering', 'SmolLM3ForSequenceClassification', 'SmolLM3ForTokenClassification', 'SmolLM3Model', 'SmolLM3PreTrainedModel', 'SmolVLMConfig', 'SmolVLMForConditionalGeneration', 'SmolVLMImageProcessor', 'SmolVLMImageProcessorFast', 'SmolVLMModel', 'SmolVLMPreTrainedModel', 'SmolVLMProcessor', 'SmolVLMVideoProcessor', 'SmolVLMVisionConfig', 'SmolVLMVisionTransformer', 'SpQRConfig', 'SpecialTokensMixin', 'Speech2Text2Config', 'Speech2Text2ForCausalLM', 'Speech2Text2PreTrainedModel', 'Speech2Text2Processor', 'Speech2Text2Tokenizer', 'Speech2TextConfig', 'Speech2TextFeatureExtractor', 'Speech2TextForConditionalGeneration', 'Speech2TextModel', 'Speech2TextPreTrainedModel', 'Speech2TextProcessor', 'Speech2TextTokenizer', 'SpeechEncoderDecoderConfig', 'SpeechEncoderDecoderModel', 'SpeechT5Config', 'SpeechT5FeatureExtractor', 'SpeechT5ForSpeechToSpeech', 'SpeechT5ForSpeechToText', 'SpeechT5ForTextToSpeech', 'SpeechT5HifiGan', 'SpeechT5HifiGanConfig', 'SpeechT5Model', 'SpeechT5PreTrainedModel', 'SpeechT5Processor', 'SpeechT5Tokenizer', 'SplinterConfig', 'SplinterForPreTraining', 'SplinterForQuestionAnswering', 'SplinterLayer', 'SplinterModel', 'SplinterPreTrainedModel', 'SplinterTokenizer', 'SplinterTokenizerFast', 'SquadDataTrainingArguments', 'SquadDataset', 'SquadExample', 'SquadFeatures', 'SquadV1Processor', 'SquadV2Processor', 'SqueezeBertConfig', 'SqueezeBertForMaskedLM', 'SqueezeBertForMultipleChoice', 'SqueezeBertForQuestionAnswering', 'SqueezeBertForSequenceClassification', 'SqueezeBertForTokenClassification', 'SqueezeBertModel', 'SqueezeBertModule', 'SqueezeBertOnnxConfig', 'SqueezeBertPreTrainedModel', 'SqueezeBertTokenizer', 'SqueezeBertTokenizerFast', 'StableLmConfig', 'StableLmForCausalLM', 'StableLmForSequenceClassification', 'StableLmForTokenClassification', 'StableLmModel', 'StableLmPreTrainedModel', 'Starcoder2Config', 'Starcoder2ForCausalLM', 'Starcoder2ForSequenceClassification', 'Starcoder2ForTokenClassification', 'Starcoder2Model', 'Starcoder2PreTrainedModel', 'StaticCache', 'StaticLayer', 'StopStringCriteria', 'StoppingCriteria', 'StoppingCriteriaList', 'SummarizationPipeline', 'SuperGlueConfig', 'SuperGlueForKeypointMatching', 'SuperGlueImageProcessor', 'SuperGluePreTrainedModel', 'SuperPointConfig', 'SuperPointForKeypointDetection', 'SuperPointImageProcessor', 'SuperPointImageProcessorFast', 'SuperPointPreTrainedModel', 'SuppressTokensAtBeginLogitsProcessor', 'SuppressTokensLogitsProcessor', 'SwiftFormerConfig', 'SwiftFormerForImageClassification', 'SwiftFormerModel', 'SwiftFormerOnnxConfig', 'SwiftFormerPreTrainedModel', 'Swin2SRConfig', 'Swin2SRForImageSuperResolution', 'Swin2SRImageProcessor', 'Swin2SRImageProcessorFast', 'Swin2SRModel', 'Swin2SRPreTrainedModel', 'SwinBackbone', 'SwinConfig', 'SwinForImageClassification', 'SwinForMaskedImageModeling', 'SwinModel', 'SwinOnnxConfig', 'SwinPreTrainedModel', 'Swinv2Backbone', 'Swinv2Config', 'Swinv2ForImageClassification', 'Swinv2ForMaskedImageModeling', 'Swinv2Model', 'Swinv2PreTrainedModel', 'SwitchTransformersConfig', 'SwitchTransformersEncoderModel', 'SwitchTransformersForConditionalGeneration', 'SwitchTransformersModel', 'SwitchTransformersPreTrainedModel', 'SwitchTransformersSparseMLP', 'SwitchTransformersTop1Router', 'SynthIDTextWatermarkDetector', 'SynthIDTextWatermarkLogitsProcessor', 'SynthIDTextWatermarkingConfig', 'T5Config', 'T5EncoderModel', 'T5ForConditionalGeneration', 'T5ForQuestionAnswering', 'T5ForSequenceClassification', 'T5ForTokenClassification', 'T5GemmaConfig', 'T5GemmaEncoderModel', 'T5GemmaForConditionalGeneration', 'T5GemmaForSequenceClassification', 'T5GemmaForTokenClassification', 'T5GemmaModel', 'T5GemmaModuleConfig', 'T5GemmaPreTrainedModel', 'T5Model', 'T5OnnxConfig', 'T5PreTrainedModel', 'T5Tokenizer', 'T5TokenizerFast', 'TF2_WEIGHTS_NAME', 'TFAdaptiveEmbedding', 'TFAlbertForMaskedLM', 'TFAlbertForMultipleChoice', 'TFAlbertForPreTraining', 'TFAlbertForQuestionAnswering', 'TFAlbertForSequenceClassification', 'TFAlbertForTokenClassification', 'TFAlbertMainLayer', 'TFAlbertModel', 'TFAlbertPreTrainedModel', 'TFAutoModel', 'TFAutoModelForAudioClassification', 'TFAutoModelForCausalLM', 'TFAutoModelForDocumentQuestionAnswering', 'TFAutoModelForImageClassification', 'TFAutoModelForMaskGeneration', 'TFAutoModelForMaskedImageModeling', 'TFAutoModelForMaskedLM', 'TFAutoModelForMultipleChoice', 'TFAutoModelForNextSentencePrediction', 'TFAutoModelForPreTraining', 'TFAutoModelForQuestionAnswering', 'TFAutoModelForSemanticSegmentation', 'TFAutoModelForSeq2SeqLM', 'TFAutoModelForSequenceClassification', 'TFAutoModelForSpeechSeq2Seq', 'TFAutoModelForTableQuestionAnswering', 'TFAutoModelForTextEncoding', 'TFAutoModelForTokenClassification', 'TFAutoModelForVision2Seq', 'TFAutoModelForZeroShotImageClassification', 'TFAutoModelWithLMHead', 'TFBartForConditionalGeneration', 'TFBartForSequenceClassification', 'TFBartModel', 'TFBartPretrainedModel', 'TFBertEmbeddings', 'TFBertForMaskedLM', 'TFBertForMultipleChoice', 'TFBertForNextSentencePrediction', 'TFBertForPreTraining', 'TFBertForQuestionAnswering', 'TFBertForSequenceClassification', 'TFBertForTokenClassification', 'TFBertLMHeadModel', 'TFBertMainLayer', 'TFBertModel', 'TFBertPreTrainedModel', 'TFBertTokenizer', 'TFBlenderbotForConditionalGeneration', 'TFBlenderbotModel', 'TFBlenderbotPreTrainedModel', 'TFBlenderbotSmallForConditionalGeneration', 'TFBlenderbotSmallModel', 'TFBlenderbotSmallPreTrainedModel', 'TFBlipForConditionalGeneration', 'TFBlipForImageTextRetrieval', 'TFBlipForQuestionAnswering', 'TFBlipModel', 'TFBlipPreTrainedModel', 'TFBlipTextLMHeadModel', 'TFBlipTextModel', 'TFBlipTextPreTrainedModel', 'TFBlipVisionModel', 'TFCLIPModel', 'TFCLIPPreTrainedModel', 'TFCLIPTextModel', 'TFCLIPVisionModel', 'TFCTRLForSequenceClassification', 'TFCTRLLMHeadModel', 'TFCTRLModel', 'TFCTRLPreTrainedModel', 'TFCamembertForCausalLM', 'TFCamembertForMaskedLM', 'TFCamembertForMultipleChoice', 'TFCamembertForQuestionAnswering', 'TFCamembertForSequenceClassification', 'TFCamembertForTokenClassification', 'TFCamembertModel', 'TFCamembertPreTrainedModel', 'TFConvBertForMaskedLM', 'TFConvBertForMultipleChoice', 'TFConvBertForQuestionAnswering', 'TFConvBertForSequenceClassification', 'TFConvBertForTokenClassification', 'TFConvBertLayer', 'TFConvBertModel', 'TFConvBertPreTrainedModel', 'TFConvNextForImageClassification', 'TFConvNextModel', 'TFConvNextPreTrainedModel', 'TFConvNextV2ForImageClassification', 'TFConvNextV2Model', 'TFConvNextV2PreTrainedModel', 'TFCvtForImageClassification', 'TFCvtModel', 'TFCvtPreTrainedModel', 'TFDPRContextEncoder', 'TFDPRPretrainedContextEncoder', 'TFDPRPretrainedQuestionEncoder', 'TFDPRPretrainedReader', 'TFDPRQuestionEncoder', 'TFDPRReader', 'TFData2VecVisionForImageClassification', 'TFData2VecVisionForSemanticSegmentation', 'TFData2VecVisionModel', 'TFData2VecVisionPreTrainedModel', 'TFDebertaForMaskedLM', 'TFDebertaForQuestionAnswering', 'TFDebertaForSequenceClassification', 'TFDebertaForTokenClassification', 'TFDebertaModel', 'TFDebertaPreTrainedModel', 'TFDebertaV2ForMaskedLM', 'TFDebertaV2ForMultipleChoice', 'TFDebertaV2ForQuestionAnswering', 'TFDebertaV2ForSequenceClassification', 'TFDebertaV2ForTokenClassification', 'TFDebertaV2Model', 'TFDebertaV2PreTrainedModel', 'TFDeiTForImageClassification', 'TFDeiTForImageClassificationWithTeacher', 'TFDeiTForMaskedImageModeling', 'TFDeiTModel', 'TFDeiTPreTrainedModel', 'TFDistilBertForMaskedLM', 'TFDistilBertForMultipleChoice', 'TFDistilBertForQuestionAnswering', 'TFDistilBertForSequenceClassification', 'TFDistilBertForTokenClassification', 'TFDistilBertMainLayer', 'TFDistilBertModel', 'TFDistilBertPreTrainedModel', 'TFEfficientFormerForImageClassification', 'TFEfficientFormerForImageClassificationWithTeacher', 'TFEfficientFormerModel', 'TFEfficientFormerPreTrainedModel', 'TFElectraForMaskedLM', 'TFElectraForMultipleChoice', 'TFElectraForPreTraining', 'TFElectraForQuestionAnswering', 'TFElectraForSequenceClassification', 'TFElectraForTokenClassification', 'TFElectraModel', 'TFElectraPreTrainedModel', 'TFEncoderDecoderModel', 'TFEsmForMaskedLM', 'TFEsmForSequenceClassification', 'TFEsmForTokenClassification', 'TFEsmModel', 'TFEsmPreTrainedModel', 'TFFlaubertForMultipleChoice', 'TFFlaubertForQuestionAnsweringSimple', 'TFFlaubertForSequenceClassification', 'TFFlaubertForTokenClassification', 'TFFlaubertModel', 'TFFlaubertPreTrainedModel', 'TFFlaubertWithLMHeadModel', 'TFForceTokensLogitsProcessor', 'TFForcedBOSTokenLogitsProcessor', 'TFForcedEOSTokenLogitsProcessor', 'TFFunnelBaseModel', 'TFFunnelForMaskedLM', 'TFFunnelForMultipleChoice', 'TFFunnelForPreTraining', 'TFFunnelForQuestionAnswering', 'TFFunnelForSequenceClassification', 'TFFunnelForTokenClassification', 'TFFunnelModel', 'TFFunnelPreTrainedModel', 'TFGPT2DoubleHeadsModel', 'TFGPT2ForSequenceClassification', 'TFGPT2LMHeadModel', 'TFGPT2MainLayer', 'TFGPT2Model', 'TFGPT2PreTrainedModel', 'TFGPT2Tokenizer', 'TFGPTJForCausalLM', 'TFGPTJForQuestionAnswering', 'TFGPTJForSequenceClassification', 'TFGPTJModel', 'TFGPTJPreTrainedModel', 'TFGenerationMixin', 'TFGroupViTModel', 'TFGroupViTPreTrainedModel', 'TFGroupViTTextModel', 'TFGroupViTVisionModel', 'TFHubertForCTC', 'TFHubertModel', 'TFHubertPreTrainedModel', 'TFIdeficsForVisionText2Text', 'TFIdeficsModel', 'TFIdeficsPreTrainedModel', 'TFLEDForConditionalGeneration', 'TFLEDModel', 'TFLEDPreTrainedModel', 'TFLayoutLMForMaskedLM', 'TFLayoutLMForQuestionAnswering', 'TFLayoutLMForSequenceClassification', 'TFLayoutLMForTokenClassification', 'TFLayoutLMMainLayer', 'TFLayoutLMModel', 'TFLayoutLMPreTrainedModel', 'TFLayoutLMv3ForQuestionAnswering', 'TFLayoutLMv3ForSequenceClassification', 'TFLayoutLMv3ForTokenClassification', 'TFLayoutLMv3Model', 'TFLayoutLMv3PreTrainedModel', 'TFLogitsProcessor', 'TFLogitsProcessorList', 'TFLogitsWarper', 'TFLongformerForMaskedLM', 'TFLongformerForMultipleChoice', 'TFLongformerForQuestionAnswering', 'TFLongformerForSequenceClassification', 'TFLongformerForTokenClassification', 'TFLongformerModel', 'TFLongformerPreTrainedModel', 'TFLongformerSelfAttention', 'TFLxmertForPreTraining', 'TFLxmertMainLayer', 'TFLxmertModel', 'TFLxmertPreTrainedModel', 'TFLxmertVisualFeatureEncoder', 'TFMBartForConditionalGeneration', 'TFMBartModel', 'TFMBartPreTrainedModel', 'TFMPNetEmbeddings', 'TFMPNetForMaskedLM', 'TFMPNetForMultipleChoice', 'TFMPNetForQuestionAnswering', 'TFMPNetForSequenceClassification', 'TFMPNetForTokenClassification', 'TFMPNetMainLayer', 'TFMPNetModel', 'TFMPNetPreTrainedModel', 'TFMT5EncoderModel', 'TFMT5ForConditionalGeneration', 'TFMT5Model', 'TFMarianMTModel', 'TFMarianModel', 'TFMarianPreTrainedModel', 'TFMinLengthLogitsProcessor', 'TFMistralForCausalLM', 'TFMistralForSequenceClassification', 'TFMistralModel', 'TFMistralPreTrainedModel', 'TFMobileBertForMaskedLM', 'TFMobileBertForMultipleChoice', 'TFMobileBertForNextSentencePrediction', 'TFMobileBertForPreTraining', 'TFMobileBertForQuestionAnswering', 'TFMobileBertForSequenceClassification', 'TFMobileBertForTokenClassification', 'TFMobileBertMainLayer', 'TFMobileBertModel', 'TFMobileBertPreTrainedModel', 'TFMobileViTForImageClassification', 'TFMobileViTForSemanticSegmentation', 'TFMobileViTModel', 'TFMobileViTPreTrainedModel', 'TFNoBadWordsLogitsProcessor', 'TFNoRepeatNGramLogitsProcessor', 'TFOPTForCausalLM', 'TFOPTModel', 'TFOPTPreTrainedModel', 'TFOpenAIGPTDoubleHeadsModel', 'TFOpenAIGPTForSequenceClassification', 'TFOpenAIGPTLMHeadModel', 'TFOpenAIGPTMainLayer', 'TFOpenAIGPTModel', 'TFOpenAIGPTPreTrainedModel', 'TFPegasusForConditionalGeneration', 'TFPegasusModel', 'TFPegasusPreTrainedModel', 'TFPreTrainedModel', 'TFRagModel', 'TFRagPreTrainedModel', 'TFRagSequenceForGeneration', 'TFRagTokenForGeneration', 'TFRegNetForImageClassification', 'TFRegNetModel', 'TFRegNetPreTrainedModel', 'TFRemBertForCausalLM', 'TFRemBertForMaskedLM', 'TFRemBertForMultipleChoice', 'TFRemBertForQuestionAnswering', 'TFRemBertForSequenceClassification', 'TFRemBertForTokenClassification', 'TFRemBertLayer', 'TFRemBertModel', 'TFRemBertPreTrainedModel', 'TFRepetitionPenaltyLogitsProcessor', 'TFResNetForImageClassification', 'TFResNetModel', 'TFResNetPreTrainedModel', 'TFRoFormerForCausalLM', 'TFRoFormerForMaskedLM', 'TFRoFormerForMultipleChoice', 'TFRoFormerForQuestionAnswering', 'TFRoFormerForSequenceClassification', 'TFRoFormerForTokenClassification', 'TFRoFormerLayer', 'TFRoFormerModel', 'TFRoFormerPreTrainedModel', 'TFRobertaForCausalLM', 'TFRobertaForMaskedLM', 'TFRobertaForMultipleChoice', 'TFRobertaForQuestionAnswering', 'TFRobertaForSequenceClassification', 'TFRobertaForTokenClassification', 'TFRobertaMainLayer', 'TFRobertaModel', 'TFRobertaPreLayerNormForCausalLM', 'TFRobertaPreLayerNormForMaskedLM', 'TFRobertaPreLayerNormForMultipleChoice', 'TFRobertaPreLayerNormForQuestionAnswering', 'TFRobertaPreLayerNormForSequenceClassification', 'TFRobertaPreLayerNormForTokenClassification', 'TFRobertaPreLayerNormMainLayer', 'TFRobertaPreLayerNormModel', 'TFRobertaPreLayerNormPreTrainedModel', 'TFRobertaPreTrainedModel', 'TFSamModel', 'TFSamPreTrainedModel', 'TFSamVisionModel', 'TFSegformerDecodeHead', 'TFSegformerForImageClassification', 'TFSegformerForSemanticSegmentation', 'TFSegformerModel', 'TFSegformerPreTrainedModel', 'TFSequenceSummary', 'TFSharedEmbeddings', 'TFSpeech2TextForConditionalGeneration', 'TFSpeech2TextModel', 'TFSpeech2TextPreTrainedModel', 'TFSuppressTokensAtBeginLogitsProcessor', 'TFSuppressTokensLogitsProcessor', 'TFSwiftFormerForImageClassification', 'TFSwiftFormerModel', 'TFSwiftFormerPreTrainedModel', 'TFSwinForImageClassification', 'TFSwinForMaskedImageModeling', 'TFSwinModel', 'TFSwinPreTrainedModel', 'TFT5EncoderModel', 'TFT5ForConditionalGeneration', 'TFT5Model', 'TFT5PreTrainedModel', 'TFTapasForMaskedLM', 'TFTapasForQuestionAnswering', 'TFTapasForSequenceClassification', 'TFTapasModel', 'TFTapasPreTrainedModel', 'TFTemperatureLogitsWarper', 'TFTopKLogitsWarper', 'TFTopPLogitsWarper', 'TFTrainingArguments', 'TFTransfoXLForSequenceClassification', 'TFTransfoXLLMHeadModel', 'TFTransfoXLMainLayer', 'TFTransfoXLModel', 'TFTransfoXLPreTrainedModel', 'TFViTForImageClassification', 'TFViTMAEForPreTraining', 'TFViTMAEModel', 'TFViTMAEPreTrainedModel', 'TFViTModel', 'TFViTPreTrainedModel', 'TFVisionEncoderDecoderModel', 'TFVisionTextDualEncoderModel', 'TFWav2Vec2ForCTC', 'TFWav2Vec2ForSequenceClassification', 'TFWav2Vec2Model', 'TFWav2Vec2PreTrainedModel', 'TFWhisperForConditionalGeneration', 'TFWhisperModel', 'TFWhisperPreTrainedModel', 'TFXGLMForCausalLM', 'TFXGLMModel', 'TFXGLMPreTrainedModel', 'TFXLMForMultipleChoice', 'TFXLMForQuestionAnsweringSimple', 'TFXLMForSequenceClassification', 'TFXLMForTokenClassification', 'TFXLMMainLayer', 'TFXLMModel', 'TFXLMPreTrainedModel', 'TFXLMRobertaForCausalLM', 'TFXLMRobertaForMaskedLM', 'TFXLMRobertaForMultipleChoice', 'TFXLMRobertaForQuestionAnswering', 'TFXLMRobertaForSequenceClassification', 'TFXLMRobertaForTokenClassification', 'TFXLMRobertaModel', 'TFXLMRobertaPreTrainedModel', 'TFXLMWithLMHeadModel', 'TFXLNetForMultipleChoice', 'TFXLNetForQuestionAnsweringSimple', 'TFXLNetForSequenceClassification', 'TFXLNetForTokenClassification', 'TFXLNetLMHeadModel', 'TFXLNetMainLayer', 'TFXLNetModel', 'TFXLNetPreTrainedModel', 'TF_MODEL_FOR_AUDIO_CLASSIFICATION_MAPPING', 'TF_MODEL_FOR_CAUSAL_LM_MAPPING', 'TF_MODEL_FOR_DOCUMENT_QUESTION_ANSWERING_MAPPING', 'TF_MODEL_FOR_IMAGE_CLASSIFICATION_MAPPING', 'TF_MODEL_FOR_MASKED_IMAGE_MODELING_MAPPING', 'TF_MODEL_FOR_MASKED_LM_MAPPING', 'TF_MODEL_FOR_MASK_GENERATION_MAPPING', 'TF_MODEL_FOR_MULTIPLE_CHOICE_MAPPING', 'TF_MODEL_FOR_NEXT_SENTENCE_PREDICTION_MAPPING', 'TF_MODEL_FOR_PRETRAINING_MAPPING', 'TF_MODEL_FOR_QUESTION_ANSWERING_MAPPING', 'TF_MODEL_FOR_SEMANTIC_SEGMENTATION_MAPPING', 'TF_MODEL_FOR_SEQUENCE_CLASSIFICATION_MAPPING', 'TF_MODEL_FOR_SEQ_TO_SEQ_CAUSAL_LM_MAPPING', 'TF_MODEL_FOR_SPEECH_SEQ_2_SEQ_MAPPING', 'TF_MODEL_FOR_TABLE_QUESTION_ANSWERING_MAPPING', 'TF_MODEL_FOR_TEXT_ENCODING_MAPPING', 'TF_MODEL_FOR_TOKEN_CLASSIFICATION_MAPPING', 'TF_MODEL_FOR_VISION_2_SEQ_MAPPING', 'TF_MODEL_FOR_ZERO_SHOT_IMAGE_CLASSIFICATION_MAPPING', 'TF_MODEL_MAPPING', 'TF_MODEL_WITH_LM_HEAD_MAPPING', 'TF_WEIGHTS_NAME', 'TOKENIZER_MAPPING', 'TRANSFORMERS_CACHE', 'TableQuestionAnsweringPipeline', 'TableTransformerConfig', 'TableTransformerForObjectDetection', 'TableTransformerModel', 'TableTransformerOnnxConfig', 'TableTransformerPreTrainedModel', 'TapasConfig', 'TapasForMaskedLM', 'TapasForQuestionAnswering', 'TapasForSequenceClassification', 'TapasModel', 'TapasPreTrainedModel', 'TapasTokenizer', 'TapexTokenizer', 'TemperatureLogitsWarper', 'TensorType', 'Text2TextGenerationPipeline', 'TextClassificationPipeline', 'TextDataset', 'TextDatasetForNextSentencePrediction', 'TextGenerationPipeline', 'TextIteratorStreamer', 'TextNetBackbone', 'TextNetConfig', 'TextNetForImageClassification', 'TextNetImageProcessor', 'TextNetModel', 'TextNetPreTrainedModel', 'TextStreamer', 'TextToAudioPipeline', 'TimeSeriesTransformerConfig', 'TimeSeriesTransformerForPrediction', 'TimeSeriesTransformerModel', 'TimeSeriesTransformerPreTrainedModel', 'TimesFmConfig', 'TimesFmModel', 'TimesFmModelForPrediction', 'TimesFmPreTrainedModel', 'TimesformerConfig', 'TimesformerForVideoClassification', 'TimesformerModel', 'TimesformerPreTrainedModel', 'TimmBackbone', 'TimmBackboneConfig', 'TimmWrapperConfig', 'TimmWrapperForImageClassification', 'TimmWrapperImageProcessor', 'TimmWrapperModel', 'TimmWrapperPreTrainedModel', 'TokenClassificationPipeline', 'TokenSpan', 'TopKLogitsWarper', 'TopPLogitsWarper', 'TorchAoConfig', 'TorchExportableModuleWithStaticCache', 'TrOCRConfig', 'TrOCRForCausalLM', 'TrOCRPreTrainedModel', 'TrOCRProcessor', 'Trainer', 'TrainerCallback', 'TrainerControl', 'TrainerState', 'TrainingArguments', 'TrajectoryTransformerConfig', 'TrajectoryTransformerModel', 'TrajectoryTransformerPreTrainedModel', 'TransfoXLConfig', 'TransfoXLCorpus', 'TransfoXLForSequenceClassification', 'TransfoXLLMHeadModel', 'TransfoXLModel', 'TransfoXLPreTrainedModel', 'TransfoXLTokenizer', 'TranslationPipeline', 'TvltConfig', 'TvltFeatureExtractor', 'TvltForAudioVisualClassification', 'TvltForPreTraining', 'TvltImageProcessor', 'TvltModel', 'TvltPreTrainedModel', 'TvltProcessor', 'TvpConfig', 'TvpForVideoGrounding', 'TvpImageProcessor', 'TvpModel', 'TvpPreTrainedModel', 'TvpProcessor', 'TypicalLogitsWarper', 'UMT5Config', 'UMT5EncoderModel', 'UMT5ForConditionalGeneration', 'UMT5ForQuestionAnswering', 'UMT5ForSequenceClassification', 'UMT5ForTokenClassification', 'UMT5Model', 'UMT5OnnxConfig', 'UMT5PreTrainedModel', 'UdopConfig', 'UdopEncoderModel', 'UdopForConditionalGeneration', 'UdopModel', 'UdopPreTrainedModel', 'UdopProcessor', 'UdopTokenizer', 'UdopTokenizerFast', 'UnbatchedClassifierFreeGuidanceLogitsProcessor', 'UniSpeechConfig', 'UniSpeechForCTC', 'UniSpeechForPreTraining', 'UniSpeechForSequenceClassification', 'UniSpeechModel', 'UniSpeechPreTrainedModel', 'UniSpeechSatConfig', 'UniSpeechSatForAudioFrameClassification', 'UniSpeechSatForCTC', 'UniSpeechSatForPreTraining', 'UniSpeechSatForSequenceClassification', 'UniSpeechSatForXVector', 'UniSpeechSatModel', 'UniSpeechSatPreTrainedModel', 'UnivNetConfig', 'UnivNetFeatureExtractor', 'UnivNetModel', 'UperNetConfig', 'UperNetForSemanticSegmentation', 'UperNetPreTrainedModel', 'VIDEO_PROCESSOR_MAPPING', 'VJEPA2Config', 'VJEPA2ForVideoClassification', 'VJEPA2Model', 'VJEPA2PreTrainedModel', 'VJEPA2VideoProcessor', 'VanConfig', 'VanForImageClassification', 'VanModel', 'VanPreTrainedModel', 'ViTConfig', 'ViTFeatureExtractor', 'ViTForImageClassification', 'ViTForMaskedImageModeling', 'ViTHybridConfig', 'ViTHybridForImageClassification', 'ViTHybridImageProcessor', 'ViTHybridModel', 'ViTHybridPreTrainedModel', 'ViTImageProcessor', 'ViTImageProcessorFast', 'ViTMAEConfig', 'ViTMAEForPreTraining', 'ViTMAELayer', 'ViTMAEModel', 'ViTMAEPreTrainedModel', 'ViTMSNConfig', 'ViTMSNForImageClassification', 'ViTMSNModel', 'ViTMSNPreTrainedModel', 'ViTModel', 'ViTOnnxConfig', 'ViTPreTrainedModel', 'VideoClassificationPipeline', 'VideoLlavaConfig', 'VideoLlavaForConditionalGeneration', 'VideoLlavaImageProcessor', 'VideoLlavaModel', 'VideoLlavaPreTrainedModel', 'VideoLlavaProcessor', 'VideoLlavaVideoProcessor', 'VideoMAEConfig', 'VideoMAEFeatureExtractor', 'VideoMAEForPreTraining', 'VideoMAEForVideoClassification', 'VideoMAEImageProcessor', 'VideoMAEModel', 'VideoMAEPreTrainedModel', 'ViltConfig', 'ViltFeatureExtractor', 'ViltForImageAndTextRetrieval', 'ViltForImagesAndTextClassification', 'ViltForMaskedLM', 'ViltForQuestionAnswering', 'ViltForTokenClassification', 'ViltImageProcessor', 'ViltImageProcessorFast', 'ViltLayer', 'ViltModel', 'ViltPreTrainedModel', 'ViltProcessor', 'VipLlavaConfig', 'VipLlavaForConditionalGeneration', 'VipLlavaModel', 'VipLlavaPreTrainedModel', 'VisionEncoderDecoderConfig', 'VisionEncoderDecoderModel', 'VisionEncoderDecoderOnnxConfig', 'VisionTextDualEncoderConfig', 'VisionTextDualEncoderModel', 'VisionTextDualEncoderProcessor', 'VisualBertConfig', 'VisualBertForMultipleChoice', 'VisualBertForPreTraining', 'VisualBertForQuestionAnswering', 'VisualBertForRegionToPhraseAlignment', 'VisualBertForVisualReasoning', 'VisualBertLayer', 'VisualBertModel', 'VisualBertPreTrainedModel', 'VisualQuestionAnsweringPipeline', 'VitDetBackbone', 'VitDetConfig', 'VitDetModel', 'VitDetPreTrainedModel', 'VitMatteConfig', 'VitMatteForImageMatting', 'VitMatteImageProcessor', 'VitMatteImageProcessorFast', 'VitMattePreTrainedModel', 'VitPoseBackbone', 'VitPoseBackboneConfig', 'VitPoseBackbonePreTrainedModel', 'VitPoseConfig', 'VitPoseForPoseEstimation', 'VitPoseImageProcessor', 'VitPosePreTrainedModel', 'VitsConfig', 'VitsModel', 'VitsPreTrainedModel', 'VitsTokenizer', 'VivitConfig', 'VivitForVideoClassification', 'VivitImageProcessor', 'VivitModel', 'VivitPreTrainedModel', 'VoxtralConfig', 'VoxtralEncoder', 'VoxtralEncoderConfig', 'VoxtralForConditionalGeneration', 'VoxtralPreTrainedModel', 'VoxtralProcessor', 'VptqConfig', 'WEIGHTS_NAME', 'WarmUp', 'WatermarkDetector', 'WatermarkLogitsProcessor', 'WatermarkingConfig', 'Wav2Vec2BertConfig', 'Wav2Vec2BertForAudioFrameClassification', 'Wav2Vec2BertForCTC', 'Wav2Vec2BertForSequenceClassification', 'Wav2Vec2BertForXVector', 'Wav2Vec2BertModel', 'Wav2Vec2BertPreTrainedModel', 'Wav2Vec2BertProcessor', 'Wav2Vec2CTCTokenizer', 'Wav2Vec2Config', 'Wav2Vec2ConformerConfig', 'Wav2Vec2ConformerForAudioFrameClassification', 'Wav2Vec2ConformerForCTC', 'Wav2Vec2ConformerForPreTraining', 'Wav2Vec2ConformerForSequenceClassification', 'Wav2Vec2ConformerForXVector', 'Wav2Vec2ConformerModel', 'Wav2Vec2ConformerPreTrainedModel', 'Wav2Vec2FeatureExtractor', 'Wav2Vec2ForAudioFrameClassification', 'Wav2Vec2ForCTC', 'Wav2Vec2ForMaskedLM', 'Wav2Vec2ForPreTraining', 'Wav2Vec2ForSequenceClassification', 'Wav2Vec2ForXVector', 'Wav2Vec2Model', 'Wav2Vec2PhonemeCTCTokenizer', 'Wav2Vec2PreTrainedModel', 'Wav2Vec2Processor', 'Wav2Vec2ProcessorWithLM', 'Wav2Vec2Tokenizer', 'WavLMConfig', 'WavLMForAudioFrameClassification', 'WavLMForCTC', 'WavLMForSequenceClassification', 'WavLMForXVector', 'WavLMModel', 'WavLMPreTrainedModel', 'WhisperConfig', 'WhisperFeatureExtractor', 'WhisperForAudioClassification', 'WhisperForCausalLM', 'WhisperForConditionalGeneration', 'WhisperModel', 'WhisperOnnxConfig', 'WhisperPreTrainedModel', 'WhisperProcessor', 'WhisperTimeStampLogitsProcessor', 'WhisperTokenizer', 'WhisperTokenizerFast', 'WordpieceTokenizer', 'XCLIPConfig', 'XCLIPModel', 'XCLIPPreTrainedModel', 'XCLIPProcessor', 'XCLIPTextConfig', 'XCLIPTextModel', 'XCLIPVisionConfig', 'XCLIPVisionModel', 'XGLMConfig', 'XGLMForCausalLM', 'XGLMModel', 'XGLMPreTrainedModel', 'XGLMTokenizer', 'XGLMTokenizerFast', 'XLMConfig', 'XLMForMultipleChoice', 'XLMForQuestionAnswering', 'XLMForQuestionAnsweringSimple', 'XLMForSequenceClassification', 'XLMForTokenClassification', 'XLMModel', 'XLMOnnxConfig', 'XLMPreTrainedModel', 'XLMProphetNetConfig', 'XLMProphetNetDecoder', 'XLMProphetNetEncoder', 'XLMProphetNetForCausalLM', 'XLMProphetNetForConditionalGeneration', 'XLMProphetNetModel', 'XLMProphetNetPreTrainedModel', 'XLMProphetNetTokenizer', 'XLMRobertaConfig', 'XLMRobertaForCausalLM', 'XLMRobertaForMaskedLM', 'XLMRobertaForMultipleChoice', 'XLMRobertaForQuestionAnswering', 'XLMRobertaForSequenceClassification', 'XLMRobertaForTokenClassification', 'XLMRobertaModel', 'XLMRobertaOnnxConfig', 'XLMRobertaPreTrainedModel', 'XLMRobertaTokenizer', 'XLMRobertaTokenizerFast', 'XLMRobertaXLConfig', 'XLMRobertaXLForCausalLM', 'XLMRobertaXLForMaskedLM', 'XLMRobertaXLForMultipleChoice', 'XLMRobertaXLForQuestionAnswering', 'XLMRobertaXLForSequenceClassification', 'XLMRobertaXLForTokenClassification', 'XLMRobertaXLModel', 'XLMRobertaXLOnnxConfig', 'XLMRobertaXLPreTrainedModel', 'XLMTokenizer', 'XLMWithLMHeadModel', 'XLNetConfig', 'XLNetForMultipleChoice', 'XLNetForQuestionAnswering', 'XLNetForQuestionAnsweringSimple', 'XLNetForSequenceClassification', 'XLNetForTokenClassification', 'XLNetLMHeadModel', 'XLNetModel', 'XLNetPreTrainedModel', 'XLNetTokenizer', 'XLNetTokenizerFast', 'XmodConfig', 'XmodForCausalLM', 'XmodForMaskedLM', 'XmodForMultipleChoice', 'XmodForQuestionAnswering', 'XmodForSequenceClassification', 'XmodForTokenClassification', 'XmodModel', 'XmodOnnxConfig', 'XmodPreTrainedModel', 'YolosConfig', 'YolosFeatureExtractor', 'YolosForObjectDetection', 'YolosImageProcessor', 'YolosImageProcessorFast', 'YolosModel', 'YolosOnnxConfig', 'YolosPreTrainedModel', 'YosoConfig', 'YosoForMaskedLM', 'YosoForMultipleChoice', 'YosoForQuestionAnswering', 'YosoForSequenceClassification', 'YosoForTokenClassification', 'YosoLayer', 'YosoModel', 'YosoPreTrainedModel', 'ZOEDEPTH_PRETRAINED_CONFIG_ARCHIVE_MAP', 'Zamba2Config', 'Zamba2ForCausalLM', 'Zamba2ForSequenceClassification', 'Zamba2Model', 'Zamba2PreTrainedModel', 'ZambaConfig', 'ZambaForCausalLM', 'ZambaForSequenceClassification', 'ZambaModel', 'ZambaPreTrainedModel', 'ZeroShotAudioClassificationPipeline', 'ZeroShotClassificationPipeline', 'ZeroShotImageClassificationPipeline', 'ZeroShotObjectDetectionPipeline', 'ZoeDepthConfig', 'ZoeDepthForDepthEstimation', 'ZoeDepthImageProcessor', 'ZoeDepthImageProcessorFast', 'ZoeDepthPreTrainedModel', '__all__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__path__', '__spec__', '_class_to_module', '_explicit_import_shortcut', '_import_structure', '_modules', '_name', '_object_missing_backend', '_objects', 'activations', 'add_end_docstrings', 'add_start_docstrings', 'apply_chunking_to_forward', 'audio_utils', 'cache_utils', 'commands', 'configuration_utils', 'convert_and_export_with_cache', 'convert_graph_to_onnx', 'convert_slow_tokenizer', 'convert_slow_tokenizers_checkpoints_to_fast', 'convert_tf_hub_seq_to_seq_bert_to_pytorch', 'convert_tf_weight_name_to_pt_weight_name', 'create_optimizer', 'data', 'data.data_collator', 'data.datasets', 'data.metrics', 'data.processors', 'debug_utils', 'default_data_collator', 'dependency_versions_check', 'dependency_versions_table', 'dynamic_module_utils', 'dynamic_rope_update', 'enable_full_determinism', 'feature_extraction_sequence_utils', 'feature_extraction_utils', 'file_utils', 'generation', 'get_constant_schedule', 'get_constant_schedule_with_warmup', 'get_cosine_schedule_with_warmup', 'get_cosine_with_hard_restarts_schedule_with_warmup', 'get_inverse_sqrt_schedule', 'get_linear_schedule_with_warmup', 'get_polynomial_decay_schedule_with_warmup', 'get_scheduler', 'get_values', 'get_wsd_schedule', 'glue_compute_metrics', 'glue_convert_examples_to_features', 'glue_output_modes', 'glue_processors', 'glue_tasks_num_labels', 'hf_argparser', 'hyperparameter_search', 'image_processing_base', 'image_processing_utils', 'image_processing_utils_fast', 'image_transforms', 'image_utils', 'integrations', 'integrations.executorch', 'is_apex_available', 'is_av_available', 'is_bitsandbytes_available', 'is_clearml_available', 'is_comet_available', 'is_datasets_available', 'is_dvclive_available', 'is_faiss_available', 'is_flax_available', 'is_keras_nlp_available', 'is_matplotlib_available', 'is_neptune_available', 'is_optuna_available', 'is_phonemizer_available', 'is_psutil_available', 'is_py3nvml_available', 'is_pyctcdecode_available', 'is_ray_available', 'is_ray_tune_available', 'is_sacremoses_available', 'is_safetensors_available', 'is_scipy_available', 'is_sentencepiece_available', 'is_sigopt_available', 'is_sklearn_available', 'is_speech_available', 'is_swanlab_available', 'is_tensorboard_available', 'is_tensorflow_text_available', 'is_tf_available', 'is_timm_available', 'is_tokenizers_available', 'is_torch_available', 'is_torch_hpu_available', 'is_torch_mlu_available', 'is_torch_musa_available', 'is_torch_neuroncore_available', 'is_torch_npu_available', 'is_torch_xla_available', 'is_torch_xpu_available', 'is_torchvision_available', 'is_trackio_available', 'is_vision_available', 'is_wandb_available', 'load_pytorch_checkpoint_in_tf2_model', 'load_pytorch_model_in_tf2_model', 'load_pytorch_weights_in_tf2_model', 'load_tf2_checkpoint_in_pytorch_model', 'load_tf2_model_in_pytorch_model', 'load_tf2_weights_in_pytorch_model', 'load_tf_weights_in_albert', 'load_tf_weights_in_bert', 'load_tf_weights_in_bert_generation', 'load_tf_weights_in_big_bird', 'load_tf_weights_in_canine', 'load_tf_weights_in_convbert', 'load_tf_weights_in_electra', 'load_tf_weights_in_funnel', 'load_tf_weights_in_gpt2', 'load_tf_weights_in_gpt_neo', 'load_tf_weights_in_imagegpt', 'load_tf_weights_in_mobilebert', 'load_tf_weights_in_mobilenet_v1', 'load_tf_weights_in_mobilenet_v2', 'load_tf_weights_in_openai_gpt', 'load_tf_weights_in_qdqbert', 'load_tf_weights_in_realm', 'load_tf_weights_in_rembert', 'load_tf_weights_in_roc_bert', 'load_tf_weights_in_roformer', 'load_tf_weights_in_t5', 'load_tf_weights_in_tapas', 'load_tf_weights_in_trajectory_transformer', 'load_tf_weights_in_transfo_xl', 'load_tf_weights_in_xlnet', 'logging', 'loss', 'masking_utils', 'model_addition_debugger_context', 'model_debugging_utils', 'modelcard', 'modeling_flash_attention_utils', 'modeling_layers', 'modeling_outputs', 'modeling_rope_utils', 'modeling_tf_pytorch_utils', 'modeling_utils', 'models', 'models.aimv2', 'models.aimv2.configuration_aimv2', 'models.aimv2.modeling_aimv2', 'models.albert', 'models.albert.configuration_albert', 'models.albert.modeling_albert', 'models.albert.modeling_flax_albert', 'models.albert.modeling_tf_albert', 'models.albert.tokenization_albert', 'models.albert.tokenization_albert_fast', 'models.align', 'models.align.configuration_align', 'models.align.modeling_align', 'models.align.processing_align', 'models.altclip', 'models.altclip.configuration_altclip', 'models.altclip.modeling_altclip', 'models.altclip.processing_altclip', 'models.arcee', 'models.arcee.configuration_arcee', 'models.arcee.modeling_arcee', 'models.aria', 'models.aria.configuration_aria', 'models.aria.image_processing_aria', 'models.aria.modeling_aria', 'models.aria.processing_aria', 'models.audio_spectrogram_transformer', 'models.audio_spectrogram_transformer.configuration_audio_spectrogram_transformer', 'models.audio_spectrogram_transformer.feature_extraction_audio_spectrogram_transformer', 'models.audio_spectrogram_transformer.modeling_audio_spectrogram_transformer', 'models.auto', 'models.auto.auto_factory', 'models.auto.configuration_auto', 'models.auto.feature_extraction_auto', 'models.auto.image_processing_auto', 'models.auto.modeling_auto', 'models.auto.modeling_flax_auto', 'models.auto.modeling_tf_auto', 'models.auto.processing_auto', 'models.auto.tokenization_auto', 'models.auto.video_processing_auto', 'models.autoformer', 'models.autoformer.configuration_autoformer', 'models.autoformer.modeling_autoformer', 'models.aya_vision', 'models.aya_vision.configuration_aya_vision', 'models.aya_vision.modeling_aya_vision', 'models.aya_vision.processing_aya_vision', 'models.bamba', 'models.bamba.configuration_bamba', 'models.bamba.modeling_bamba', 'models.bark', 'models.bark.configuration_bark', 'models.bark.modeling_bark', 'models.bark.processing_bark', 'models.bart', 'models.bart.configuration_bart', 'models.bart.modeling_bart', 'models.bart.modeling_flax_bart', 'models.bart.modeling_tf_bart', 'models.bart.tokenization_bart', 'models.bart.tokenization_bart_fast', 'models.barthez', 'models.barthez.tokenization_barthez', 'models.barthez.tokenization_barthez_fast', 'models.bartpho', 'models.bartpho.tokenization_bartpho', 'models.beit', 'models.beit.configuration_beit', 'models.beit.feature_extraction_beit', 'models.beit.image_processing_beit', 'models.beit.image_processing_beit_fast', 'models.beit.modeling_beit', 'models.beit.modeling_flax_beit', 'models.bert', 'models.bert.configuration_bert', 'models.bert.modeling_bert', 'models.bert.modeling_flax_bert', 'models.bert.modeling_tf_bert', 'models.bert.tokenization_bert', 'models.bert.tokenization_bert_fast', 'models.bert.tokenization_bert_tf', 'models.bert_generation', 'models.bert_generation.configuration_bert_generation', 'models.bert_generation.modeling_bert_generation', 'models.bert_generation.tokenization_bert_generation', 'models.bert_japanese', 'models.bert_japanese.tokenization_bert_japanese', 'models.bertweet', 'models.bertweet.tokenization_bertweet', 'models.big_bird', 'models.big_bird.configuration_big_bird', 'models.big_bird.modeling_big_bird', 'models.big_bird.modeling_flax_big_bird', 'models.big_bird.tokenization_big_bird', 'models.big_bird.tokenization_big_bird_fast', 'models.bigbird_pegasus', 'models.bigbird_pegasus.configuration_bigbird_pegasus', 'models.bigbird_pegasus.modeling_bigbird_pegasus', 'models.biogpt', 'models.biogpt.configuration_biogpt', 'models.biogpt.modeling_biogpt', 'models.biogpt.tokenization_biogpt', 'models.bit', 'models.bit.configuration_bit', 'models.bit.image_processing_bit', 'models.bit.image_processing_bit_fast', 'models.bit.modeling_bit', 'models.bitnet', 'models.bitnet.configuration_bitnet', 'models.bitnet.modeling_bitnet', 'models.blenderbot', 'models.blenderbot.configuration_blenderbot', 'models.blenderbot.modeling_blenderbot', 'models.blenderbot.modeling_flax_blenderbot', 'models.blenderbot.modeling_tf_blenderbot', 'models.blenderbot.tokenization_blenderbot', 'models.blenderbot.tokenization_blenderbot_fast', 'models.blenderbot_small', 'models.blenderbot_small.configuration_blenderbot_small', 'models.blenderbot_small.modeling_blenderbot_small', 'models.blenderbot_small.modeling_flax_blenderbot_small', 'models.blenderbot_small.modeling_tf_blenderbot_small', 'models.blenderbot_small.tokenization_blenderbot_small', 'models.blenderbot_small.tokenization_blenderbot_small_fast', 'models.blip', 'models.blip.configuration_blip', 'models.blip.image_processing_blip', 'models.blip.image_processing_blip_fast', 'models.blip.modeling_blip', 'models.blip.modeling_blip_text', 'models.blip.modeling_tf_blip', 'models.blip.modeling_tf_blip_text', 'models.blip.processing_blip', 'models.blip_2', 'models.blip_2.configuration_blip_2', 'models.blip_2.modeling_blip_2', 'models.blip_2.processing_blip_2', 'models.bloom', 'models.bloom.configuration_bloom', 'models.bloom.modeling_bloom', 'models.bloom.modeling_flax_bloom', 'models.bloom.tokenization_bloom_fast', 'models.bridgetower', 'models.bridgetower.configuration_bridgetower', 'models.bridgetower.image_processing_bridgetower', 'models.bridgetower.image_processing_bridgetower_fast', 'models.bridgetower.modeling_bridgetower', 'models.bridgetower.processing_bridgetower', 'models.bros', 'models.bros.configuration_bros', 'models.bros.modeling_bros', 'models.bros.processing_bros', 'models.byt5', 'models.byt5.tokenization_byt5', 'models.camembert', 'models.camembert.configuration_camembert', 'models.camembert.modeling_camembert', 'models.camembert.modeling_tf_camembert', 'models.camembert.tokenization_camembert', 'models.camembert.tokenization_camembert_fast', 'models.canine', 'models.canine.configuration_canine', 'models.canine.modeling_canine', 'models.canine.tokenization_canine', 'models.chameleon', 'models.chameleon.configuration_chameleon', 'models.chameleon.image_processing_chameleon', 'models.chameleon.image_processing_chameleon_fast', 'models.chameleon.modeling_chameleon', 'models.chameleon.processing_chameleon', 'models.chinese_clip', 'models.chinese_clip.configuration_chinese_clip', 'models.chinese_clip.feature_extraction_chinese_clip', 'models.chinese_clip.image_processing_chinese_clip', 'models.chinese_clip.image_processing_chinese_clip_fast', 'models.chinese_clip.modeling_chinese_clip', 'models.chinese_clip.processing_chinese_clip', 'models.clap', 'models.clap.configuration_clap', 'models.clap.feature_extraction_clap', 'models.clap.modeling_clap', 'models.clap.processing_clap', 'models.clip', 'models.clip.configuration_clip', 'models.clip.feature_extraction_clip', 'models.clip.image_processing_clip', 'models.clip.image_processing_clip_fast', 'models.clip.modeling_clip', 'models.clip.modeling_flax_clip', 'models.clip.modeling_tf_clip', 'models.clip.processing_clip', 'models.clip.tokenization_clip', 'models.clip.tokenization_clip_fast', 'models.clipseg', 'models.clipseg.configuration_clipseg', 'models.clipseg.modeling_clipseg', 'models.clipseg.processing_clipseg', 'models.clvp', 'models.clvp.configuration_clvp', 'models.clvp.feature_extraction_clvp', 'models.clvp.modeling_clvp', 'models.clvp.processing_clvp', 'models.clvp.tokenization_clvp', 'models.code_llama', 'models.code_llama.tokenization_code_llama', 'models.code_llama.tokenization_code_llama_fast', 'models.codegen', 'models.codegen.configuration_codegen', 'models.codegen.modeling_codegen', 'models.codegen.tokenization_codegen', 'models.codegen.tokenization_codegen_fast', 'models.cohere', 'models.cohere.configuration_cohere', 'models.cohere.modeling_cohere', 'models.cohere.tokenization_cohere_fast', 'models.cohere2', 'models.cohere2.configuration_cohere2', 'models.cohere2.modeling_cohere2', 'models.cohere2_vision', 'models.cohere2_vision.configuration_cohere2_vision', 'models.cohere2_vision.image_processing_cohere2_vision_fast', 'models.cohere2_vision.modeling_cohere2_vision', 'models.cohere2_vision.processing_cohere2_vision', 'models.colpali', 'models.colpali.configuration_colpali', 'models.colpali.modeling_colpali', 'models.colpali.processing_colpali', 'models.colqwen2', 'models.colqwen2.configuration_colqwen2', 'models.colqwen2.modeling_colqwen2', 'models.colqwen2.processing_colqwen2', 'models.conditional_detr', 'models.conditional_detr.configuration_conditional_detr', 'models.conditional_detr.feature_extraction_conditional_detr', 'models.conditional_detr.image_processing_conditional_detr', 'models.conditional_detr.image_processing_conditional_detr_fast', 'models.conditional_detr.modeling_conditional_detr', 'models.convbert', 'models.convbert.configuration_convbert', 'models.convbert.modeling_convbert', 'models.convbert.modeling_tf_convbert', 'models.convbert.tokenization_convbert', 'models.convbert.tokenization_convbert_fast', 'models.convnext', 'models.convnext.configuration_convnext', 'models.convnext.feature_extraction_convnext', 'models.convnext.image_processing_convnext', 'models.convnext.image_processing_convnext_fast', 'models.convnext.modeling_convnext', 'models.convnext.modeling_tf_convnext', 'models.convnextv2', 'models.convnextv2.configuration_convnextv2', 'models.convnextv2.modeling_convnextv2', 'models.convnextv2.modeling_tf_convnextv2', 'models.cpm', 'models.cpm.tokenization_cpm', 'models.cpm.tokenization_cpm_fast', 'models.cpmant', 'models.cpmant.configuration_cpmant', 'models.cpmant.modeling_cpmant', 'models.cpmant.tokenization_cpmant', 'models.csm', 'models.csm.configuration_csm', 'models.csm.modeling_csm', 'models.csm.processing_csm', 'models.ctrl', 'models.ctrl.configuration_ctrl', 'models.ctrl.modeling_ctrl', 'models.ctrl.modeling_tf_ctrl', 'models.ctrl.tokenization_ctrl', 'models.cvt', 'models.cvt.configuration_cvt', 'models.cvt.modeling_cvt', 'models.cvt.modeling_tf_cvt', 'models.d_fine', 'models.d_fine.configuration_d_fine', 'models.d_fine.modeling_d_fine', 'models.dab_detr', 'models.dab_detr.configuration_dab_detr', 'models.dab_detr.modeling_dab_detr', 'models.dac', 'models.dac.configuration_dac', 'models.dac.feature_extraction_dac', 'models.dac.modeling_dac', 'models.data2vec', 'models.data2vec.configuration_data2vec_audio', 'models.data2vec.configuration_data2vec_text', 'models.data2vec.configuration_data2vec_vision', 'models.data2vec.modeling_data2vec_audio', 'models.data2vec.modeling_data2vec_text', 'models.data2vec.modeling_data2vec_vision', 'models.data2vec.modeling_tf_data2vec_vision', 'models.dbrx', 'models.dbrx.configuration_dbrx', 'models.dbrx.modeling_dbrx', 'models.deberta', 'models.deberta.configuration_deberta', 'models.deberta.modeling_deberta', 'models.deberta.modeling_tf_deberta', 'models.deberta.tokenization_deberta', 'models.deberta.tokenization_deberta_fast', 'models.deberta_v2', 'models.deberta_v2.configuration_deberta_v2', 'models.deberta_v2.modeling_deberta_v2', 'models.deberta_v2.modeling_tf_deberta_v2', 'models.deberta_v2.tokenization_deberta_v2', 'models.deberta_v2.tokenization_deberta_v2_fast', 'models.decision_transformer', 'models.decision_transformer.configuration_decision_transformer', 'models.decision_transformer.modeling_decision_transformer', 'models.deepseek_v2', 'models.deepseek_v2.configuration_deepseek_v2', 'models.deepseek_v2.modeling_deepseek_v2', 'models.deepseek_v3', 'models.deepseek_v3.configuration_deepseek_v3', 'models.deepseek_v3.modeling_deepseek_v3', 'models.deepseek_vl', 'models.deepseek_vl.configuration_deepseek_vl', 'models.deepseek_vl.image_processing_deepseek_vl', 'models.deepseek_vl.image_processing_deepseek_vl_fast', 'models.deepseek_vl.modeling_deepseek_vl', 'models.deepseek_vl.processing_deepseek_vl', 'models.deepseek_vl_hybrid', 'models.deepseek_vl_hybrid.configuration_deepseek_vl_hybrid', 'models.deepseek_vl_hybrid.image_processing_deepseek_vl_hybrid', 'models.deepseek_vl_hybrid.image_processing_deepseek_vl_hybrid_fast', 'models.deepseek_vl_hybrid.modeling_deepseek_vl_hybrid', 'models.deepseek_vl_hybrid.processing_deepseek_vl_hybrid', 'models.deformable_detr', 'models.deformable_detr.configuration_deformable_detr', 'models.deformable_detr.feature_extraction_deformable_detr', 'models.deformable_detr.image_processing_deformable_detr', 'models.deformable_detr.image_processing_deformable_detr_fast', 'models.deformable_detr.modeling_deformable_detr', 'models.deit', 'models.deit.configuration_deit', 'models.deit.feature_extraction_deit', 'models.deit.image_processing_deit', 'models.deit.image_processing_deit_fast', 'models.deit.modeling_deit', 'models.deit.modeling_tf_deit', 'models.deprecated', 'models.deprecated.deta', 'models.deprecated.deta.configuration_deta', 'models.deprecated.deta.image_processing_deta', 'models.deprecated.deta.modeling_deta', 'models.deprecated.efficientformer', 'models.deprecated.efficientformer.configuration_efficientformer', 'models.deprecated.efficientformer.image_processing_efficientformer', 'models.deprecated.efficientformer.modeling_efficientformer', 'models.deprecated.efficientformer.modeling_tf_efficientformer', 'models.deprecated.ernie_m', 'models.deprecated.ernie_m.configuration_ernie_m', 'models.deprecated.ernie_m.modeling_ernie_m', 'models.deprecated.ernie_m.tokenization_ernie_m', 'models.deprecated.gptsan_japanese', 'models.deprecated.gptsan_japanese.configuration_gptsan_japanese', 'models.deprecated.gptsan_japanese.modeling_gptsan_japanese', 'models.deprecated.gptsan_japanese.tokenization_gptsan_japanese', 'models.deprecated.graphormer', 'models.deprecated.graphormer.configuration_graphormer', 'models.deprecated.graphormer.modeling_graphormer', 'models.deprecated.jukebox', 'models.deprecated.jukebox.configuration_jukebox', 'models.deprecated.jukebox.modeling_jukebox', 'models.deprecated.jukebox.tokenization_jukebox', 'models.deprecated.mctct', 'models.deprecated.mctct.configuration_mctct', 'models.deprecated.mctct.feature_extraction_mctct', 'models.deprecated.mctct.modeling_mctct', 'models.deprecated.mctct.processing_mctct', 'models.deprecated.mega', 'models.deprecated.mega.configuration_mega', 'models.deprecated.mega.modeling_mega', 'models.deprecated.mmbt', 'models.deprecated.mmbt.configuration_mmbt', 'models.deprecated.mmbt.modeling_mmbt', 'models.deprecated.nat', 'models.deprecated.nat.configuration_nat', 'models.deprecated.nat.modeling_nat', 'models.deprecated.nezha', 'models.deprecated.nezha.configuration_nezha', 'models.deprecated.nezha.modeling_nezha', 'models.deprecated.open_llama', 'models.deprecated.open_llama.configuration_open_llama', 'models.deprecated.open_llama.modeling_open_llama', 'models.deprecated.qdqbert', 'models.deprecated.qdqbert.configuration_qdqbert', 'models.deprecated.qdqbert.modeling_qdqbert', 'models.deprecated.realm', 'models.deprecated.realm.configuration_realm', 'models.deprecated.realm.modeling_realm', 'models.deprecated.realm.retrieval_realm', 'models.deprecated.realm.tokenization_realm', 'models.deprecated.realm.tokenization_realm_fast', 'models.deprecated.retribert', 'models.deprecated.retribert.configuration_retribert', 'models.deprecated.retribert.modeling_retribert', 'models.deprecated.retribert.tokenization_retribert', 'models.deprecated.retribert.tokenization_retribert_fast', 'models.deprecated.speech_to_text_2', 'models.deprecated.speech_to_text_2.configuration_speech_to_text_2', 'models.deprecated.speech_to_text_2.modeling_speech_to_text_2', 'models.deprecated.speech_to_text_2.processing_speech_to_text_2', 'models.deprecated.speech_to_text_2.tokenization_speech_to_text_2', 'models.deprecated.tapex', 'models.deprecated.tapex.tokenization_tapex', 'models.deprecated.trajectory_transformer', 'models.deprecated.trajectory_transformer.configuration_trajectory_transformer', 'models.deprecated.trajectory_transformer.modeling_trajectory_transformer', 'models.deprecated.transfo_xl', 'models.deprecated.transfo_xl.configuration_transfo_xl', 'models.deprecated.transfo_xl.modeling_tf_transfo_xl', 'models.deprecated.transfo_xl.modeling_transfo_xl', 'models.deprecated.transfo_xl.tokenization_transfo_xl', 'models.deprecated.tvlt', 'models.deprecated.tvlt.configuration_tvlt', 'models.deprecated.tvlt.feature_extraction_tvlt', 'models.deprecated.tvlt.image_processing_tvlt', 'models.deprecated.tvlt.modeling_tvlt', 'models.deprecated.tvlt.processing_tvlt', 'models.deprecated.van', 'models.deprecated.van.configuration_van', 'models.deprecated.van.modeling_van', 'models.deprecated.vit_hybrid', 'models.deprecated.vit_hybrid.configuration_vit_hybrid', 'models.deprecated.vit_hybrid.image_processing_vit_hybrid', 'models.deprecated.vit_hybrid.modeling_vit_hybrid', 'models.deprecated.xlm_prophetnet', 'models.deprecated.xlm_prophetnet.configuration_xlm_prophetnet', 'models.deprecated.xlm_prophetnet.modeling_xlm_prophetnet', 'models.deprecated.xlm_prophetnet.tokenization_xlm_prophetnet', 'models.depth_anything', 'models.depth_anything.configuration_depth_anything', 'models.depth_anything.modeling_depth_anything', 'models.depth_pro', 'models.depth_pro.configuration_depth_pro', 'models.depth_pro.image_processing_depth_pro', 'models.depth_pro.image_processing_depth_pro_fast', 'models.depth_pro.modeling_depth_pro', 'models.detr', 'models.detr.configuration_detr', 'models.detr.feature_extraction_detr', 'models.detr.image_processing_detr', 'models.detr.image_processing_detr_fast', 'models.detr.modeling_detr', 'models.dia', 'models.dia.configuration_dia', 'models.dia.feature_extraction_dia', 'models.dia.modeling_dia', 'models.dia.processing_dia', 'models.dia.tokenization_dia', 'models.diffllama', 'models.diffllama.configuration_diffllama', 'models.diffllama.modeling_diffllama', 'models.dinat', 'models.dinat.configuration_dinat', 'models.dinat.modeling_dinat', 'models.dinov2', 'models.dinov2.configuration_dinov2', 'models.dinov2.modeling_dinov2', 'models.dinov2.modeling_flax_dinov2', 'models.dinov2_with_registers', 'models.dinov2_with_registers.configuration_dinov2_with_registers', 'models.dinov2_with_registers.modeling_dinov2_with_registers', 'models.distilbert', 'models.distilbert.configuration_distilbert', 'models.distilbert.modeling_distilbert', 'models.distilbert.modeling_flax_distilbert', 'models.distilbert.modeling_tf_distilbert', 'models.distilbert.tokenization_distilbert', 'models.distilbert.tokenization_distilbert_fast', 'models.doge', 'models.doge.configuration_doge', 'models.doge.modeling_doge', 'models.donut', 'models.donut.configuration_donut_swin', 'models.donut.feature_extraction_donut', 'models.donut.image_processing_donut', 'models.donut.image_processing_donut_fast', 'models.donut.modeling_donut_swin', 'models.donut.processing_donut', 'models.dots1', 'models.dots1.configuration_dots1', 'models.dots1.modeling_dots1', 'models.dpr', 'models.dpr.configuration_dpr', 'models.dpr.modeling_dpr', 'models.dpr.modeling_tf_dpr', 'models.dpr.tokenization_dpr', 'models.dpr.tokenization_dpr_fast', 'models.dpt', 'models.dpt.configuration_dpt', 'models.dpt.feature_extraction_dpt', 'models.dpt.image_processing_dpt', 'models.dpt.image_processing_dpt_fast', 'models.dpt.modeling_dpt', 'models.efficientloftr', 'models.efficientloftr.configuration_efficientloftr', 'models.efficientloftr.image_processing_efficientloftr', 'models.efficientloftr.modeling_efficientloftr', 'models.efficientnet', 'models.efficientnet.configuration_efficientnet', 'models.efficientnet.image_processing_efficientnet', 'models.efficientnet.image_processing_efficientnet_fast', 'models.efficientnet.modeling_efficientnet', 'models.electra', 'models.electra.configuration_electra', 'models.electra.modeling_electra', 'models.electra.modeling_flax_electra', 'models.electra.modeling_tf_electra', 'models.electra.tokenization_electra', 'models.electra.tokenization_electra_fast', 'models.emu3', 'models.emu3.configuration_emu3', 'models.emu3.image_processing_emu3', 'models.emu3.modeling_emu3', 'models.emu3.processing_emu3', 'models.encodec', 'models.encodec.configuration_encodec', 'models.encodec.feature_extraction_encodec', 'models.encodec.modeling_encodec', 'models.encoder_decoder', 'models.encoder_decoder.configuration_encoder_decoder', 'models.encoder_decoder.modeling_encoder_decoder', 'models.encoder_decoder.modeling_flax_encoder_decoder', 'models.encoder_decoder.modeling_tf_encoder_decoder', 'models.eomt', 'models.eomt.configuration_eomt', 'models.eomt.image_processing_eomt', 'models.eomt.image_processing_eomt_fast', 'models.eomt.modeling_eomt', 'models.ernie', 'models.ernie.configuration_ernie', 'models.ernie.modeling_ernie', 'models.ernie4_5', 'models.ernie4_5.configuration_ernie4_5', 'models.ernie4_5.modeling_ernie4_5', 'models.ernie4_5_moe', 'models.ernie4_5_moe.configuration_ernie4_5_moe', 'models.ernie4_5_moe.modeling_ernie4_5_moe', 'models.esm', 'models.esm.configuration_esm', 'models.esm.modeling_esm', 'models.esm.modeling_esmfold', 'models.esm.modeling_tf_esm', 'models.esm.tokenization_esm', 'models.evolla', 'models.evolla.configuration_evolla', 'models.evolla.modeling_evolla', 'models.evolla.processing_evolla', 'models.exaone4', 'models.exaone4.configuration_exaone4', 'models.exaone4.modeling_exaone4', 'models.falcon', 'models.falcon.configuration_falcon', 'models.falcon.modeling_falcon', 'models.falcon_h1', 'models.falcon_h1.configuration_falcon_h1', 'models.falcon_h1.modeling_falcon_h1', 'models.falcon_mamba', 'models.falcon_mamba.configuration_falcon_mamba', 'models.falcon_mamba.modeling_falcon_mamba', 'models.fastspeech2_conformer', 'models.fastspeech2_conformer.configuration_fastspeech2_conformer', 'models.fastspeech2_conformer.modeling_fastspeech2_conformer', 'models.fastspeech2_conformer.tokenization_fastspeech2_conformer', 'models.flaubert', 'models.flaubert.configuration_flaubert', 'models.flaubert.modeling_flaubert', 'models.flaubert.modeling_tf_flaubert', 'models.flaubert.tokenization_flaubert', 'models.flava', 'models.flava.configuration_flava', 'models.flava.feature_extraction_flava', 'models.flava.image_processing_flava', 'models.flava.image_processing_flava_fast', 'models.flava.modeling_flava', 'models.flava.processing_flava', 'models.fnet', 'models.fnet.configuration_fnet', 'models.fnet.modeling_fnet', 'models.fnet.tokenization_fnet', 'models.fnet.tokenization_fnet_fast', 'models.focalnet', 'models.focalnet.configuration_focalnet', 'models.focalnet.modeling_focalnet', 'models.fsmt', 'models.fsmt.configuration_fsmt', 'models.fsmt.modeling_fsmt', 'models.fsmt.tokenization_fsmt', 'models.funnel', 'models.funnel.configuration_funnel', 'models.funnel.modeling_funnel', 'models.funnel.modeling_tf_funnel', 'models.funnel.tokenization_funnel', 'models.funnel.tokenization_funnel_fast', 'models.fuyu', 'models.fuyu.configuration_fuyu', 'models.fuyu.image_processing_fuyu', 'models.fuyu.modeling_fuyu', 'models.fuyu.processing_fuyu', 'models.gemma', 'models.gemma.configuration_gemma', 'models.gemma.modeling_flax_gemma', 'models.gemma.modeling_gemma', 'models.gemma.tokenization_gemma', 'models.gemma.tokenization_gemma_fast', 'models.gemma2', 'models.gemma2.configuration_gemma2', 'models.gemma2.modeling_gemma2', 'models.gemma3', 'models.gemma3.configuration_gemma3', 'models.gemma3.image_processing_gemma3', 'models.gemma3.image_processing_gemma3_fast', 'models.gemma3.modeling_gemma3', 'models.gemma3.processing_gemma3', 'models.gemma3n', 'models.gemma3n.configuration_gemma3n', 'models.gemma3n.feature_extraction_gemma3n', 'models.gemma3n.modeling_gemma3n', 'models.gemma3n.processing_gemma3n', 'models.git', 'models.git.configuration_git', 'models.git.modeling_git', 'models.git.processing_git', 'models.glm', 'models.glm.configuration_glm', 'models.glm.modeling_glm', 'models.glm4', 'models.glm4.configuration_glm4', 'models.glm4.modeling_glm4', 'models.glm4_moe', 'models.glm4_moe.configuration_glm4_moe', 'models.glm4_moe.modeling_glm4_moe', 'models.glm4v', 'models.glm4v.configuration_glm4v', 'models.glm4v.image_processing_glm4v', 'models.glm4v.image_processing_glm4v_fast', 'models.glm4v.modeling_glm4v', 'models.glm4v.processing_glm4v', 'models.glm4v.video_processing_glm4v', 'models.glpn', 'models.glpn.configuration_glpn', 'models.glpn.feature_extraction_glpn', 'models.glpn.image_processing_glpn', 'models.glpn.modeling_glpn', 'models.got_ocr2', 'models.got_ocr2.configuration_got_ocr2', 'models.got_ocr2.image_processing_got_ocr2', 'models.got_ocr2.image_processing_got_ocr2_fast', 'models.got_ocr2.modeling_got_ocr2', 'models.got_ocr2.processing_got_ocr2', 'models.gpt2', 'models.gpt2.configuration_gpt2', 'models.gpt2.modeling_flax_gpt2', 'models.gpt2.modeling_gpt2', 'models.gpt2.modeling_tf_gpt2', 'models.gpt2.tokenization_gpt2', 'models.gpt2.tokenization_gpt2_fast', 'models.gpt2.tokenization_gpt2_tf', 'models.gpt_bigcode', 'models.gpt_bigcode.configuration_gpt_bigcode', 'models.gpt_bigcode.modeling_gpt_bigcode', 'models.gpt_neo', 'models.gpt_neo.configuration_gpt_neo', 'models.gpt_neo.modeling_flax_gpt_neo', 'models.gpt_neo.modeling_gpt_neo', 'models.gpt_neox', 'models.gpt_neox.configuration_gpt_neox', 'models.gpt_neox.modeling_gpt_neox', 'models.gpt_neox.tokenization_gpt_neox_fast', 'models.gpt_neox_japanese', 'models.gpt_neox_japanese.configuration_gpt_neox_japanese', 'models.gpt_neox_japanese.modeling_gpt_neox_japanese', 'models.gpt_neox_japanese.tokenization_gpt_neox_japanese', 'models.gpt_oss', 'models.gpt_oss.configuration_gpt_oss', 'models.gpt_oss.modeling_gpt_oss', 'models.gpt_sw3', 'models.gpt_sw3.tokenization_gpt_sw3', 'models.gptj', 'models.gptj.configuration_gptj', 'models.gptj.modeling_flax_gptj', 'models.gptj.modeling_gptj', 'models.gptj.modeling_tf_gptj', 'models.granite', 'models.granite.configuration_granite', 'models.granite.modeling_granite', 'models.granite_speech', 'models.granite_speech.configuration_granite_speech', 'models.granite_speech.feature_extraction_granite_speech', 'models.granite_speech.modeling_granite_speech', 'models.granite_speech.processing_granite_speech', 'models.granitemoe', 'models.granitemoe.configuration_granitemoe', 'models.granitemoe.modeling_granitemoe', 'models.granitemoehybrid', 'models.granitemoehybrid.configuration_granitemoehybrid', 'models.granitemoehybrid.modeling_granitemoehybrid', 'models.granitemoeshared', 'models.granitemoeshared.configuration_granitemoeshared', 'models.granitemoeshared.modeling_granitemoeshared', 'models.grounding_dino', 'models.grounding_dino.configuration_grounding_dino', 'models.grounding_dino.image_processing_grounding_dino', 'models.grounding_dino.image_processing_grounding_dino_fast', 'models.grounding_dino.modeling_grounding_dino', 'models.grounding_dino.processing_grounding_dino', 'models.groupvit', 'models.groupvit.configuration_groupvit', 'models.groupvit.modeling_groupvit', 'models.groupvit.modeling_tf_groupvit', 'models.helium', 'models.helium.configuration_helium', 'models.helium.modeling_helium', 'models.herbert', 'models.herbert.tokenization_herbert', 'models.herbert.tokenization_herbert_fast', 'models.hgnet_v2', 'models.hgnet_v2.configuration_hgnet_v2', 'models.hgnet_v2.modeling_hgnet_v2', 'models.hiera', 'models.hiera.configuration_hiera', 'models.hiera.modeling_hiera', 'models.hubert', 'models.hubert.configuration_hubert', 'models.hubert.modeling_hubert', 'models.hubert.modeling_tf_hubert', 'models.ibert', 'models.ibert.configuration_ibert', 'models.ibert.modeling_ibert', 'models.idefics', 'models.idefics.configuration_idefics', 'models.idefics.image_processing_idefics', 'models.idefics.modeling_idefics', 'models.idefics.modeling_tf_idefics', 'models.idefics.processing_idefics', 'models.idefics2', 'models.idefics2.configuration_idefics2', 'models.idefics2.image_processing_idefics2', 'models.idefics2.image_processing_idefics2_fast', 'models.idefics2.modeling_idefics2', 'models.idefics2.processing_idefics2', 'models.idefics3', 'models.idefics3.configuration_idefics3', 'models.idefics3.image_processing_idefics3', 'models.idefics3.image_processing_idefics3_fast', 'models.idefics3.modeling_idefics3', 'models.idefics3.processing_idefics3', 'models.ijepa', 'models.ijepa.configuration_ijepa', 'models.ijepa.modeling_ijepa', 'models.imagegpt', 'models.imagegpt.configuration_imagegpt', 'models.imagegpt.feature_extraction_imagegpt', 'models.imagegpt.image_processing_imagegpt', 'models.imagegpt.modeling_imagegpt', 'models.informer', 'models.informer.configuration_informer', 'models.informer.modeling_informer', 'models.instructblip', 'models.instructblip.configuration_instructblip', 'models.instructblip.modeling_instructblip', 'models.instructblip.processing_instructblip', 'models.instructblipvideo', 'models.instructblipvideo.configuration_instructblipvideo', 'models.instructblipvideo.image_processing_instructblipvideo', 'models.instructblipvideo.modeling_instructblipvideo', 'models.instructblipvideo.processing_instructblipvideo', 'models.instructblipvideo.video_processing_instructblipvideo', 'models.internvl', 'models.internvl.configuration_internvl', 'models.internvl.modeling_internvl', 'models.internvl.processing_internvl', 'models.internvl.video_processing_internvl', 'models.jamba', 'models.jamba.configuration_jamba', 'models.jamba.modeling_jamba', 'models.janus', 'models.janus.configuration_janus', 'models.janus.image_processing_janus', 'models.janus.image_processing_janus_fast', 'models.janus.modeling_janus', 'models.janus.processing_janus', 'models.jetmoe', 'models.jetmoe.configuration_jetmoe', 'models.jetmoe.modeling_jetmoe', 'models.kosmos2', 'models.kosmos2.configuration_kosmos2', 'models.kosmos2.modeling_kosmos2', 'models.kosmos2.processing_kosmos2', 'models.kyutai_speech_to_text', 'models.kyutai_speech_to_text.configuration_kyutai_speech_to_text', 'models.kyutai_speech_to_text.feature_extraction_kyutai_speech_to_text', 'models.kyutai_speech_to_text.modeling_kyutai_speech_to_text', 'models.kyutai_speech_to_text.processing_kyutai_speech_to_text', 'models.layoutlm', 'models.layoutlm.configuration_layoutlm', 'models.layoutlm.modeling_layoutlm', 'models.layoutlm.modeling_tf_layoutlm', 'models.layoutlm.tokenization_layoutlm', 'models.layoutlm.tokenization_layoutlm_fast', 'models.layoutlmv2', 'models.layoutlmv2.configuration_layoutlmv2', 'models.layoutlmv2.feature_extraction_layoutlmv2', 'models.layoutlmv2.image_processing_layoutlmv2', 'models.layoutlmv2.image_processing_layoutlmv2_fast', 'models.layoutlmv2.modeling_layoutlmv2', 'models.layoutlmv2.processing_layoutlmv2', 'models.layoutlmv2.tokenization_layoutlmv2', 'models.layoutlmv2.tokenization_layoutlmv2_fast', 'models.layoutlmv3', 'models.layoutlmv3.configuration_layoutlmv3', 'models.layoutlmv3.feature_extraction_layoutlmv3', 'models.layoutlmv3.image_processing_layoutlmv3', 'models.layoutlmv3.image_processing_layoutlmv3_fast', 'models.layoutlmv3.modeling_layoutlmv3', 'models.layoutlmv3.modeling_tf_layoutlmv3', 'models.layoutlmv3.processing_layoutlmv3', 'models.layoutlmv3.tokenization_layoutlmv3', 'models.layoutlmv3.tokenization_layoutlmv3_fast', 'models.layoutxlm', 'models.layoutxlm.processing_layoutxlm', 'models.layoutxlm.tokenization_layoutxlm', 'models.layoutxlm.tokenization_layoutxlm_fast', 'models.led', 'models.led.configuration_led', 'models.led.modeling_led', 'models.led.modeling_tf_led', 'models.led.tokenization_led', 'models.led.tokenization_led_fast', 'models.levit', 'models.levit.configuration_levit', 'models.levit.feature_extraction_levit', 'models.levit.image_processing_levit', 'models.levit.image_processing_levit_fast', 'models.levit.modeling_levit', 'models.lfm2', 'models.lfm2.configuration_lfm2', 'models.lfm2.modeling_lfm2', 'models.lightglue', 'models.lightglue.configuration_lightglue', 'models.lightglue.image_processing_lightglue', 'models.lightglue.modeling_lightglue', 'models.lilt', 'models.lilt.configuration_lilt', 'models.lilt.modeling_lilt', 'models.llama', 'models.llama.configuration_llama', 'models.llama.modeling_flax_llama', 'models.llama.modeling_llama', 'models.llama.tokenization_llama', 'models.llama.tokenization_llama_fast', 'models.llama4', 'models.llama4.configuration_llama4', 'models.llama4.image_processing_llama4_fast', 'models.llama4.modeling_llama4', 'models.llama4.processing_llama4', 'models.llava', 'models.llava.configuration_llava', 'models.llava.image_processing_llava', 'models.llava.image_processing_llava_fast', 'models.llava.modeling_llava', 'models.llava.processing_llava', 'models.llava_next', 'models.llava_next.configuration_llava_next', 'models.llava_next.image_processing_llava_next', 'models.llava_next.image_processing_llava_next_fast', 'models.llava_next.modeling_llava_next', 'models.llava_next.processing_llava_next', 'models.llava_next_video', 'models.llava_next_video.configuration_llava_next_video', 'models.llava_next_video.image_processing_llava_next_video', 'models.llava_next_video.modeling_llava_next_video', 'models.llava_next_video.processing_llava_next_video', 'models.llava_next_video.video_processing_llava_next_video', 'models.llava_onevision', 'models.llava_onevision.configuration_llava_onevision', 'models.llava_onevision.image_processing_llava_onevision', 'models.llava_onevision.image_processing_llava_onevision_fast', 'models.llava_onevision.modeling_llava_onevision', 'models.llava_onevision.processing_llava_onevision', 'models.llava_onevision.video_processing_llava_onevision', 'models.longformer', 'models.longformer.configuration_longformer', 'models.longformer.modeling_longformer', 'models.longformer.modeling_tf_longformer', 'models.longformer.tokenization_longformer', 'models.longformer.tokenization_longformer_fast', 'models.longt5', 'models.longt5.configuration_longt5', 'models.longt5.modeling_flax_longt5', 'models.longt5.modeling_longt5', 'models.luke', 'models.luke.configuration_luke', 'models.luke.modeling_luke', 'models.luke.tokenization_luke', 'models.lxmert', 'models.lxmert.configuration_lxmert', 'models.lxmert.modeling_lxmert', 'models.lxmert.modeling_tf_lxmert', 'models.lxmert.tokenization_lxmert', 'models.lxmert.tokenization_lxmert_fast', 'models.m2m_100', 'models.m2m_100.configuration_m2m_100', 'models.m2m_100.modeling_m2m_100', 'models.m2m_100.tokenization_m2m_100', 'models.mamba', 'models.mamba.configuration_mamba', 'models.mamba.modeling_mamba', 'models.mamba2', 'models.mamba2.configuration_mamba2', 'models.mamba2.modeling_mamba2', 'models.marian', 'models.marian.configuration_marian', 'models.marian.modeling_flax_marian', 'models.marian.modeling_marian', 'models.marian.modeling_tf_marian', 'models.marian.tokenization_marian', 'models.markuplm', 'models.markuplm.configuration_markuplm', 'models.markuplm.feature_extraction_markuplm', 'models.markuplm.modeling_markuplm', 'models.markuplm.processing_markuplm', 'models.markuplm.tokenization_markuplm', 'models.markuplm.tokenization_markuplm_fast', 'models.mask2former', 'models.mask2former.configuration_mask2former', 'models.mask2former.image_processing_mask2former', 'models.mask2former.image_processing_mask2former_fast', 'models.mask2former.modeling_mask2former', 'models.maskformer', 'models.maskformer.configuration_maskformer', 'models.maskformer.configuration_maskformer_swin', 'models.maskformer.feature_extraction_maskformer', 'models.maskformer.image_processing_maskformer', 'models.maskformer.image_processing_maskformer_fast', 'models.maskformer.modeling_maskformer', 'models.maskformer.modeling_maskformer_swin', 'models.mbart', 'models.mbart.configuration_mbart', 'models.mbart.modeling_flax_mbart', 'models.mbart.modeling_mbart', 'models.mbart.modeling_tf_mbart', 'models.mbart.tokenization_mbart', 'models.mbart.tokenization_mbart_fast', 'models.mbart50', 'models.mbart50.tokenization_mbart50', 'models.mbart50.tokenization_mbart50_fast', 'models.megatron_bert', 'models.megatron_bert.configuration_megatron_bert', 'models.megatron_bert.modeling_megatron_bert', 'models.mgp_str', 'models.mgp_str.configuration_mgp_str', 'models.mgp_str.modeling_mgp_str', 'models.mgp_str.processing_mgp_str', 'models.mgp_str.tokenization_mgp_str', 'models.mimi', 'models.mimi.configuration_mimi', 'models.mimi.modeling_mimi', 'models.minimax', 'models.minimax.configuration_minimax', 'models.minimax.modeling_minimax', 'models.mistral', 'models.mistral.configuration_mistral', 'models.mistral.modeling_flax_mistral', 'models.mistral.modeling_mistral', 'models.mistral.modeling_tf_mistral', 'models.mistral3', 'models.mistral3.configuration_mistral3', 'models.mistral3.modeling_mistral3', 'models.mixtral', 'models.mixtral.configuration_mixtral', 'models.mixtral.modeling_mixtral', 'models.mlcd', 'models.mlcd.configuration_mlcd', 'models.mlcd.modeling_mlcd', 'models.mllama', 'models.mllama.configuration_mllama', 'models.mllama.image_processing_mllama', 'models.mllama.modeling_mllama', 'models.mllama.processing_mllama', 'models.mluke', 'models.mluke.tokenization_mluke', 'models.mm_grounding_dino', 'models.mm_grounding_dino.configuration_mm_grounding_dino', 'models.mm_grounding_dino.modeling_mm_grounding_dino', 'models.mobilebert', 'models.mobilebert.configuration_mobilebert', 'models.mobilebert.modeling_mobilebert', 'models.mobilebert.modeling_tf_mobilebert', 'models.mobilebert.tokenization_mobilebert', 'models.mobilebert.tokenization_mobilebert_fast', 'models.mobilenet_v1', 'models.mobilenet_v1.configuration_mobilenet_v1', 'models.mobilenet_v1.feature_extraction_mobilenet_v1', 'models.mobilenet_v1.image_processing_mobilenet_v1', 'models.mobilenet_v1.image_processing_mobilenet_v1_fast', 'models.mobilenet_v1.modeling_mobilenet_v1', 'models.mobilenet_v2', 'models.mobilenet_v2.configuration_mobilenet_v2', 'models.mobilenet_v2.feature_extraction_mobilenet_v2', 'models.mobilenet_v2.image_processing_mobilenet_v2', 'models.mobilenet_v2.image_processing_mobilenet_v2_fast', 'models.mobilenet_v2.modeling_mobilenet_v2', 'models.mobilevit', 'models.mobilevit.configuration_mobilevit', 'models.mobilevit.feature_extraction_mobilevit', 'models.mobilevit.image_processing_mobilevit', 'models.mobilevit.image_processing_mobilevit_fast', 'models.mobilevit.modeling_mobilevit', 'models.mobilevit.modeling_tf_mobilevit', 'models.mobilevitv2', 'models.mobilevitv2.configuration_mobilevitv2', 'models.mobilevitv2.modeling_mobilevitv2', 'models.modernbert', 'models.modernbert.configuration_modernbert', 'models.modernbert.modeling_modernbert', 'models.modernbert_decoder', 'models.modernbert_decoder.configuration_modernbert_decoder', 'models.modernbert_decoder.modeling_modernbert_decoder', 'models.moonshine', 'models.moonshine.configuration_moonshine', 'models.moonshine.modeling_moonshine', 'models.moshi', 'models.moshi.configuration_moshi', 'models.moshi.modeling_moshi', 'models.mpnet', 'models.mpnet.configuration_mpnet', 'models.mpnet.modeling_mpnet', 'models.mpnet.modeling_tf_mpnet', 'models.mpnet.tokenization_mpnet', 'models.mpnet.tokenization_mpnet_fast', 'models.mpt', 'models.mpt.configuration_mpt', 'models.mpt.modeling_mpt', 'models.mra', 'models.mra.configuration_mra', 'models.mra.modeling_mra', 'models.mt5', 'models.mt5.configuration_mt5', 'models.mt5.modeling_flax_mt5', 'models.mt5.modeling_mt5', 'models.mt5.modeling_tf_mt5', 'models.mt5.tokenization_mt5', 'models.mt5.tokenization_mt5_fast', 'models.musicgen', 'models.musicgen.configuration_musicgen', 'models.musicgen.modeling_musicgen', 'models.musicgen.processing_musicgen', 'models.musicgen_melody', 'models.musicgen_melody.configuration_musicgen_melody', 'models.musicgen_melody.feature_extraction_musicgen_melody', 'models.musicgen_melody.modeling_musicgen_melody', 'models.musicgen_melody.processing_musicgen_melody', 'models.mvp', 'models.mvp.configuration_mvp', 'models.mvp.modeling_mvp', 'models.mvp.tokenization_mvp', 'models.mvp.tokenization_mvp_fast', 'models.myt5', 'models.myt5.tokenization_myt5', 'models.nemotron', 'models.nemotron.configuration_nemotron', 'models.nemotron.modeling_nemotron', 'models.nllb', 'models.nllb.tokenization_nllb', 'models.nllb.tokenization_nllb_fast', 'models.nllb_moe', 'models.nllb_moe.configuration_nllb_moe', 'models.nllb_moe.modeling_nllb_moe', 'models.nougat', 'models.nougat.image_processing_nougat', 'models.nougat.image_processing_nougat_fast', 'models.nougat.processing_nougat', 'models.nougat.tokenization_nougat_fast', 'models.nystromformer', 'models.nystromformer.configuration_nystromformer', 'models.nystromformer.modeling_nystromformer', 'models.olmo', 'models.olmo.configuration_olmo', 'models.olmo.modeling_olmo', 'models.olmo2', 'models.olmo2.configuration_olmo2', 'models.olmo2.modeling_olmo2', 'models.olmoe', 'models.olmoe.configuration_olmoe', 'models.olmoe.modeling_olmoe', 'models.omdet_turbo', 'models.omdet_turbo.configuration_omdet_turbo', 'models.omdet_turbo.modeling_omdet_turbo', 'models.omdet_turbo.processing_omdet_turbo', 'models.oneformer', 'models.oneformer.configuration_oneformer', 'models.oneformer.image_processing_oneformer', 'models.oneformer.image_processing_oneformer_fast', 'models.oneformer.modeling_oneformer', 'models.oneformer.processing_oneformer', 'models.openai', 'models.openai.configuration_openai', 'models.openai.modeling_openai', 'models.openai.modeling_tf_openai', 'models.openai.tokenization_openai', 'models.openai.tokenization_openai_fast', 'models.opt', 'models.opt.configuration_opt', 'models.opt.modeling_flax_opt', 'models.opt.modeling_opt', 'models.opt.modeling_tf_opt', 'models.owlv2', 'models.owlv2.configuration_owlv2', 'models.owlv2.image_processing_owlv2', 'models.owlv2.image_processing_owlv2_fast', 'models.owlv2.modeling_owlv2', 'models.owlv2.processing_owlv2', 'models.owlvit', 'models.owlvit.configuration_owlvit', 'models.owlvit.feature_extraction_owlvit', 'models.owlvit.image_processing_owlvit', 'models.owlvit.image_processing_owlvit_fast', 'models.owlvit.modeling_owlvit', 'models.owlvit.processing_owlvit', 'models.paligemma', 'models.paligemma.configuration_paligemma', 'models.paligemma.modeling_paligemma', 'models.paligemma.processing_paligemma', 'models.patchtsmixer', 'models.patchtsmixer.configuration_patchtsmixer', 'models.patchtsmixer.modeling_patchtsmixer', 'models.patchtst', 'models.patchtst.configuration_patchtst', 'models.patchtst.modeling_patchtst', 'models.pegasus', 'models.pegasus.configuration_pegasus', 'models.pegasus.modeling_flax_pegasus', 'models.pegasus.modeling_pegasus', 'models.pegasus.modeling_tf_pegasus', 'models.pegasus.tokenization_pegasus', 'models.pegasus.tokenization_pegasus_fast', 'models.pegasus_x', 'models.pegasus_x.configuration_pegasus_x', 'models.pegasus_x.modeling_pegasus_x', 'models.perceiver', 'models.perceiver.configuration_perceiver', 'models.perceiver.feature_extraction_perceiver', 'models.perceiver.image_processing_perceiver', 'models.perceiver.image_processing_perceiver_fast', 'models.perceiver.modeling_perceiver', 'models.perceiver.tokenization_perceiver', 'models.perception_lm', 'models.perception_lm.configuration_perception_lm', 'models.perception_lm.image_processing_perception_lm_fast', 'models.perception_lm.modeling_perception_lm', 'models.perception_lm.processing_perception_lm', 'models.perception_lm.video_processing_perception_lm', 'models.persimmon', 'models.persimmon.configuration_persimmon', 'models.persimmon.modeling_persimmon', 'models.phi', 'models.phi.configuration_phi', 'models.phi.modeling_phi', 'models.phi3', 'models.phi3.configuration_phi3', 'models.phi3.modeling_phi3', 'models.phi4_multimodal', 'models.phi4_multimodal.configuration_phi4_multimodal', 'models.phi4_multimodal.feature_extraction_phi4_multimodal', 'models.phi4_multimodal.image_processing_phi4_multimodal_fast', 'models.phi4_multimodal.modeling_phi4_multimodal', 'models.phi4_multimodal.processing_phi4_multimodal', 'models.phimoe', 'models.phimoe.configuration_phimoe', 'models.phimoe.modeling_phimoe', 'models.phobert', 'models.phobert.tokenization_phobert', 'models.pix2struct', 'models.pix2struct.configuration_pix2struct', 'models.pix2struct.image_processing_pix2struct', 'models.pix2struct.modeling_pix2struct', 'models.pix2struct.processing_pix2struct', 'models.pixtral', 'models.pixtral.configuration_pixtral', 'models.pixtral.image_processing_pixtral', 'models.pixtral.image_processing_pixtral_fast', 'models.pixtral.modeling_pixtral', 'models.pixtral.processing_pixtral', 'models.plbart', 'models.plbart.configuration_plbart', 'models.plbart.modeling_plbart', 'models.plbart.tokenization_plbart', 'models.poolformer', 'models.poolformer.configuration_poolformer', 'models.poolformer.feature_extraction_poolformer', 'models.poolformer.image_processing_poolformer', 'models.poolformer.image_processing_poolformer_fast', 'models.poolformer.modeling_poolformer', 'models.pop2piano', 'models.pop2piano.configuration_pop2piano', 'models.pop2piano.feature_extraction_pop2piano', 'models.pop2piano.modeling_pop2piano', 'models.pop2piano.processing_pop2piano', 'models.pop2piano.tokenization_pop2piano', 'models.prompt_depth_anything', 'models.prompt_depth_anything.configuration_prompt_depth_anything', 'models.prompt_depth_anything.image_processing_prompt_depth_anything', 'models.prompt_depth_anything.modeling_prompt_depth_anything', 'models.prophetnet', 'models.prophetnet.configuration_prophetnet', 'models.prophetnet.modeling_prophetnet', 'models.prophetnet.tokenization_prophetnet', 'models.pvt', 'models.pvt.configuration_pvt', 'models.pvt.image_processing_pvt', 'models.pvt.image_processing_pvt_fast', 'models.pvt.modeling_pvt', 'models.pvt_v2', 'models.pvt_v2.configuration_pvt_v2', 'models.pvt_v2.modeling_pvt_v2', 'models.qwen2', 'models.qwen2.configuration_qwen2', 'models.qwen2.modeling_qwen2', 'models.qwen2.tokenization_qwen2', 'models.qwen2.tokenization_qwen2_fast', 'models.qwen2_5_omni', 'models.qwen2_5_omni.configuration_qwen2_5_omni', 'models.qwen2_5_omni.modeling_qwen2_5_omni', 'models.qwen2_5_omni.processing_qwen2_5_omni', 'models.qwen2_5_vl', 'models.qwen2_5_vl.configuration_qwen2_5_vl', 'models.qwen2_5_vl.modeling_qwen2_5_vl', 'models.qwen2_5_vl.processing_qwen2_5_vl', 'models.qwen2_audio', 'models.qwen2_audio.configuration_qwen2_audio', 'models.qwen2_audio.modeling_qwen2_audio', 'models.qwen2_audio.processing_qwen2_audio', 'models.qwen2_moe', 'models.qwen2_moe.configuration_qwen2_moe', 'models.qwen2_moe.modeling_qwen2_moe', 'models.qwen2_vl', 'models.qwen2_vl.configuration_qwen2_vl', 'models.qwen2_vl.image_processing_qwen2_vl', 'models.qwen2_vl.image_processing_qwen2_vl_fast', 'models.qwen2_vl.modeling_qwen2_vl', 'models.qwen2_vl.processing_qwen2_vl', 'models.qwen2_vl.video_processing_qwen2_vl', 'models.qwen3', 'models.qwen3.configuration_qwen3', 'models.qwen3.modeling_qwen3', 'models.qwen3_moe', 'models.qwen3_moe.configuration_qwen3_moe', 'models.qwen3_moe.modeling_qwen3_moe', 'models.rag', 'models.rag.configuration_rag', 'models.rag.modeling_rag', 'models.rag.modeling_tf_rag', 'models.rag.retrieval_rag', 'models.rag.tokenization_rag', 'models.recurrent_gemma', 'models.recurrent_gemma.configuration_recurrent_gemma', 'models.recurrent_gemma.modeling_recurrent_gemma', 'models.reformer', 'models.reformer.configuration_reformer', 'models.reformer.modeling_reformer', 'models.reformer.tokenization_reformer', 'models.reformer.tokenization_reformer_fast', 'models.regnet', 'models.regnet.configuration_regnet', 'models.regnet.modeling_flax_regnet', 'models.regnet.modeling_regnet', 'models.regnet.modeling_tf_regnet', 'models.rembert', 'models.rembert.configuration_rembert', 'models.rembert.modeling_rembert', 'models.rembert.modeling_tf_rembert', 'models.rembert.tokenization_rembert', 'models.rembert.tokenization_rembert_fast', 'models.resnet', 'models.resnet.configuration_resnet', 'models.resnet.modeling_flax_resnet', 'models.resnet.modeling_resnet', 'models.resnet.modeling_tf_resnet', 'models.roberta', 'models.roberta.configuration_roberta', 'models.roberta.modeling_flax_roberta', 'models.roberta.modeling_roberta', 'models.roberta.modeling_tf_roberta', 'models.roberta.tokenization_roberta', 'models.roberta.tokenization_roberta_fast', 'models.roberta_prelayernorm', 'models.roberta_prelayernorm.configuration_roberta_prelayernorm', 'models.roberta_prelayernorm.modeling_flax_roberta_prelayernorm', 'models.roberta_prelayernorm.modeling_roberta_prelayernorm', 'models.roberta_prelayernorm.modeling_tf_roberta_prelayernorm', 'models.roc_bert', 'models.roc_bert.configuration_roc_bert', 'models.roc_bert.modeling_roc_bert', 'models.roc_bert.tokenization_roc_bert', 'models.roformer', 'models.roformer.configuration_roformer', 'models.roformer.modeling_flax_roformer', 'models.roformer.modeling_roformer', 'models.roformer.modeling_tf_roformer', 'models.roformer.tokenization_roformer', 'models.roformer.tokenization_roformer_fast', 'models.rt_detr', 'models.rt_detr.configuration_rt_detr', 'models.rt_detr.configuration_rt_detr_resnet', 'models.rt_detr.image_processing_rt_detr', 'models.rt_detr.image_processing_rt_detr_fast', 'models.rt_detr.modeling_rt_detr', 'models.rt_detr.modeling_rt_detr_resnet', 'models.rt_detr_v2', 'models.rt_detr_v2.configuration_rt_detr_v2', 'models.rt_detr_v2.modeling_rt_detr_v2', 'models.rwkv', 'models.rwkv.configuration_rwkv', 'models.rwkv.modeling_rwkv', 'models.sam', 'models.sam.configuration_sam', 'models.sam.image_processing_sam', 'models.sam.image_processing_sam_fast', 'models.sam.modeling_sam', 'models.sam.modeling_tf_sam', 'models.sam.processing_sam', 'models.sam_hq', 'models.sam_hq.configuration_sam_hq', 'models.sam_hq.modeling_sam_hq', 'models.sam_hq.processing_samhq', 'models.seamless_m4t', 'models.seamless_m4t.configuration_seamless_m4t', 'models.seamless_m4t.feature_extraction_seamless_m4t', 'models.seamless_m4t.modeling_seamless_m4t', 'models.seamless_m4t.processing_seamless_m4t', 'models.seamless_m4t.tokenization_seamless_m4t', 'models.seamless_m4t.tokenization_seamless_m4t_fast', 'models.seamless_m4t_v2', 'models.seamless_m4t_v2.configuration_seamless_m4t_v2', 'models.seamless_m4t_v2.modeling_seamless_m4t_v2', 'models.segformer', 'models.segformer.configuration_segformer', 'models.segformer.feature_extraction_segformer', 'models.segformer.image_processing_segformer', 'models.segformer.image_processing_segformer_fast', 'models.segformer.modeling_segformer', 'models.segformer.modeling_tf_segformer', 'models.seggpt', 'models.seggpt.configuration_seggpt', 'models.seggpt.image_processing_seggpt', 'models.seggpt.modeling_seggpt', 'models.sew', 'models.sew.configuration_sew', 'models.sew.modeling_sew', 'models.sew_d', 'models.sew_d.configuration_sew_d', 'models.sew_d.modeling_sew_d', 'models.shieldgemma2', 'models.shieldgemma2.configuration_shieldgemma2', 'models.shieldgemma2.modeling_shieldgemma2', 'models.shieldgemma2.processing_shieldgemma2', 'models.siglip', 'models.siglip.configuration_siglip', 'models.siglip.image_processing_siglip', 'models.siglip.image_processing_siglip_fast', 'models.siglip.modeling_siglip', 'models.siglip.processing_siglip', 'models.siglip.tokenization_siglip', 'models.siglip2', 'models.siglip2.configuration_siglip2', 'models.siglip2.image_processing_siglip2', 'models.siglip2.image_processing_siglip2_fast', 'models.siglip2.modeling_siglip2', 'models.siglip2.processing_siglip2', 'models.smollm3', 'models.smollm3.configuration_smollm3', 'models.smollm3.modeling_smollm3', 'models.smolvlm', 'models.smolvlm.configuration_smolvlm', 'models.smolvlm.image_processing_smolvlm', 'models.smolvlm.image_processing_smolvlm_fast', 'models.smolvlm.modeling_smolvlm', 'models.smolvlm.processing_smolvlm', 'models.smolvlm.video_processing_smolvlm', 'models.speech_encoder_decoder', 'models.speech_encoder_decoder.configuration_speech_encoder_decoder', 'models.speech_encoder_decoder.modeling_flax_speech_encoder_decoder', 'models.speech_encoder_decoder.modeling_speech_encoder_decoder', 'models.speech_to_text', 'models.speech_to_text.configuration_speech_to_text', 'models.speech_to_text.feature_extraction_speech_to_text', 'models.speech_to_text.modeling_speech_to_text', 'models.speech_to_text.modeling_tf_speech_to_text', 'models.speech_to_text.processing_speech_to_text', 'models.speech_to_text.tokenization_speech_to_text', 'models.speecht5', 'models.speecht5.configuration_speecht5', 'models.speecht5.feature_extraction_speecht5', 'models.speecht5.modeling_speecht5', 'models.speecht5.processing_speecht5', 'models.speecht5.tokenization_speecht5', 'models.splinter', 'models.splinter.configuration_splinter', 'models.splinter.modeling_splinter', 'models.splinter.tokenization_splinter', 'models.splinter.tokenization_splinter_fast', 'models.squeezebert', 'models.squeezebert.configuration_squeezebert', 'models.squeezebert.modeling_squeezebert', 'models.squeezebert.tokenization_squeezebert', 'models.squeezebert.tokenization_squeezebert_fast', 'models.stablelm', 'models.stablelm.configuration_stablelm', 'models.stablelm.modeling_stablelm', 'models.starcoder2', 'models.starcoder2.configuration_starcoder2', 'models.starcoder2.modeling_starcoder2', 'models.superglue', 'models.superglue.configuration_superglue', 'models.superglue.image_processing_superglue', 'models.superglue.modeling_superglue', 'models.superpoint', 'models.superpoint.configuration_superpoint', 'models.superpoint.image_processing_superpoint', 'models.superpoint.image_processing_superpoint_fast', 'models.superpoint.modeling_superpoint', 'models.swiftformer', 'models.swiftformer.configuration_swiftformer', 'models.swiftformer.modeling_swiftformer', 'models.swiftformer.modeling_tf_swiftformer', 'models.swin', 'models.swin.configuration_swin', 'models.swin.modeling_swin', 'models.swin.modeling_tf_swin', 'models.swin2sr', 'models.swin2sr.configuration_swin2sr', 'models.swin2sr.image_processing_swin2sr', 'models.swin2sr.image_processing_swin2sr_fast', 'models.swin2sr.modeling_swin2sr', 'models.swinv2', 'models.swinv2.configuration_swinv2', 'models.swinv2.modeling_swinv2', 'models.switch_transformers', 'models.switch_transformers.configuration_switch_transformers', 'models.switch_transformers.modeling_switch_transformers', 'models.t5', 'models.t5.configuration_t5', 'models.t5.modeling_flax_t5', 'models.t5.modeling_t5', 'models.t5.modeling_tf_t5', 'models.t5.tokenization_t5', 'models.t5.tokenization_t5_fast', 'models.t5gemma', 'models.t5gemma.configuration_t5gemma', 'models.t5gemma.modeling_t5gemma', 'models.table_transformer', 'models.table_transformer.configuration_table_transformer', 'models.table_transformer.modeling_table_transformer', 'models.tapas', 'models.tapas.configuration_tapas', 'models.tapas.modeling_tapas', 'models.tapas.modeling_tf_tapas', 'models.tapas.tokenization_tapas', 'models.textnet', 'models.textnet.configuration_textnet', 'models.textnet.image_processing_textnet', 'models.textnet.modeling_textnet', 'models.time_series_transformer', 'models.time_series_transformer.configuration_time_series_transformer', 'models.time_series_transformer.modeling_time_series_transformer', 'models.timesfm', 'models.timesfm.configuration_timesfm', 'models.timesfm.modeling_timesfm', 'models.timesformer', 'models.timesformer.configuration_timesformer', 'models.timesformer.modeling_timesformer', 'models.timm_backbone', 'models.timm_backbone.configuration_timm_backbone', 'models.timm_backbone.modeling_timm_backbone', 'models.timm_wrapper', 'models.timm_wrapper.configuration_timm_wrapper', 'models.timm_wrapper.image_processing_timm_wrapper', 'models.timm_wrapper.modeling_timm_wrapper', 'models.trocr', 'models.trocr.configuration_trocr', 'models.trocr.modeling_trocr', 'models.trocr.processing_trocr', 'models.tvp', 'models.tvp.configuration_tvp', 'models.tvp.image_processing_tvp', 'models.tvp.modeling_tvp', 'models.tvp.processing_tvp', 'models.udop', 'models.udop.configuration_udop', 'models.udop.modeling_udop', 'models.udop.processing_udop', 'models.udop.tokenization_udop', 'models.udop.tokenization_udop_fast', 'models.umt5', 'models.umt5.configuration_umt5', 'models.umt5.modeling_umt5', 'models.unispeech', 'models.unispeech.configuration_unispeech', 'models.unispeech.modeling_unispeech', 'models.unispeech_sat', 'models.unispeech_sat.configuration_unispeech_sat', 'models.unispeech_sat.modeling_unispeech_sat', 'models.univnet', 'models.univnet.configuration_univnet', 'models.univnet.feature_extraction_univnet', 'models.univnet.modeling_univnet', 'models.upernet', 'models.upernet.configuration_upernet', 'models.upernet.modeling_upernet', 'models.video_llava', 'models.video_llava.configuration_video_llava', 'models.video_llava.image_processing_video_llava', 'models.video_llava.modeling_video_llava', 'models.video_llava.processing_video_llava', 'models.video_llava.video_processing_video_llava', 'models.videomae', 'models.videomae.configuration_videomae', 'models.videomae.feature_extraction_videomae', 'models.videomae.image_processing_videomae', 'models.videomae.modeling_videomae', 'models.vilt', 'models.vilt.configuration_vilt', 'models.vilt.feature_extraction_vilt', 'models.vilt.image_processing_vilt', 'models.vilt.image_processing_vilt_fast', 'models.vilt.modeling_vilt', 'models.vilt.processing_vilt', 'models.vipllava', 'models.vipllava.configuration_vipllava', 'models.vipllava.modeling_vipllava', 'models.vision_encoder_decoder', 'models.vision_encoder_decoder.configuration_vision_encoder_decoder', 'models.vision_encoder_decoder.modeling_flax_vision_encoder_decoder', 'models.vision_encoder_decoder.modeling_tf_vision_encoder_decoder', 'models.vision_encoder_decoder.modeling_vision_encoder_decoder', 'models.vision_text_dual_encoder', 'models.vision_text_dual_encoder.configuration_vision_text_dual_encoder', 'models.vision_text_dual_encoder.modeling_flax_vision_text_dual_encoder', 'models.vision_text_dual_encoder.modeling_tf_vision_text_dual_encoder', 'models.vision_text_dual_encoder.modeling_vision_text_dual_encoder', 'models.vision_text_dual_encoder.processing_vision_text_dual_encoder', 'models.visual_bert', 'models.visual_bert.configuration_visual_bert', 'models.visual_bert.modeling_visual_bert', 'models.vit', 'models.vit.configuration_vit', 'models.vit.feature_extraction_vit', 'models.vit.image_processing_vit', 'models.vit.image_processing_vit_fast', 'models.vit.modeling_flax_vit', 'models.vit.modeling_tf_vit', 'models.vit.modeling_vit', 'models.vit_mae', 'models.vit_mae.configuration_vit_mae', 'models.vit_mae.modeling_tf_vit_mae', 'models.vit_mae.modeling_vit_mae', 'models.vit_msn', 'models.vit_msn.configuration_vit_msn', 'models.vit_msn.modeling_vit_msn', 'models.vitdet', 'models.vitdet.configuration_vitdet', 'models.vitdet.modeling_vitdet', 'models.vitmatte', 'models.vitmatte.configuration_vitmatte', 'models.vitmatte.image_processing_vitmatte', 'models.vitmatte.image_processing_vitmatte_fast', 'models.vitmatte.modeling_vitmatte', 'models.vitpose', 'models.vitpose.configuration_vitpose', 'models.vitpose.image_processing_vitpose', 'models.vitpose.modeling_vitpose', 'models.vitpose_backbone', 'models.vitpose_backbone.configuration_vitpose_backbone', 'models.vitpose_backbone.modeling_vitpose_backbone', 'models.vits', 'models.vits.configuration_vits', 'models.vits.modeling_vits', 'models.vits.tokenization_vits', 'models.vivit', 'models.vivit.configuration_vivit', 'models.vivit.image_processing_vivit', 'models.vivit.modeling_vivit', 'models.vjepa2', 'models.vjepa2.configuration_vjepa2', 'models.vjepa2.modeling_vjepa2', 'models.vjepa2.video_processing_vjepa2', 'models.voxtral', 'models.voxtral.configuration_voxtral', 'models.voxtral.modeling_voxtral', 'models.voxtral.processing_voxtral', 'models.wav2vec2', 'models.wav2vec2.configuration_wav2vec2', 'models.wav2vec2.feature_extraction_wav2vec2', 'models.wav2vec2.modeling_flax_wav2vec2', 'models.wav2vec2.modeling_tf_wav2vec2', 'models.wav2vec2.modeling_wav2vec2', 'models.wav2vec2.processing_wav2vec2', 'models.wav2vec2.tokenization_wav2vec2', 'models.wav2vec2_bert', 'models.wav2vec2_bert.configuration_wav2vec2_bert', 'models.wav2vec2_bert.modeling_wav2vec2_bert', 'models.wav2vec2_bert.processing_wav2vec2_bert', 'models.wav2vec2_conformer', 'models.wav2vec2_conformer.configuration_wav2vec2_conformer', 'models.wav2vec2_conformer.modeling_wav2vec2_conformer', 'models.wav2vec2_phoneme', 'models.wav2vec2_phoneme.tokenization_wav2vec2_phoneme', 'models.wav2vec2_with_lm', 'models.wav2vec2_with_lm.processing_wav2vec2_with_lm', 'models.wavlm', 'models.wavlm.configuration_wavlm', 'models.wavlm.modeling_wavlm', 'models.whisper', 'models.whisper.configuration_whisper', 'models.whisper.feature_extraction_whisper', 'models.whisper.modeling_flax_whisper', 'models.whisper.modeling_tf_whisper', 'models.whisper.modeling_whisper', 'models.whisper.processing_whisper', 'models.whisper.tokenization_whisper', 'models.whisper.tokenization_whisper_fast', 'models.x_clip', 'models.x_clip.configuration_x_clip', 'models.x_clip.modeling_x_clip', 'models.x_clip.processing_x_clip', 'models.xglm', 'models.xglm.configuration_xglm', 'models.xglm.modeling_flax_xglm', 'models.xglm.modeling_tf_xglm', 'models.xglm.modeling_xglm', 'models.xglm.tokenization_xglm', 'models.xglm.tokenization_xglm_fast', 'models.xlm', 'models.xlm.configuration_xlm', 'models.xlm.modeling_tf_xlm', 'models.xlm.modeling_xlm', 'models.xlm.tokenization_xlm', 'models.xlm_roberta', 'models.xlm_roberta.configuration_xlm_roberta', 'models.xlm_roberta.modeling_flax_xlm_roberta', 'models.xlm_roberta.modeling_tf_xlm_roberta', 'models.xlm_roberta.modeling_xlm_roberta', 'models.xlm_roberta.tokenization_xlm_roberta', 'models.xlm_roberta.tokenization_xlm_roberta_fast', 'models.xlm_roberta_xl', 'models.xlm_roberta_xl.configuration_xlm_roberta_xl', 'models.xlm_roberta_xl.modeling_xlm_roberta_xl', 'models.xlnet', 'models.xlnet.configuration_xlnet', 'models.xlnet.modeling_tf_xlnet', 'models.xlnet.modeling_xlnet', 'models.xlnet.tokenization_xlnet', 'models.xlnet.tokenization_xlnet_fast', 'models.xlstm', 'models.xlstm.configuration_xlstm', 'models.xlstm.modeling_xlstm', 'models.xmod', 'models.xmod.configuration_xmod', 'models.xmod.modeling_xmod', 'models.yolos', 'models.yolos.configuration_yolos', 'models.yolos.feature_extraction_yolos', 'models.yolos.image_processing_yolos', 'models.yolos.image_processing_yolos_fast', 'models.yolos.modeling_yolos', 'models.yoso', 'models.yoso.configuration_yoso', 'models.yoso.modeling_yoso', 'models.zamba', 'models.zamba.configuration_zamba', 'models.zamba.modeling_zamba', 'models.zamba2', 'models.zamba2.configuration_zamba2', 'models.zamba2.modeling_zamba2', 'models.zoedepth', 'models.zoedepth.configuration_zoedepth', 'models.zoedepth.image_processing_zoedepth', 'models.zoedepth.image_processing_zoedepth_fast', 'models.zoedepth.modeling_zoedepth', 'onnx', 'optimization', 'pipeline', 'pipelines', 'processing_utils', 'prune_layer', 'pytorch_utils', 'quantizers', 'requires_backends', 'sagemaker', 'set_seed', 'shape_list', 'squad_convert_examples_to_features', 'testing_utils', 'time_series_utils', 'tokenization_utils', 'tokenization_utils_base', 'tokenization_utils_fast', 'torch_distributed_zero_first', 'trainer', 'trainer_callback', 'trainer_pt_utils', 'trainer_seq2seq', 'trainer_utils', 'training_args', 'training_args_seq2seq', 'training_args_tf', 'utils', 'utils.dummy_flax_objects', 'utils.dummy_mistral_common_objects', 'utils.dummy_sentencepiece_and_tokenizers_objects', 'utils.dummy_tf_objects', 'utils.quantization_config', 'video_processing_utils', 'video_utils', 'xLSTMConfig', 'xLSTMForCausalLM', 'xLSTMModel', 'xLSTMPreTrainedModel', 'xnli_compute_metrics', 'xnli_output_modes', 'xnli_processors', 'xnli_tasks_num_labels']\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "print(dir(transformers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44915f82",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
